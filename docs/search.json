[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Currently pursuing a Master of Science in Applied Statistics from Indira Gandhi National Open University (IGNOU), complemented by a Bachelor of Science (Non-Medical) from Kurukshetra University, I possess a robust foundation in quantitative methods and statistical analysis. My proficiency in data analysis tools such as R, Python, and Microsoft Office has enabled me to effectively manage and analyze large datasets, including extracting and analyzing data from PLFS and compiling and analyzing union budget data to identify expenditure trends. I am adept at data scraping from various secondary sources, ensuring comprehensive data collection for research projects.\nMy professional experience, particularly as a Research Assistant at the Society for Social and Economic Research (SSER) and a Course Assistant at IDEAs, has provided me with invaluable hands-on experience in the entire research lifecycle. I have actively participated in and assisted with numerous field surveys across diverse regions and topics, including rural households, industrial workers, farmers during protests and crises, and health financing studies. My responsibilities included data compilation, analysis, visualization using R, and meticulous data entry for primary surveys.\nBeyond my analytical capabilities, I bring strong administrative and technical skills. I am proficient in managing virtual learning platforms like Zoom, OBS-Studio, and YouTube streaming, ensuring seamless hybrid classroom environments. My administrative experience includes classroom management, accounts maintenance, inventory management, and general office functioning. Furthermore, I am proficient in operating systems such as Linux, Windows, and macOS, with expertise in troubleshooting and software management. I am a highly motivated and detail-oriented professional with a proven ability to contribute to research initiatives, manage complex datasets, and coordinate field activities effectively. My diverse skill set and practical experience make me a strong candidate for a role that demands both analytical rigor and operational efficiency."
  },
  {
    "objectID": "episodes.html",
    "href": "episodes.html",
    "title": "Episodes",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n\n\n\n\n\n\n\n\nBefore we Start\n\n\n\n\n\n\n\n\n\n\nProcessing JSON data (Optional)\n\n\n\n\n\n\n\n\n\n\nData Wrangling with tidyr\n\n\n\n\n\n\n\n\n\n\nIntroduction to R\n\n\n\n\n\n\n\n\n\n\nData Visualisation with ggplot2\n\n\n\n\n\n\n\n\n\n\nData Wrangling with dplyr\n\n\n\n\n\n\n\n\n\n\nGetting started with R Markdown (Optional)\n\n\n\n\n\n\n\n\n\n\nInstalling R and RStudio on Linux\n\n\n\n\n\n\n\n\n\n\nStarting with Data\n\n\n\n\n\n\n\n\n\n\ndata frame\n\n\n\nSeptember 19, 2023\n\n\n\n\n\n\n\n\n\n\n\nEfficient reshaping using data.tables\n\n\n\nSeptember 19, 2023\n\n\n\n\n\n\n\n\n\n\n\ndata in R\n\n\n\nSeptember 14, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "episodes/02-starting-with-data.html",
    "href": "episodes/02-starting-with-data.html",
    "title": "Starting with Data",
    "section": "",
    "text": "The two main goals for this lessons are:\n\nTo make sure that learners are comfortable with working with data frames, and can use the bracket notation to select slices/columns.\nTo expose learners to factors. Their behavior is not necessarily intuitive, and so it is important that they are guided through it the first time they are exposed to it. The content of the lesson should be enough for learners to avoid common mistakes with them."
  },
  {
    "objectID": "episodes/02-starting-with-data.html#what-are-data-frames",
    "href": "episodes/02-starting-with-data.html#what-are-data-frames",
    "title": "Starting with Data",
    "section": "What are data frames?",
    "text": "What are data frames?\nData frames are the de facto data structure for tabular data in R, and what we use for data processing, statistics, and plotting.\nA data frame is the representation of data in the format of a table where the columns are vectors that all have the same length. Data frames are analogous to the more familiar spreadsheet in programs such as Excel, with one key difference. Because columns are vectors, each column must contain a single type of data (e.g., characters, integers, factors). For example, here is a figure depicting a data frame comprising a numeric, a character, and a logical vector.\n\nData frames can be created by hand, but most commonly they are generated by the functions read_csv() or read_table(); in other words, when importing spreadsheets from your hard drive (or the web). We will now demonstrate how to import tabular data using read_csv()."
  },
  {
    "objectID": "episodes/02-starting-with-data.html#presentation-of-the-safi-data",
    "href": "episodes/02-starting-with-data.html#presentation-of-the-safi-data",
    "title": "Starting with Data",
    "section": "Presentation of the SAFI Data",
    "text": "Presentation of the SAFI Data\nSAFI (Studying African Farmer-Led Irrigation) is a study looking at farming and irrigation methods in Tanzania and Mozambique. The survey data was collected through interviews conducted between November 2016 and June 2017. For this lesson, we will be using a subset of the available data. For information about the full teaching dataset used in other lessons in this workshop, see the dataset description.\nWe will be using a subset of the cleaned version of the dataset that was produced through cleaning in OpenRefine (data/SAFI_clean.csv). In this dataset, the missing data is encoded as “NULL”, each row holds information for a single interview respondent, and the columns represent:\n\n\n\n\n\n\n\ncolumn_name\ndescription\n\n\n\n\nkey_id\nAdded to provide a unique Id for each observation. (The InstanceID field does this as well but it is not as convenient to use)\n\n\nvillage\nVillage name\n\n\ninterview_date\nDate of interview\n\n\nno_membrs\nHow many members in the household?\n\n\nyears_liv\nHow many years have you been living in this village or neighboring village?\n\n\nrespondent_wall_type\nWhat type of walls does their house have (from list)\n\n\nrooms\nHow many rooms in the main house are used for sleeping?\n\n\nmemb_assoc\nAre you a member of an irrigation association?\n\n\naffect_conflicts\nHave you been affected by conflicts with other irrigators in the area?\n\n\nliv_count\nNumber of livestock owned.\n\n\nitems_owned\nWhich of the following items are owned by the household? (list)\n\n\nno_meals\nHow many meals do people in your household normally eat in a day?\n\n\nmonths_lack_food\nIndicate which months, In the last 12 months have you faced a situation when you did not have enough food to feed the household?\n\n\ninstanceID\nUnique identifier for the form data submission"
  },
  {
    "objectID": "episodes/02-starting-with-data.html#importing-data",
    "href": "episodes/02-starting-with-data.html#importing-data",
    "title": "Starting with Data",
    "section": "Importing data",
    "text": "Importing data\nYou are going to load the data in R’s memory using the function read_csv() from the readr package, which is part of the tidyverse; learn more about the tidyverse collection of packages here. readr gets installed as part as the tidyverse installation. When you load the tidyverse (library(tidyverse)), the core packages (the packages used in most data analyses) get loaded, including readr.\nBefore proceeding, however, this is a good opportunity to talk about conflicts. Certain packages we load can end up introducing function names that are already in use by pre-loaded R packages. For instance, when we load the tidyverse package below, we will introduce two conflicting functions: filter() and lag(). This happens because filter and lag are already functions used by the stats package (already pre-loaded in R). What will happen now is that if we, for example, call the filter() function, R will use the dplyr::filter() version and not the stats::filter() one. This happens because, if conflicted, by default R uses the function from the most recently loaded package. Conflicted functions may cause you some trouble in the future, so it is important that we are aware of them so that we can properly handle them, if we want.\nTo do so, we just need the following functions from the conflicted package:\n\nconflicted::conflict_scout(): Shows us any conflicted functions.\n\nconflict_prefer(\"function\", \"package_prefered\"): Allows us to choose the default function we want from now on.\n\nIt is also important to know that we can, at any time, just call the function directly from the package we want, such as stats::filter().\nEven with the use of an RStudio project, it can be difficult to learn how to specify paths to file locations. Enter the here package! The here package creates paths relative to the top-level directory (your RStudio project). These relative paths work regardless of where the associated source file lives inside your project, like analysis projects with data and reports in different subdirectories. This is an important contrast to using setwd(), which depends on the way you order your files on your computer.\n\n\n\n\n\n\n\n\n\n\n\nImage credit: Allison Horst\n\n\nBefore we can use the read_csv() and here() functions, we need to load the tidyverse and here packages.\nAlso, if you recall, the missing data is encoded as “NULL” in the dataset. We’ll tell it to the function, so R will automatically convert all the “NULL” entries in the dataset into NA.\n\nlibrary(tidyverse)\nlibrary(here)\n\ninterviews &lt;- read_csv(\n  here(\"data\", \"SAFI_clean.csv\"), \n  na = \"NULL\")\n\nIn the above code, we notice the here() function takes folder and file names as inputs (e.g., \"data\", \"SAFI_clean.csv\"), each enclosed in quotations (\"\") and separated by a comma. The here() will accept as many names as are necessary to navigate to a particular file (e.g., here(\"analysis\", \"data\", \"surveys\", \"clean\", \"SAFI_clean.csv)).\nThe here() function can accept the folder and file names in an alternate format, using a slash (“/”) rather than commas to separate the names. The two methods are equivalent, so that here(\"data\", \"SAFI_clean.csv\") and here(\"data/SAFI_clean.csv\") produce the same result. (The slash is used on all operating systems; backslashes are not used.)\nIf you were to type in the code above, it is likely that the read.csv() function would appear in the automatically populated list of functions. This function is different from the read_csv() function, as it is included in the “base” packages that come pre-installed with R. Overall, read.csv() behaves similar to read_csv(), with a few notable differences. First, read.csv() coerces column names with spaces and/or special characters to different names (e.g. interview date becomes interview.date). Second, read.csv() stores data as a data.frame, where read_csv() stores data as a different kind of data frame called a tibble. We prefer tibbles because they have nice printing properties among other desirable qualities. Read more about tibbles here.\nThe second statement in the code above creates a data frame but doesn’t output any data because, as you might recall, assignments (&lt;-) don’t display anything. (Note, however, that read_csv may show informational text about the data frame that is created.) If we want to check that our data has been loaded, we can see the contents of the data frame by typing its name: interviews in the console.\n\ninterviews\n## Try also\n## view(interviews)\n## head(interviews)\n\n# A tibble: 131 × 14\n   key_ID village  interview_date      no_membrs years_liv respondent_wall_type\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n 1      1 God      2016-11-17 00:00:00         3         4 muddaub             \n 2      2 God      2016-11-17 00:00:00         7         9 muddaub             \n 3      3 God      2016-11-17 00:00:00        10        15 burntbricks         \n 4      4 God      2016-11-17 00:00:00         7         6 burntbricks         \n 5      5 God      2016-11-17 00:00:00         7        40 burntbricks         \n 6      6 God      2016-11-17 00:00:00         3         3 muddaub             \n 7      7 God      2016-11-17 00:00:00         6        38 muddaub             \n 8      8 Chirodzo 2016-11-16 00:00:00        12        70 burntbricks         \n 9      9 Chirodzo 2016-11-16 00:00:00         8         6 burntbricks         \n10     10 Chirodzo 2016-12-16 00:00:00        12        23 burntbricks         \n# ℹ 121 more rows\n# ℹ 8 more variables: rooms &lt;dbl&gt;, memb_assoc &lt;chr&gt;, affect_conflicts &lt;chr&gt;,\n#   liv_count &lt;dbl&gt;, items_owned &lt;chr&gt;, no_meals &lt;dbl&gt;, months_lack_food &lt;chr&gt;,\n#   instanceID &lt;chr&gt;\n\n\n\n\n\n\n\n\nNoneNote\n\n\n\nread_csv() assumes that fields are delimited by commas. However, in several countries, the comma is used as a decimal separator and the semicolon (;) is used as a field delimiter. If you want to read in this type of files in R, you can use the read_csv2 function. It behaves exactly like read_csv but uses different parameters for the decimal and the field separators. If you are working with another format, they can be both specified by the user. Check out the help for read_csv() by typing ?read_csv to learn more. There is also the read_tsv() for tab-separated data files, and read_delim() allows you to specify more details about the structure of your file.\n\n\nNote that read_csv() actually loads the data as a tibble. A tibble is an extension of R data frames used by the tidyverse. When the data is read using read_csv(), it is stored in an object of class tbl_df, tbl, and data.frame. You can see the class of an object with\n\nclass(interviews)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nAs a tibble, the type of data included in each column is listed in an abbreviated fashion below the column names. For instance, here key_ID is a column of floating point numbers (abbreviated &lt;dbl&gt; for the word ‘double’), village is a column of characters (&lt;chr&gt;) and the interview_date is a column in the “date and time” format (&lt;dttm&gt;)."
  },
  {
    "objectID": "episodes/02-starting-with-data.html#inspecting-data-frames",
    "href": "episodes/02-starting-with-data.html#inspecting-data-frames",
    "title": "Starting with Data",
    "section": "Inspecting data frames",
    "text": "Inspecting data frames\nWhen calling a tbl_df object (like interviews here), there is already a lot of information about our data frame being displayed such as the number of rows, the number of columns, the names of the columns, and as we just saw the class of data stored in each column. However, there are functions to extract this information from data frames. Here is a non-exhaustive list of some of these functions. Let’s try them out!\nSize:\n\ndim(interviews) - returns a vector with the number of rows as the first element, and the number of columns as the second element (the dimensions of the object)\nnrow(interviews) - returns the number of rows\nncol(interviews) - returns the number of columns\n\nContent:\n\nhead(interviews) - shows the first 6 rows\ntail(interviews) - shows the last 6 rows\n\nNames:\n\nnames(interviews) - returns the column names (synonym of colnames() for data.frame objects)\n\nSummary:\n\nstr(interviews) - structure of the object and information about the class, length and content of each column\nsummary(interviews) - summary statistics for each column\nglimpse(interviews) - returns the number of columns and rows of the tibble, the names and class of each column, and previews as many values will fit on the screen. Unlike the other inspecting functions listed above, glimpse() is not a “base R” function so you need to have the dplyr or tibble packages loaded to be able to execute it.\n\nNote: most of these functions are “generic.” They can be used on other types of objects besides data frames or tibbles."
  },
  {
    "objectID": "episodes/02-starting-with-data.html#subsetting-data-frames",
    "href": "episodes/02-starting-with-data.html#subsetting-data-frames",
    "title": "Starting with Data",
    "section": "Subsetting data frames",
    "text": "Subsetting data frames\nOur interviews data frame has rows and columns (it has 2 dimensions). In practice, we may not need the entire data frame; for instance, we may only be interested in a subset of the observations (the rows) or a particular set of variables (the columns). If we want to access some specific data from it, we need to specify the “coordinates” (i.e., indices) we want from it. Row numbers come first, followed by column numbers.\n\n\n\n\n\n\nNoneTip\n\n\n\nSubsetting a tibble with [ always results in a tibble. However, note this is not true in general for data frames, so be careful! Different ways of specifying these coordinates can lead to results with different classes. This is covered in the Software Carpentry lesson R for Reproducible Scientific Analysis.\n\n\n\n## first element in the first column of the tibble\ninterviews[1, 1]\n\n# A tibble: 1 × 1\n  key_ID\n   &lt;dbl&gt;\n1      1\n\n## first element in the 6th column of the tibble \ninterviews[1, 6]\n\n# A tibble: 1 × 1\n  respondent_wall_type\n  &lt;chr&gt;               \n1 muddaub             \n\n## first column of the tibble (as a vector)\ninterviews[[1]]\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71 127\n [73] 133 152 153 155 178 177 180 181 182 186 187 195 196 197 198 201 202  72\n [91]  73  76  83  85  89 101 103 102  78  80 104 105 106 109 110 113 118 125\n[109] 119 115 108 116 117 144 143 150 159 160 165 166 167 174 175 189 191 192\n[127] 126 193 194 199 200\n\n## first column of the tibble\ninterviews[1]\n\n# A tibble: 131 × 1\n   key_ID\n    &lt;dbl&gt;\n 1      1\n 2      2\n 3      3\n 4      4\n 5      5\n 6      6\n 7      7\n 8      8\n 9      9\n10     10\n# ℹ 121 more rows\n\n## first three elements in the 7th column of the tibble\ninterviews[1:3, 7]\n\n# A tibble: 3 × 1\n  rooms\n  &lt;dbl&gt;\n1     1\n2     1\n3     1\n\n## the 3rd row of the tibble\ninterviews[3, ]\n\n# A tibble: 1 × 14\n  key_ID village interview_date      no_membrs years_liv respondent_wall_type\n   &lt;dbl&gt; &lt;chr&gt;   &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n1      3 God     2016-11-17 00:00:00        10        15 burntbricks         \n# ℹ 8 more variables: rooms &lt;dbl&gt;, memb_assoc &lt;chr&gt;, affect_conflicts &lt;chr&gt;,\n#   liv_count &lt;dbl&gt;, items_owned &lt;chr&gt;, no_meals &lt;dbl&gt;, months_lack_food &lt;chr&gt;,\n#   instanceID &lt;chr&gt;\n\n## equivalent to head_interviews &lt;- head(interviews)\nhead_interviews &lt;- interviews[1:6, ]\n\n: is a special function that creates numeric vectors of integers in increasing or decreasing order, test 1:10 and 10:1 for instance.\nYou can also exclude certain indices of a data frame using the “-” sign:\n\ninterviews[, -1]          # The whole tibble, except the first column\n\n# A tibble: 131 × 13\n   village  interview_date      no_membrs years_liv respondent_wall_type rooms\n   &lt;chr&gt;    &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                &lt;dbl&gt;\n 1 God      2016-11-17 00:00:00         3         4 muddaub                  1\n 2 God      2016-11-17 00:00:00         7         9 muddaub                  1\n 3 God      2016-11-17 00:00:00        10        15 burntbricks              1\n 4 God      2016-11-17 00:00:00         7         6 burntbricks              1\n 5 God      2016-11-17 00:00:00         7        40 burntbricks              1\n 6 God      2016-11-17 00:00:00         3         3 muddaub                  1\n 7 God      2016-11-17 00:00:00         6        38 muddaub                  1\n 8 Chirodzo 2016-11-16 00:00:00        12        70 burntbricks              3\n 9 Chirodzo 2016-11-16 00:00:00         8         6 burntbricks              1\n10 Chirodzo 2016-12-16 00:00:00        12        23 burntbricks              5\n# ℹ 121 more rows\n# ℹ 7 more variables: memb_assoc &lt;chr&gt;, affect_conflicts &lt;chr&gt;,\n#   liv_count &lt;dbl&gt;, items_owned &lt;chr&gt;, no_meals &lt;dbl&gt;, months_lack_food &lt;chr&gt;,\n#   instanceID &lt;chr&gt;\n\ninterviews[-c(7:131), ]   # Equivalent to head(interviews)\n\n# A tibble: 6 × 14\n  key_ID village interview_date      no_membrs years_liv respondent_wall_type\n   &lt;dbl&gt; &lt;chr&gt;   &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n1      1 God     2016-11-17 00:00:00         3         4 muddaub             \n2      2 God     2016-11-17 00:00:00         7         9 muddaub             \n3      3 God     2016-11-17 00:00:00        10        15 burntbricks         \n4      4 God     2016-11-17 00:00:00         7         6 burntbricks         \n5      5 God     2016-11-17 00:00:00         7        40 burntbricks         \n6      6 God     2016-11-17 00:00:00         3         3 muddaub             \n# ℹ 8 more variables: rooms &lt;dbl&gt;, memb_assoc &lt;chr&gt;, affect_conflicts &lt;chr&gt;,\n#   liv_count &lt;dbl&gt;, items_owned &lt;chr&gt;, no_meals &lt;dbl&gt;, months_lack_food &lt;chr&gt;,\n#   instanceID &lt;chr&gt;\n\n\ntibbles can be subset by calling indices (as shown previously), but also by calling their column names directly:\n\ninterviews[\"village\"]       # Result is a tibble\n\ninterviews[, \"village\"]     # Result is a tibble\n\ninterviews[[\"village\"]]     # Result is a vector\n\ninterviews$village          # Result is a vector\n\nIn RStudio, you can use the autocompletion feature to get the full and correct names of the columns."
  },
  {
    "objectID": "episodes/02-starting-with-data.html#exercise",
    "href": "episodes/02-starting-with-data.html#exercise",
    "title": "Starting with Data",
    "section": "Exercise",
    "text": "Exercise\n\nCreate a tibble (interviews_100) containing only the data in row 100 of the interviews dataset.\n\nNow, continue using interviews for each of the following activities:\n\nNotice how nrow() gave you the number of rows in the tibble?\n\n\nUse that number to pull out just that last row in the tibble.\nCompare that with what you see as the last row using tail() to make sure it’s meeting expectations.\nPull out that last row using nrow() instead of the row number.\nCreate a new tibble (interviews_last) from that last row.\n\n\nUsing the number of rows in the interviews dataset that you found in question 2, extract the row that is in the middle of the dataset. Store the content of this middle row in an object named interviews_middle. (hint: This dataset has an odd number of rows, so finding the middle is a bit trickier than dividing n_rows by 2. Use the median( ) function and what you’ve learned about sequences in R to extract the middle row!\nCombine nrow() with the - notation above to reproduce the behavior of head(interviews), keeping just the first through 6th rows of the interviews dataset.\n\n\nSolution (Solution). \n\n## 1.\ninterviews_100 &lt;- interviews[100, ]\n## 2.\n# Saving `n_rows` to improve readability and reduce duplication\nn_rows &lt;- nrow(interviews)\ninterviews_last &lt;- interviews[n_rows, ]\n## 3.\ninterviews_middle &lt;- interviews[median(1:n_rows), ]\n## 4.\ninterviews_head &lt;- interviews[-(7:n_rows), ]"
  },
  {
    "objectID": "episodes/02-starting-with-data.html#factors",
    "href": "episodes/02-starting-with-data.html#factors",
    "title": "Starting with Data",
    "section": "Factors",
    "text": "Factors\nR has a special data class, called factor, to deal with categorical data that you may encounter when creating plots or doing statistical analyses. Factors are very useful and actually contribute to making R particularly well suited to working with data. So we are going to spend a little time introducing them.\nFactors represent categorical data. They are stored as integers associated with labels and they can be ordered (ordinal) or unordered (nominal). Factors create a structured relation between the different levels (values) of a categorical variable, such as days of the week or responses to a question in a survey. This can make it easier to see how one element relates to the other elements in a column. While factors look (and often behave) like character vectors, they are actually treated as integer vectors by R. So you need to be very careful when treating them as strings.\nOnce created, factors can only contain a pre-defined set of values, known as levels. By default, R always sorts levels in alphabetical order. For instance, if you have a factor with 2 levels:\n\nrespondent_floor_type &lt;- factor(c(\"earth\", \"cement\", \"cement\", \"earth\"))\n\nR will assign 1 to the level \"cement\" and 2 to the level \"earth\" (because c comes before e, even though the first element in this vector is \"earth\"). You can see this by using the function levels() and you can find the number of levels using nlevels():\n\nlevels(respondent_floor_type)\n\n[1] \"cement\" \"earth\" \n\nnlevels(respondent_floor_type)\n\n[1] 2\n\n\nSometimes, the order of the factors does not matter. Other times you might want to specify the order because it is meaningful (e.g., “low”, “medium”, “high”). It may improve your visualization, or it may be required by a particular type of analysis. Here, one way to reorder our levels in the respondent_floor_type vector would be:\n\nrespondent_floor_type # current order\n\n[1] earth  cement cement earth \nLevels: cement earth\n\nrespondent_floor_type &lt;- factor(respondent_floor_type, \n                                levels = c(\"earth\", \"cement\"))\n\nrespondent_floor_type # after re-ordering\n\n[1] earth  cement cement earth \nLevels: earth cement\n\n\nIn R’s memory, these factors are represented by integers (1, 2), but are more informative than integers because factors are self describing: \"cement\", \"earth\" is more descriptive than 1, and 2. Which one is “earth”? You wouldn’t be able to tell just from the integer data. Factors, on the other hand, have this information built in. It is particularly helpful when there are many levels. It also makes renaming levels easier. Let’s say we made a mistake and need to recode “cement” to “brick”. We can do this using the fct_recode() function from the forcats package (included in the tidyverse) which provides some extra tools to work with factors.\n\nlevels(respondent_floor_type)\n\n[1] \"earth\"  \"cement\"\n\nrespondent_floor_type &lt;- fct_recode(respondent_floor_type, brick = \"cement\")\n\n## as an alternative, we could change the \"cement\" level directly using the\n## levels() function, but we have to remember that \"cement\" is the second level\n# levels(respondent_floor_type)[2] &lt;- \"brick\"\n\nlevels(respondent_floor_type)\n\n[1] \"earth\" \"brick\"\n\nrespondent_floor_type\n\n[1] earth brick brick earth\nLevels: earth brick\n\n\nSo far, your factor is unordered, like a nominal variable. R does not know the difference between a nominal and an ordinal variable. You make your factor an ordered factor by using the ordered=TRUE option inside your factor function. Note how the reported levels changed from the unordered factor above to the ordered version below. Ordered levels use the less than sign &lt; to denote level ranking.\n\nrespondent_floor_type_ordered &lt;- factor(respondent_floor_type, \n                                        ordered = TRUE)\n\nrespondent_floor_type_ordered # after setting as ordered factor\n\n[1] earth brick brick earth\nLevels: earth &lt; brick\n\n\n\nConverting factors\nIf you need to convert a factor to a character vector, you use as.character(x).\n\nas.character(respondent_floor_type)\n\n[1] \"earth\" \"brick\" \"brick\" \"earth\"\n\n\nConverting factors where the levels appear as numbers (such as concentration levels, or years) to a numeric vector is a little trickier. The as.numeric() function returns the index values of the factor, not its levels, so it will result in an entirely new (and unwanted in this case) set of numbers. One method to avoid this is to convert factors to characters, and then to numbers. Another method is to use the levels() function. Compare:\n\nyear_fct &lt;- factor(c(1990, 1983, 1977, 1998, 1990))\n\nas.numeric(year_fct)                     # Wrong! And there is no warning...\n\n[1] 3 2 1 4 3\n\nas.numeric(as.character(year_fct))       # Works...\n\n[1] 1990 1983 1977 1998 1990\n\nas.numeric(levels(year_fct))[year_fct]   # The recommended way.\n\n[1] 1990 1983 1977 1998 1990\n\n\nNotice that in the recommended levels() approach, three important steps occur:\n\nWe obtain all the factor levels using levels(year_fct)\nWe convert these levels to numeric values using as.numeric(levels(year_fct))\nWe then access these numeric values using the underlying integers of the vector year_fct inside the square brackets\n\n\n\nRenaming factors\nWhen your data is stored as a factor, you can use the plot() function to get a quick glance at the number of observations represented by each factor level. Let’s extract the memb_assoc column from our data frame, convert it into a factor, and use it to look at the number of interview respondents who were or were not members of an irrigation association:\n\n## create a vector from the data frame column \"memb_assoc\"\nmemb_assoc &lt;- interviews$memb_assoc\n\n## convert it into a factor\nmemb_assoc &lt;- as.factor(memb_assoc)\n\n## let's see what it looks like\nmemb_assoc\n\n  [1] &lt;NA&gt; yes  &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; no   yes  no   no   &lt;NA&gt; yes  no   &lt;NA&gt; yes \n [16] &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; no   &lt;NA&gt; &lt;NA&gt; no   no   no   &lt;NA&gt; no   yes  &lt;NA&gt;\n [31] &lt;NA&gt; yes  no   yes  yes  yes  &lt;NA&gt; yes  &lt;NA&gt; yes  &lt;NA&gt; no   no   &lt;NA&gt; no  \n [46] no   yes  &lt;NA&gt; &lt;NA&gt; yes  &lt;NA&gt; no   yes  no   &lt;NA&gt; yes  no   no   &lt;NA&gt; no  \n [61] yes  &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; no   yes  no   no   no   no   yes  &lt;NA&gt; no   yes  &lt;NA&gt;\n [76] &lt;NA&gt; yes  no   no   yes  no   no   yes  no   yes  no   no   &lt;NA&gt; yes  yes \n [91] yes  yes  yes  no   no   no   no   yes  no   no   yes  yes  no   &lt;NA&gt; no  \n[106] no   &lt;NA&gt; no   no   &lt;NA&gt; no   &lt;NA&gt; &lt;NA&gt; no   no   no   no   yes  no   no  \n[121] no   no   no   no   no   no   no   no   no   yes  &lt;NA&gt;\nLevels: no yes\n\n## bar plot of the number of interview respondents who were\n## members of irrigation association:\nplot(memb_assoc)\n\n\n\n\n\n\n\n\nLooking at the plot compared to the output of the vector, we can see that in addition to “no”s and “yes”s, there are some respondents for whom the information about whether they were part of an irrigation association hasn’t been recorded, and encoded as missing data. These respondents do not appear on the plot. Let’s encode them differently so they can be counted and visualized in our plot.\n\n## Let's recreate the vector from the data frame column \"memb_assoc\"\nmemb_assoc &lt;- interviews$memb_assoc\n\n## replace the missing data with \"undetermined\"\nmemb_assoc[is.na(memb_assoc)] &lt;- \"undetermined\"\n\n## convert it into a factor\nmemb_assoc &lt;- as.factor(memb_assoc)\n\n## let's see what it looks like\nmemb_assoc\n\n  [1] undetermined yes          undetermined undetermined undetermined\n  [6] undetermined no           yes          no           no          \n [11] undetermined yes          no           undetermined yes         \n [16] undetermined undetermined undetermined undetermined undetermined\n [21] no           undetermined undetermined no           no          \n [26] no           undetermined no           yes          undetermined\n [31] undetermined yes          no           yes          yes         \n [36] yes          undetermined yes          undetermined yes         \n [41] undetermined no           no           undetermined no          \n [46] no           yes          undetermined undetermined yes         \n [51] undetermined no           yes          no           undetermined\n [56] yes          no           no           undetermined no          \n [61] yes          undetermined undetermined undetermined no          \n [66] yes          no           no           no           no          \n [71] yes          undetermined no           yes          undetermined\n [76] undetermined yes          no           no           yes         \n [81] no           no           yes          no           yes         \n [86] no           no           undetermined yes          yes         \n [91] yes          yes          yes          no           no          \n [96] no           no           yes          no           no          \n[101] yes          yes          no           undetermined no          \n[106] no           undetermined no           no           undetermined\n[111] no           undetermined undetermined no           no          \n[116] no           no           yes          no           no          \n[121] no           no           no           no           no          \n[126] no           no           no           no           yes         \n[131] undetermined\nLevels: no undetermined yes\n\n## bar plot of the number of interview respondents who were\n## members of irrigation association:\nplot(memb_assoc)"
  },
  {
    "objectID": "episodes/02-starting-with-data.html#exercise-1",
    "href": "episodes/02-starting-with-data.html#exercise-1",
    "title": "Starting with Data",
    "section": "Exercise",
    "text": "Exercise\n\nRename the levels of the factor to have the first letter in uppercase: “No”,“Undetermined”, and “Yes”.\nNow that we have renamed the factor level to “Undetermined”, can you recreate the barplot such that “Undetermined” is last (after “Yes”)?\n\n\nSolution (Solution). \n\n## Rename levels.\nmemb_assoc &lt;- fct_recode(memb_assoc, No = \"no\",\n                         Undetermined = \"undetermined\", Yes = \"yes\")\n## Reorder levels. Note we need to use the new level names.\nmemb_assoc &lt;- factor(memb_assoc, levels = c(\"No\", \"Yes\", \"Undetermined\"))\nplot(memb_assoc)"
  },
  {
    "objectID": "episodes/02-starting-with-data.html#formatting-dates",
    "href": "episodes/02-starting-with-data.html#formatting-dates",
    "title": "Starting with Data",
    "section": "Formatting Dates",
    "text": "Formatting Dates\nOne of the most common issues that new (and experienced!) R users have is converting date and time information into a variable that is appropriate and usable during analyses. A best practice for dealing with date data is to ensure that each component of your date is available as a separate variable. In our dataset, we have a column interview_date which contains information about the year, month, and day that the interview was conducted. Let’s convert those dates into three separate columns.\n\nstr(interviews)\n\nWe are going to use the package lubridate, , which is included in the tidyverse installation and should be loaded by default. However, if we deal with older versions of tidyverse (2022 and ealier), we can manually load it by typing library(lubridate).\nIf necessary, start by loading the required package:\n\nlibrary(lubridate)\n\nThe lubridate function ymd() takes a vector representing year, month, and day, and converts it to a Date vector. Date is a class of data recognized by R as being a date and can be manipulated as such. The argument that the function requires is flexible, but, as a best practice, is a character vector formatted as “YYYY-MM-DD”.\nLet’s extract our interview_date column and inspect the structure:\n\ndates &lt;- interviews$interview_date\nstr(dates)\n\n POSIXct[1:131], format: \"2016-11-17\" \"2016-11-17\" \"2016-11-17\" \"2016-11-17\" \"2016-11-17\" ...\n\n\nWhen we imported the data in R, read_csv() recognized that this column contained date information. We can now use the day(), month() and year() functions to extract this information from the date, and create new columns in our data frame to store it:\n\ninterviews$day &lt;- day(dates)\ninterviews$month &lt;- month(dates)\ninterviews$year &lt;- year(dates)\ninterviews\n\n# A tibble: 131 × 17\n   key_ID village  interview_date      no_membrs years_liv respondent_wall_type\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n 1      1 God      2016-11-17 00:00:00         3         4 muddaub             \n 2      2 God      2016-11-17 00:00:00         7         9 muddaub             \n 3      3 God      2016-11-17 00:00:00        10        15 burntbricks         \n 4      4 God      2016-11-17 00:00:00         7         6 burntbricks         \n 5      5 God      2016-11-17 00:00:00         7        40 burntbricks         \n 6      6 God      2016-11-17 00:00:00         3         3 muddaub             \n 7      7 God      2016-11-17 00:00:00         6        38 muddaub             \n 8      8 Chirodzo 2016-11-16 00:00:00        12        70 burntbricks         \n 9      9 Chirodzo 2016-11-16 00:00:00         8         6 burntbricks         \n10     10 Chirodzo 2016-12-16 00:00:00        12        23 burntbricks         \n# ℹ 121 more rows\n# ℹ 11 more variables: rooms &lt;dbl&gt;, memb_assoc &lt;chr&gt;, affect_conflicts &lt;chr&gt;,\n#   liv_count &lt;dbl&gt;, items_owned &lt;chr&gt;, no_meals &lt;dbl&gt;, months_lack_food &lt;chr&gt;,\n#   instanceID &lt;chr&gt;, day &lt;int&gt;, month &lt;dbl&gt;, year &lt;dbl&gt;\n\n\nNotice the three new columns at the end of our data frame.\nIn our example above, the interview_date column was read in correctly as a Date variable but generally that is not the case. Date columns are often read in as character variables and one can use the as_date() function to convert them to the appropriate Date/POSIXctformat.\nLet’s say we have a vector of dates in character format:\n\nchar_dates &lt;- c(\"7/31/2012\", \"8/9/2014\", \"4/30/2016\")\nstr(char_dates)\n\n chr [1:3] \"7/31/2012\" \"8/9/2014\" \"4/30/2016\"\n\n\nWe can convert this vector to dates as :\n\nas_date(char_dates, format = \"%m/%d/%Y\")\n\n[1] \"2012-07-31\" \"2014-08-09\" \"2016-04-30\"\n\n\nArgument format tells the function the order to parse the characters and identify the month, day and year. The format above is the equivalent of mm/dd/yyyy. A wrong format can lead to parsing errors or incorrect results.\nFor example, observe what happens when we use a lower case y instead of upper case Y for the year.\n\nas_date(char_dates, format = \"%m/%d/%y\")\n\nWarning: 3 failed to parse.\n\n\n[1] NA NA NA\n\n\nHere, the %y part of the format stands for a two-digit year instead of a four-digit year, and this leads to parsing errors.\nOr in the following example, observe what happens when the month and day elements of the format are switched.\n\nas_date(char_dates, format = \"%d/%m/%y\")\n\nWarning: 3 failed to parse.\n\n\n[1] NA NA NA\n\n\nSince there is no month numbered 30 or 31, the first and third dates cannot be parsed.\nWe can also use functions ymd(), mdy() or dmy() to convert character variables to date.\n\nmdy(char_dates)\n\n[1] \"2012-07-31\" \"2014-08-09\" \"2016-04-30\"\n\n\n\n\nUse read_csv to read tabular data in R.\nUse factors to represent categorical data in R."
  },
  {
    "objectID": "episodes/installation.html",
    "href": "episodes/installation.html",
    "title": "Installing R and RStudio on Linux",
    "section": "",
    "text": "You can just install the R-base package using the following code or Use your package manager to install R and R-studio.\n\n\napt-get install r-base (as superuser)\nor\nsudo apt-get install r-base\n\n\n\nNext comes installing RStudio. To install RStudio, go to download RStudio, click on the download button for the RStudio desktop, click the link for the latest R version for your OS, and save the .deb file.\nDownload the correct version of R-Studio from https://www.rstudio.com/products/rstudio/download/#download\napt install -f ./filename.deb (as superuser)"
  },
  {
    "objectID": "episodes/installation.html#debianubuntulinux-mint",
    "href": "episodes/installation.html#debianubuntulinux-mint",
    "title": "Installing R and RStudio on Linux",
    "section": "",
    "text": "apt-get install r-base (as superuser)\nor\nsudo apt-get install r-base"
  },
  {
    "objectID": "episodes/installation.html#install-rstudio-on-linux",
    "href": "episodes/installation.html#install-rstudio-on-linux",
    "title": "Installing R and RStudio on Linux",
    "section": "",
    "text": "Next comes installing RStudio. To install RStudio, go to download RStudio, click on the download button for the RStudio desktop, click the link for the latest R version for your OS, and save the .deb file.\nDownload the correct version of R-Studio from https://www.rstudio.com/products/rstudio/download/#download\napt install -f ./filename.deb (as superuser)"
  },
  {
    "objectID": "episodes/installation.html#install-rstudio-on-windows",
    "href": "episodes/installation.html#install-rstudio-on-windows",
    "title": "Installing R and RStudio on Linux",
    "section": "Install RStudio on Windows",
    "text": "Install RStudio on Windows\nStep – 1: With R-base installed, let’s move on to installing RStudio. To begin, go to download RStudio and click on the download button for the RStudio desktop.\nStep – 2: Click on the link for the Windows version of RStudio and save the .exe file.\nStep – 3: Run the .exe and follow the installation instructions.\n- 3.a. Click Next on the welcome window. - 3.b. Enter/browse the path to the installation folder and click Next to proceed. - 3.c. Select the folder for the start menu shortcut, click on Do not Create shortcuts, and click Next. - 3.d. Wait for the installation process to complete. - 3.e. Click Finish to end the installation."
  },
  {
    "objectID": "episodes/installation.html#install-r-on-mac",
    "href": "episodes/installation.html#install-r-on-mac",
    "title": "Installing R and RStudio on Linux",
    "section": "Install R on Mac",
    "text": "Install R on Mac\nStep – 1: Go to CRAN R Project Website.\nStep – 2: Click the Download for (Mac) OS X link.\nStep – 3: Click on the link for the pkg file of the latest R version and save it.\nStep – 4: Double-click the downloaded file and follow the installation instructions."
  },
  {
    "objectID": "episodes/installation.html#install-rstudio-on-mac-os-x",
    "href": "episodes/installation.html#install-rstudio-on-mac-os-x",
    "title": "Installing R and RStudio on Linux",
    "section": "Install RStudio on Mac OS X",
    "text": "Install RStudio on Mac OS X\nStep – 1: With the r-base installed, you must install RStudio. To do that, go to download RStudio and click on the download button for the RStudio desktop.\nStep – 2: Click on the link for the Mac OS X version of RStudio and save the .dmg file.\nStep – 3: Double-click the downloaded file and then drag and drop it into your applications folder."
  },
  {
    "objectID": "episodes/03-dplyr.html",
    "href": "episodes/03-dplyr.html",
    "title": "Data Wrangling with dplyr",
    "section": "",
    "text": "This lesson works better if you have graphics demonstrating dplyr commands. You can modify this Google Slides deck and use it for your workshop.\nFor this lesson make sure that learners are comfortable using pipes.\nThere is also sometimes some confusion on what the arguments of group_by should be, and when to use filter() and select().\ndplyr is a package for making tabular data wrangling easier by using a limited set of functions that can be combined to extract and summarize insights from your data.\nLike readr, dplyr is a part of the tidyverse. These packages were loaded in R’s memory when we called library(tidyverse) earlier."
  },
  {
    "objectID": "episodes/03-dplyr.html#what-is-an-r-package",
    "href": "episodes/03-dplyr.html#what-is-an-r-package",
    "title": "Data Wrangling with dplyr",
    "section": "What is an R package?",
    "text": "What is an R package?\nThe package dplyr provides easy tools for the most common data wrangling tasks. It is built to work directly with dataframes, with many common tasks optimized by being written in a compiled language (C++) (not all R packages are written in R!).\nThere are also packages available for a wide range of tasks including building plots (ggplot2, which we’ll see later), downloading data from the NCBI database, or performing statistical analysis on your data set. Many packages such as these are housed on, and downloadable from, the Comprehensive R Archive Network (CRAN) using install.packages. This function makes the package accessible by your R installation with the command library(), as you did with tidyverse earlier.\nTo easily access the documentation for a package within R or RStudio, use help(package = \"package_name\").\nTo learn more about dplyr after the workshop, you may want to check out this handy data transformation with dplyr cheatsheet.\n\n\n\n\n\n\nNoneNote\n\n\n\nThere are alternatives to the tidyverse packages for data wrangling, including the package data.table. See this comparison for example to get a sense of the differences between using base, tidyverse, and data.table."
  },
  {
    "objectID": "episodes/03-dplyr.html#learning-dplyr",
    "href": "episodes/03-dplyr.html#learning-dplyr",
    "title": "Data Wrangling with dplyr",
    "section": "Learning dplyr",
    "text": "Learning dplyr\nTo make sure everyone will use the same dataset for this lesson, we’ll read again the SAFI dataset that we downloaded earlier.\n\n## load the tidyverse\nlibrary(tidyverse)\nlibrary(here)\n\ninterviews &lt;- read_csv(here(\"data\", \"SAFI_clean.csv\"), na = \"NULL\")\n\n## inspect the data\ninterviews\n\n## preview the data\n# view(interviews)\n\nWe’re going to learn some of the most common dplyr functions:\n\nselect(): subset columns\nfilter(): subset rows on conditions\nmutate(): create new columns by using information from other columns\ngroup_by() and summarize(): create summary statistics on grouped data\narrange(): sort results\ncount(): count discrete values"
  },
  {
    "objectID": "episodes/03-dplyr.html#selecting-columns-and-filtering-rows",
    "href": "episodes/03-dplyr.html#selecting-columns-and-filtering-rows",
    "title": "Data Wrangling with dplyr",
    "section": "Selecting columns and filtering rows",
    "text": "Selecting columns and filtering rows\nTo select columns of a dataframe, use select(). The first argument to this function is the dataframe (interviews), and the subsequent arguments are the columns to keep, separated by commas. Alternatively, if you are selecting columns adjacent to each other, you can use a : to select a range of columns, read as “select columns from ___ to ___.” You may have done something similar in the past using subsetting. select() is essentially doing the same thing as subsetting, using a package (dplyr) instead of R’s base functions.\n\n# to select columns throughout the dataframe\nselect(interviews, village, no_membrs, months_lack_food)\n# to do the same thing with subsetting\ninterviews[c(\"village\",\"no_membrs\",\"months_lack_food\")]\n# to select a series of connected columns\nselect(interviews, village:respondent_wall_type)\n\nTo choose rows based on specific criteria, we can use the filter() function. The argument after the dataframe is the condition we want our final dataframe to adhere to (e.g. village name is Chirodzo):\n\n# filters observations where village name is \"Chirodzo\"\nfilter(interviews, village == \"Chirodzo\")\n\n# A tibble: 39 × 14\n   key_ID village  interview_date      no_membrs years_liv respondent_wall_type\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n 1      8 Chirodzo 2016-11-16 00:00:00        12        70 burntbricks         \n 2      9 Chirodzo 2016-11-16 00:00:00         8         6 burntbricks         \n 3     10 Chirodzo 2016-12-16 00:00:00        12        23 burntbricks         \n 4     34 Chirodzo 2016-11-17 00:00:00         8        18 burntbricks         \n 5     35 Chirodzo 2016-11-17 00:00:00         5        45 muddaub             \n 6     36 Chirodzo 2016-11-17 00:00:00         6        23 sunbricks           \n 7     37 Chirodzo 2016-11-17 00:00:00         3         8 burntbricks         \n 8     43 Chirodzo 2016-11-17 00:00:00         7        29 muddaub             \n 9     44 Chirodzo 2016-11-17 00:00:00         2         6 muddaub             \n10     45 Chirodzo 2016-11-17 00:00:00         9         7 muddaub             \n# ℹ 29 more rows\n# ℹ 8 more variables: rooms &lt;dbl&gt;, memb_assoc &lt;chr&gt;, affect_conflicts &lt;chr&gt;,\n#   liv_count &lt;dbl&gt;, items_owned &lt;chr&gt;, no_meals &lt;dbl&gt;, months_lack_food &lt;chr&gt;,\n#   instanceID &lt;chr&gt;\n\n\nYou may also have noticed that the output from these call doesn’t run off the screen anymore. It’s one of the advantages of tbl_df (also called tibble), the central data class in the tidyverse, compared to normal dataframes in R.\nWe can also specify multiple conditions within the filter() function. We can combine conditions using either “and” or “or” statements. In an “and” statement, an observation (row) must meet every criteria to be included in the resulting dataframe. To form “and” statements within dplyr, we can pass our desired conditions as arguments in the filter() function, separated by commas:\n\n# filters observations with \"and\" operator (comma)\n# output dataframe satisfies ALL specified conditions\nfilter(interviews, village == \"Chirodzo\",\n                   rooms &gt; 1,\n                   no_meals &gt; 2)\n\n# A tibble: 10 × 14\n   key_ID village  interview_date      no_membrs years_liv respondent_wall_type\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n 1     10 Chirodzo 2016-12-16 00:00:00        12        23 burntbricks         \n 2     49 Chirodzo 2016-11-16 00:00:00         6        26 burntbricks         \n 3     52 Chirodzo 2016-11-16 00:00:00        11        15 burntbricks         \n 4     56 Chirodzo 2016-11-16 00:00:00        12        23 burntbricks         \n 5     65 Chirodzo 2016-11-16 00:00:00         8        20 burntbricks         \n 6     66 Chirodzo 2016-11-16 00:00:00        10        37 burntbricks         \n 7     67 Chirodzo 2016-11-16 00:00:00         5        31 burntbricks         \n 8     68 Chirodzo 2016-11-16 00:00:00         8        52 burntbricks         \n 9    199 Chirodzo 2017-06-04 00:00:00         7        17 burntbricks         \n10    200 Chirodzo 2017-06-04 00:00:00         8        20 burntbricks         \n# ℹ 8 more variables: rooms &lt;dbl&gt;, memb_assoc &lt;chr&gt;, affect_conflicts &lt;chr&gt;,\n#   liv_count &lt;dbl&gt;, items_owned &lt;chr&gt;, no_meals &lt;dbl&gt;, months_lack_food &lt;chr&gt;,\n#   instanceID &lt;chr&gt;\n\n\nWe can also form “and” statements with the & operator instead of commas:\n\n# filters observations with \"&\" logical operator\n# output dataframe satisfies ALL specified conditions\nfilter(interviews, village == \"Chirodzo\" &\n                   rooms &gt; 1 &\n                   no_meals &gt; 2)\n\n# A tibble: 10 × 14\n   key_ID village  interview_date      no_membrs years_liv respondent_wall_type\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n 1     10 Chirodzo 2016-12-16 00:00:00        12        23 burntbricks         \n 2     49 Chirodzo 2016-11-16 00:00:00         6        26 burntbricks         \n 3     52 Chirodzo 2016-11-16 00:00:00        11        15 burntbricks         \n 4     56 Chirodzo 2016-11-16 00:00:00        12        23 burntbricks         \n 5     65 Chirodzo 2016-11-16 00:00:00         8        20 burntbricks         \n 6     66 Chirodzo 2016-11-16 00:00:00        10        37 burntbricks         \n 7     67 Chirodzo 2016-11-16 00:00:00         5        31 burntbricks         \n 8     68 Chirodzo 2016-11-16 00:00:00         8        52 burntbricks         \n 9    199 Chirodzo 2017-06-04 00:00:00         7        17 burntbricks         \n10    200 Chirodzo 2017-06-04 00:00:00         8        20 burntbricks         \n# ℹ 8 more variables: rooms &lt;dbl&gt;, memb_assoc &lt;chr&gt;, affect_conflicts &lt;chr&gt;,\n#   liv_count &lt;dbl&gt;, items_owned &lt;chr&gt;, no_meals &lt;dbl&gt;, months_lack_food &lt;chr&gt;,\n#   instanceID &lt;chr&gt;\n\n\nIn an “or” statement, observations must meet at least one of the specified conditions. To form “or” statements we use the logical operator for “or,” which is the vertical bar (|):\n\n# filters observations with \"|\" logical operator\n# output dataframe satisfies AT LEAST ONE of the specified conditions\nfilter(interviews, village == \"Chirodzo\" | village == \"Ruaca\")\n\n# A tibble: 88 × 14\n   key_ID village  interview_date      no_membrs years_liv respondent_wall_type\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n 1      8 Chirodzo 2016-11-16 00:00:00        12        70 burntbricks         \n 2      9 Chirodzo 2016-11-16 00:00:00         8         6 burntbricks         \n 3     10 Chirodzo 2016-12-16 00:00:00        12        23 burntbricks         \n 4     23 Ruaca    2016-11-21 00:00:00        10        20 burntbricks         \n 5     24 Ruaca    2016-11-21 00:00:00         6         4 burntbricks         \n 6     25 Ruaca    2016-11-21 00:00:00        11         6 burntbricks         \n 7     26 Ruaca    2016-11-21 00:00:00         3        20 burntbricks         \n 8     27 Ruaca    2016-11-21 00:00:00         7        36 burntbricks         \n 9     28 Ruaca    2016-11-21 00:00:00         2         2 muddaub             \n10     29 Ruaca    2016-11-21 00:00:00         7        10 burntbricks         \n# ℹ 78 more rows\n# ℹ 8 more variables: rooms &lt;dbl&gt;, memb_assoc &lt;chr&gt;, affect_conflicts &lt;chr&gt;,\n#   liv_count &lt;dbl&gt;, items_owned &lt;chr&gt;, no_meals &lt;dbl&gt;, months_lack_food &lt;chr&gt;,\n#   instanceID &lt;chr&gt;"
  },
  {
    "objectID": "episodes/03-dplyr.html#pipes",
    "href": "episodes/03-dplyr.html#pipes",
    "title": "Data Wrangling with dplyr",
    "section": "Pipes",
    "text": "Pipes\nWhat if you want to select and filter at the same time? There are three ways to do this: use intermediate steps, nested functions, or pipes.\nWith intermediate steps, you create a temporary dataframe and use that as input to the next function, like this:\n\ninterviews2 &lt;- filter(interviews, village == \"Chirodzo\")\ninterviews_ch &lt;- select(interviews2, village:respondent_wall_type)\n\nThis is readable, but can clutter up your workspace with lots of objects that you have to name individually. With multiple steps, that can be hard to keep track of.\nYou can also nest functions (i.e. one function inside of another), like this:\n\ninterviews_ch &lt;- select(filter(interviews, village == \"Chirodzo\"),\n                         village:respondent_wall_type)\n\nThis is handy, but can be difficult to read if too many functions are nested, as R evaluates the expression from the inside out (in this case, filtering, then selecting).\nThe last option, pipes, are a recent addition to R. Pipes let you take the output of one function and send it directly to the next, which is useful when you need to do many things to the same dataset. There are two Pipes in R: 1) %&gt;% (called magrittr pipe; made available via the magrittr package, installed automatically with dplyr) or 2) |&gt; (called native R pipe and it comes preinstalled with R v4.1.0 onwards). Both the pipes are, by and large, function similarly with a few differences (For more information, check: https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/). The choice of which pipe to be used can be changed in the Global settings in R studio and once that is done, you can type the pipe with:\n\nCtrl + Shift + M if you have a PC or Cmd + Shift + M if you have a Mac.\n\n\n# the following example is run using magrittr pipe but the output will be same with the native pipe\ninterviews %&gt;%\n    filter(village == \"Chirodzo\") %&gt;%\n    select(village:respondent_wall_type)\n\n# A tibble: 39 × 5\n   village  interview_date      no_membrs years_liv respondent_wall_type\n   &lt;chr&gt;    &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n 1 Chirodzo 2016-11-16 00:00:00        12        70 burntbricks         \n 2 Chirodzo 2016-11-16 00:00:00         8         6 burntbricks         \n 3 Chirodzo 2016-12-16 00:00:00        12        23 burntbricks         \n 4 Chirodzo 2016-11-17 00:00:00         8        18 burntbricks         \n 5 Chirodzo 2016-11-17 00:00:00         5        45 muddaub             \n 6 Chirodzo 2016-11-17 00:00:00         6        23 sunbricks           \n 7 Chirodzo 2016-11-17 00:00:00         3         8 burntbricks         \n 8 Chirodzo 2016-11-17 00:00:00         7        29 muddaub             \n 9 Chirodzo 2016-11-17 00:00:00         2         6 muddaub             \n10 Chirodzo 2016-11-17 00:00:00         9         7 muddaub             \n# ℹ 29 more rows\n\n#interviews |&gt;\n#   filter(village == \"Chirodzo\") |&gt;\n#   select(village:respondent_wall_type)\n\nIn the above code, we use the pipe to send the interviews dataset first through filter() to keep rows where village is “Chirodzo”, then through select() to keep only the columns from village to respondent_wall_type. Since %&gt;% takes the object on its left and passes it as the first argument to the function on its right, we don’t need to explicitly include the dataframe as an argument to the filter() and select() functions any more.\nSome may find it helpful to read the pipe like the word “then”. For instance, in the above example, we take the dataframe interviews, then we filter for rows with village == \"Chirodzo\", then we select columns village:respondent_wall_type. The dplyr functions by themselves are somewhat simple, but by combining them into linear workflows with the pipe, we can accomplish more complex data wrangling operations.\nIf we want to create a new object with this smaller version of the data, we can assign it a new name:\n\ninterviews_ch &lt;- interviews %&gt;%\n    filter(village == \"Chirodzo\") %&gt;%\n    select(village:respondent_wall_type)\n\ninterviews_ch\n\n# A tibble: 39 × 5\n   village  interview_date      no_membrs years_liv respondent_wall_type\n   &lt;chr&gt;    &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n 1 Chirodzo 2016-11-16 00:00:00        12        70 burntbricks         \n 2 Chirodzo 2016-11-16 00:00:00         8         6 burntbricks         \n 3 Chirodzo 2016-12-16 00:00:00        12        23 burntbricks         \n 4 Chirodzo 2016-11-17 00:00:00         8        18 burntbricks         \n 5 Chirodzo 2016-11-17 00:00:00         5        45 muddaub             \n 6 Chirodzo 2016-11-17 00:00:00         6        23 sunbricks           \n 7 Chirodzo 2016-11-17 00:00:00         3         8 burntbricks         \n 8 Chirodzo 2016-11-17 00:00:00         7        29 muddaub             \n 9 Chirodzo 2016-11-17 00:00:00         2         6 muddaub             \n10 Chirodzo 2016-11-17 00:00:00         9         7 muddaub             \n# ℹ 29 more rows\n\n\nNote that the final dataframe (interviews_ch) is the leftmost part of this expression."
  },
  {
    "objectID": "episodes/03-dplyr.html#exercise",
    "href": "episodes/03-dplyr.html#exercise",
    "title": "Data Wrangling with dplyr",
    "section": "Exercise",
    "text": "Exercise\nUsing pipes, subset the interviews data to include interviews where respondents were members of an irrigation association (memb_assoc) and retain only the columns affect_conflicts, liv_count, and no_meals.\n\nSolution (Solution). \n\ninterviews %&gt;%\n    filter(memb_assoc == \"yes\") %&gt;%\n    select(affect_conflicts, liv_count, no_meals)\n\n# A tibble: 33 × 3\n   affect_conflicts liv_count no_meals\n   &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;\n 1 once                     3        2\n 2 never                    2        2\n 3 never                    2        3\n 4 once                     3        2\n 5 frequently               1        3\n 6 more_once                5        2\n 7 more_once                3        2\n 8 more_once                2        3\n 9 once                     3        3\n10 never                    3        3\n# ℹ 23 more rows"
  },
  {
    "objectID": "episodes/03-dplyr.html#mutate",
    "href": "episodes/03-dplyr.html#mutate",
    "title": "Data Wrangling with dplyr",
    "section": "Mutate",
    "text": "Mutate\nFrequently you’ll want to create new columns based on the values in existing columns, for example to do unit conversions, or to find the ratio of values in two columns. For this we’ll use mutate().\nWe might be interested in the ratio of number of household members to rooms used for sleeping (i.e. avg number of people per room):\n\ninterviews %&gt;%\n    mutate(people_per_room = no_membrs / rooms)\n\n# A tibble: 131 × 15\n   key_ID village  interview_date      no_membrs years_liv respondent_wall_type\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n 1      1 God      2016-11-17 00:00:00         3         4 muddaub             \n 2      2 God      2016-11-17 00:00:00         7         9 muddaub             \n 3      3 God      2016-11-17 00:00:00        10        15 burntbricks         \n 4      4 God      2016-11-17 00:00:00         7         6 burntbricks         \n 5      5 God      2016-11-17 00:00:00         7        40 burntbricks         \n 6      6 God      2016-11-17 00:00:00         3         3 muddaub             \n 7      7 God      2016-11-17 00:00:00         6        38 muddaub             \n 8      8 Chirodzo 2016-11-16 00:00:00        12        70 burntbricks         \n 9      9 Chirodzo 2016-11-16 00:00:00         8         6 burntbricks         \n10     10 Chirodzo 2016-12-16 00:00:00        12        23 burntbricks         \n# ℹ 121 more rows\n# ℹ 9 more variables: rooms &lt;dbl&gt;, memb_assoc &lt;chr&gt;, affect_conflicts &lt;chr&gt;,\n#   liv_count &lt;dbl&gt;, items_owned &lt;chr&gt;, no_meals &lt;dbl&gt;, months_lack_food &lt;chr&gt;,\n#   instanceID &lt;chr&gt;, people_per_room &lt;dbl&gt;\n\n\nWe may be interested in investigating whether being a member of an irrigation association had any effect on the ratio of household members to rooms. To look at this relationship, we will first remove data from our dataset where the respondent didn’t answer the question of whether they were a member of an irrigation association. These cases are recorded as “NULL” in the dataset.\nTo remove these cases, we could insert a filter() in the chain:\n\ninterviews %&gt;%\n    filter(!is.na(memb_assoc)) %&gt;%\n    mutate(people_per_room = no_membrs / rooms)\n\n# A tibble: 92 × 15\n   key_ID village  interview_date      no_membrs years_liv respondent_wall_type\n    &lt;dbl&gt; &lt;chr&gt;    &lt;dttm&gt;                  &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;               \n 1      2 God      2016-11-17 00:00:00         7         9 muddaub             \n 2      7 God      2016-11-17 00:00:00         6        38 muddaub             \n 3      8 Chirodzo 2016-11-16 00:00:00        12        70 burntbricks         \n 4      9 Chirodzo 2016-11-16 00:00:00         8         6 burntbricks         \n 5     10 Chirodzo 2016-12-16 00:00:00        12        23 burntbricks         \n 6     12 God      2016-11-21 00:00:00         7        20 burntbricks         \n 7     13 God      2016-11-21 00:00:00         6         8 burntbricks         \n 8     15 God      2016-11-21 00:00:00         5        30 sunbricks           \n 9     21 God      2016-11-21 00:00:00         8        20 burntbricks         \n10     24 Ruaca    2016-11-21 00:00:00         6         4 burntbricks         \n# ℹ 82 more rows\n# ℹ 9 more variables: rooms &lt;dbl&gt;, memb_assoc &lt;chr&gt;, affect_conflicts &lt;chr&gt;,\n#   liv_count &lt;dbl&gt;, items_owned &lt;chr&gt;, no_meals &lt;dbl&gt;, months_lack_food &lt;chr&gt;,\n#   instanceID &lt;chr&gt;, people_per_room &lt;dbl&gt;\n\n\nThe ! symbol negates the result of the is.na() function. Thus, if is.na() returns a value of TRUE (because the memb_assoc is missing), the ! symbol negates this and says we only want values of FALSE, where memb_assoc is not missing."
  },
  {
    "objectID": "episodes/03-dplyr.html#exercise-1",
    "href": "episodes/03-dplyr.html#exercise-1",
    "title": "Data Wrangling with dplyr",
    "section": "Exercise",
    "text": "Exercise\nCreate a new dataframe from the interviews data that meets the following criteria: contains only the village column and a new column called total_meals containing a value that is equal to the total number of meals served in the household per day on average (no_membrs times no_meals). Only the rows where total_meals is greater than 20 should be shown in the final dataframe.\nHint: think about how the commands should be ordered to produce this data frame!\n\nSolution (Solution). \n\ninterviews_total_meals &lt;- interviews %&gt;%\n    mutate(total_meals = no_membrs * no_meals) %&gt;%\n    filter(total_meals &gt; 20) %&gt;%\n    select(village, total_meals)"
  },
  {
    "objectID": "episodes/03-dplyr.html#split-apply-combine-data-analysis-and-the-summarize-function",
    "href": "episodes/03-dplyr.html#split-apply-combine-data-analysis-and-the-summarize-function",
    "title": "Data Wrangling with dplyr",
    "section": "Split-apply-combine data analysis and the summarize() function",
    "text": "Split-apply-combine data analysis and the summarize() function\nMany data analysis tasks can be approached using the split-apply-combine paradigm: split the data into groups, apply some analysis to each group, and then combine the results. dplyr makes this very easy through the use of the group_by() function.\n\nThe summarize() function\ngroup_by() is often used together with summarize(), which collapses each group into a single-row summary of that group. group_by() takes as arguments the column names that contain the categorical variables for which you want to calculate the summary statistics. So to compute the average household size by village:\n\ninterviews %&gt;%\n    group_by(village) %&gt;%\n    summarize(mean_no_membrs = mean(no_membrs))\n\n# A tibble: 3 × 2\n  village  mean_no_membrs\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Chirodzo           7.08\n2 God                6.86\n3 Ruaca              7.57\n\n\nYou can also group by multiple columns:\n\ninterviews %&gt;%\n    group_by(village, memb_assoc) %&gt;%\n    summarize(mean_no_membrs = mean(no_membrs))\n\n`summarise()` has grouped output by 'village'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 9 × 3\n# Groups:   village [3]\n  village  memb_assoc mean_no_membrs\n  &lt;chr&gt;    &lt;chr&gt;               &lt;dbl&gt;\n1 Chirodzo no                   8.06\n2 Chirodzo yes                  7.82\n3 Chirodzo &lt;NA&gt;                 5.08\n4 God      no                   7.13\n5 God      yes                  8   \n6 God      &lt;NA&gt;                 6   \n7 Ruaca    no                   7.18\n8 Ruaca    yes                  9.5 \n9 Ruaca    &lt;NA&gt;                 6.22\n\n\nNote that the output is a grouped tibble of nine rows by three columns which is indicated by the by two first lines with the #. To obtain an ungrouped tibble, use the ungroup function:\n\ninterviews %&gt;%\n    group_by(village, memb_assoc) %&gt;%\n    summarize(mean_no_membrs = mean(no_membrs)) %&gt;%\n    ungroup()\n\n`summarise()` has grouped output by 'village'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 9 × 3\n  village  memb_assoc mean_no_membrs\n  &lt;chr&gt;    &lt;chr&gt;               &lt;dbl&gt;\n1 Chirodzo no                   8.06\n2 Chirodzo yes                  7.82\n3 Chirodzo &lt;NA&gt;                 5.08\n4 God      no                   7.13\n5 God      yes                  8   \n6 God      &lt;NA&gt;                 6   \n7 Ruaca    no                   7.18\n8 Ruaca    yes                  9.5 \n9 Ruaca    &lt;NA&gt;                 6.22\n\n\nNotice that the second line with the # that previously indicated the grouping has disappeared and we now only have a 9x3-tibble without grouping. When grouping both by village and membr_assoc, we see rows in our table for respondents who did not specify whether they were a member of an irrigation association. We can exclude those data from our table using a filter step.\n\ninterviews %&gt;%\n    filter(!is.na(memb_assoc)) %&gt;%\n    group_by(village, memb_assoc) %&gt;%\n    summarize(mean_no_membrs = mean(no_membrs))\n\n`summarise()` has grouped output by 'village'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 6 × 3\n# Groups:   village [3]\n  village  memb_assoc mean_no_membrs\n  &lt;chr&gt;    &lt;chr&gt;               &lt;dbl&gt;\n1 Chirodzo no                   8.06\n2 Chirodzo yes                  7.82\n3 God      no                   7.13\n4 God      yes                  8   \n5 Ruaca    no                   7.18\n6 Ruaca    yes                  9.5 \n\n\nOnce the data are grouped, you can also summarize multiple variables at the same time (and not necessarily on the same variable). For instance, we could add a column indicating the minimum household size for each village for each group (members of an irrigation association vs not):\n\ninterviews %&gt;%\n    filter(!is.na(memb_assoc)) %&gt;%\n    group_by(village, memb_assoc) %&gt;%\n    summarize(mean_no_membrs = mean(no_membrs),\n              min_membrs = min(no_membrs))\n\n`summarise()` has grouped output by 'village'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 6 × 4\n# Groups:   village [3]\n  village  memb_assoc mean_no_membrs min_membrs\n  &lt;chr&gt;    &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;\n1 Chirodzo no                   8.06          4\n2 Chirodzo yes                  7.82          2\n3 God      no                   7.13          3\n4 God      yes                  8             5\n5 Ruaca    no                   7.18          2\n6 Ruaca    yes                  9.5           5\n\n\nIt is sometimes useful to rearrange the result of a query to inspect the values. For instance, we can sort on min_membrs to put the group with the smallest household first:\n\ninterviews %&gt;%\n    filter(!is.na(memb_assoc)) %&gt;%\n    group_by(village, memb_assoc) %&gt;%\n    summarize(mean_no_membrs = mean(no_membrs),\n              min_membrs = min(no_membrs)) %&gt;%\n    arrange(min_membrs)\n\n`summarise()` has grouped output by 'village'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 6 × 4\n# Groups:   village [3]\n  village  memb_assoc mean_no_membrs min_membrs\n  &lt;chr&gt;    &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;\n1 Chirodzo yes                  7.82          2\n2 Ruaca    no                   7.18          2\n3 God      no                   7.13          3\n4 Chirodzo no                   8.06          4\n5 God      yes                  8             5\n6 Ruaca    yes                  9.5           5\n\n\nTo sort in descending order, we need to add the desc() function. If we want to sort the results by decreasing order of minimum household size:\n\ninterviews %&gt;%\n    filter(!is.na(memb_assoc)) %&gt;%\n    group_by(village, memb_assoc) %&gt;%\n    summarize(mean_no_membrs = mean(no_membrs),\n              min_membrs = min(no_membrs)) %&gt;%\n    arrange(desc(min_membrs))\n\n`summarise()` has grouped output by 'village'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 6 × 4\n# Groups:   village [3]\n  village  memb_assoc mean_no_membrs min_membrs\n  &lt;chr&gt;    &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;\n1 God      yes                  8             5\n2 Ruaca    yes                  9.5           5\n3 Chirodzo no                   8.06          4\n4 God      no                   7.13          3\n5 Chirodzo yes                  7.82          2\n6 Ruaca    no                   7.18          2\n\n\n\n\nCounting\nWhen working with data, we often want to know the number of observations found for each factor or combination of factors. For this task, dplyr provides count(). For example, if we wanted to count the number of rows of data for each village, we would do:\n\ninterviews %&gt;%\n    count(village)\n\n# A tibble: 3 × 2\n  village      n\n  &lt;chr&gt;    &lt;int&gt;\n1 Chirodzo    39\n2 God         43\n3 Ruaca       49\n\n\nFor convenience, count() provides the sort argument to get results in decreasing order:\n\ninterviews %&gt;%\n    count(village, sort = TRUE)\n\n# A tibble: 3 × 2\n  village      n\n  &lt;chr&gt;    &lt;int&gt;\n1 Ruaca       49\n2 God         43\n3 Chirodzo    39"
  },
  {
    "objectID": "episodes/03-dplyr.html#exercise-2",
    "href": "episodes/03-dplyr.html#exercise-2",
    "title": "Data Wrangling with dplyr",
    "section": "Exercise",
    "text": "Exercise\nHow many households in the survey have an average of two meals per day? Three meals per day? Are there any other numbers of meals represented?\n\nSolution (Solution). \n\ninterviews %&gt;%\n   count(no_meals)\n\n# A tibble: 2 × 2\n  no_meals     n\n     &lt;dbl&gt; &lt;int&gt;\n1        2    52\n2        3    79\n\n\n\nUse group_by() and summarize() to find the mean, min, and max number of household members for each village. Also add the number of observations (hint: see ?n).\n\nSolution (Solution). \n\ninterviews %&gt;%\n  group_by(village) %&gt;%\n  summarize(\n      mean_no_membrs = mean(no_membrs),\n      min_no_membrs = min(no_membrs),\n      max_no_membrs = max(no_membrs),\n      n = n()\n  )\n\n# A tibble: 3 × 5\n  village  mean_no_membrs min_no_membrs max_no_membrs     n\n  &lt;chr&gt;             &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;\n1 Chirodzo           7.08             2            12    39\n2 God                6.86             3            15    43\n3 Ruaca              7.57             2            19    49\n\n\n\nWhat was the largest household interviewed in each month?\n\nSolution (Solution). \n\n# if not already included, add month, year, and day columns\nlibrary(lubridate) # load lubridate if not already loaded\ninterviews %&gt;%\n    mutate(month = month(interview_date),\n           day = day(interview_date),\n           year = year(interview_date)) %&gt;%\n    group_by(year, month) %&gt;%\n    summarize(max_no_membrs = max(no_membrs))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 × 3\n# Groups:   year [2]\n   year month max_no_membrs\n  &lt;dbl&gt; &lt;dbl&gt;         &lt;dbl&gt;\n1  2016    11            19\n2  2016    12            12\n3  2017     4            17\n4  2017     5            15\n5  2017     6            15"
  },
  {
    "objectID": "episodes/01-intro-to-r.html",
    "href": "episodes/01-intro-to-r.html",
    "title": "Introduction to R",
    "section": "",
    "text": "The main goal is to introduce users to the various objects in R, from atomic types to creating your own objects.\nWhile this epsiode is foundational, be careful not to get caught in the weeds as the variety of types and operations can be overwhelming for new users, especially before they understand how this fits into their own “workflow.”\nNow that we have learned how to write scripts, and the basics of R’s data structures, we are ready to start working with the SAFI dataset we have been using in the other lessons, and learn about data frames."
  },
  {
    "objectID": "episodes/01-intro-to-r.html#creating-objects-in-r",
    "href": "episodes/01-intro-to-r.html#creating-objects-in-r",
    "title": "Introduction to R",
    "section": "Creating objects in R",
    "text": "Creating objects in R\nYou can get output from R simply by typing math in the console:\n\n3 + 5\n\n[1] 8\n\n12 / 7\n\n[1] 1.714286\n\n\nEverything that exists in R is an objects: from simple numerical values, to strings, to more complex objects like vectors, matrices, and lists. Even expressions and functions are objects in R.\nHowever, to do useful and interesting things, we need to name objects. To do so, we need to give a name followed by the assignment operator &lt;-, and the object we want to be named:\n\narea_hectares &lt;- 1.0\n\n&lt;- is the assignment operator. It assigns values (objects) on the right to names (also called symbols) on the left. So, after executing x &lt;- 3, the value of x is 3. The arrow can be read as 3 goes into x. For historical reasons, you can also use = for assignments, but not in every context. Because of the slight differences in syntax, it is good practice to always use &lt;- for assignments. More generally we prefer the &lt;- syntax over = because it makes it clear what direction the assignment is operating (left assignment), and it increases the read-ability of the code.\nIn RStudio, typing Alt + - (push Alt at the same time as the - key) will write &lt;- in a single keystroke in a PC, while typing Option + - (push Option at the same time as the - key) does the same in a Mac.\nObjects can be given any name such as x, current_temperature, or subject_id. You want your object names to be explicit and not too long. They cannot start with a number (2x is not valid, but x2 is). R is case sensitive (e.g., age is different from Age). There are some names that cannot be used because they are the names of fundamental objects in R (e.g., if, else, for, see here for a complete list). In general, even if it’s allowed, it’s best to not use them (e.g., c, T, mean, data, df, weights). If in doubt, check the help to see if the name is already in use. It’s also best to avoid dots (.) within an object name as in my.dataset. There are many objects in R with dots in their names for historical reasons, but because dots have a special meaning in R (for methods) and other programming languages, it’s best to avoid them. The recommended writing style is called snake_case, which implies using only lowercaseletters and numbers and separating each word with underscores (e.g., animals_weight, average_income). It is also recommended to use nouns for object names, and verbs for function names. It’s important to be consistent in the styling of your code (where you put spaces, how you name objects, etc.). Using a consistent coding style makes your code clearer to read for your future self and your collaborators. In R, three popular style guides are Google’s, Jean Fan’s and the tidyverse’s. The tidyverse’s is very comprehensive and may seem overwhelming at first. You can install the lintr package to automatically check for issues in the styling of your code.\n\n\n\n\n\n\nNoneObjects vs. variables\n\n\n\nThe naming of objects in R is somehow related to variables in many other programming languages. In many programming languages, a variable has three aspects: a name, a memory location, and the current value stored in this location. R abstracts from modifiable memory locations. In R we only have objects which cn be named. Depending on the context, name (of an object) and variable can have drastically different meanings. However, in this lesson, the two words are used synonymously. For more information see: https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Objects\n\n\nWhen assigning an value to a name, R does not print anything. You can force R to print the value by using parentheses or by typing the object name:\n\narea_hectares &lt;- 1.0    # doesn't print anything\n(area_hectares &lt;- 1.0)  # putting parenthesis around the call prints the value of `area_hectares`\n\n[1] 1\n\narea_hectares         # and so does typing the name of the object\n\n[1] 1\n\n\nNow that R has area_hectares in memory, we can do arithmetic with it. For instance, we may want to convert this area into acres (area in acres is 2.47 times the area in hectares):\n\n2.47 * area_hectares\n\n[1] 2.47\n\n\nWe can also change an the value assigned to an name by assigning it a new one:\n\narea_hectares &lt;- 2.5\n2.47 * area_hectares\n\n[1] 6.175\n\n\nThis means that assigning a value to one name does not change the values of other names. For example, let’s name the plot’s area in acres area_acres:\n\narea_acres &lt;- 2.47 * area_hectares\n\nand then change (reassign) area_hectares to 50.\n\narea_hectares &lt;- 50"
  },
  {
    "objectID": "episodes/01-intro-to-r.html#exercise",
    "href": "episodes/01-intro-to-r.html#exercise",
    "title": "Introduction to R",
    "section": "Exercise",
    "text": "Exercise\nWhat do you think is the current value of area_acres? 123.5 or 6.175?\n\nSolution (Solution). The value of area_acres is still 6.175 because you have not re-run the line area_acres &lt;- 2.47 * area_hectares since changing the value of area_hectares."
  },
  {
    "objectID": "episodes/01-intro-to-r.html#comments",
    "href": "episodes/01-intro-to-r.html#comments",
    "title": "Introduction to R",
    "section": "Comments",
    "text": "Comments\nAll programming languages allow the programmer to include comments in their code. Including comments to your code has many advantages: it helps you explain your reasoning and it forces you to be tidy. A commented code is also a great tool not only to your collaborators, but to your future self. Comments are the key to a reproducible analysis.\nTo do this in R we use the # character. Anything to the right of the # sign and up to the end of the line is treated as a comment and is ignored by R. You can start lines with comments or include them after any code on the line.\n\narea_hectares &lt;- 1.0            # land area in hectares\narea_acres &lt;- area_hectares * 2.47  # convert to acres\narea_acres              # print land area in acres.\n\n[1] 2.47\n\n\nRStudio makes it easy to comment or uncomment a paragraph: after selecting the lines you want to comment, press at the same time on your keyboard Ctrl + Shift + C. If you only want to comment out one line, you can put the cursor at any location of that line (i.e. no need to select the whole line), then press Ctrl + Shift + C."
  },
  {
    "objectID": "episodes/01-intro-to-r.html#exercise-1",
    "href": "episodes/01-intro-to-r.html#exercise-1",
    "title": "Introduction to R",
    "section": "Exercise",
    "text": "Exercise\nCreate two variables r_length and r_width and assign them values. It should be noted that, because length is a built-in R function, R Studio might add “()” after you type length and if you leave the parentheses you will get unexpected results. This is why you might see other programmers abbreviate common words. Create a third variable r_area and give it a value based on the current values of r_length and r_width. Show that changing the values of either r_length and r_width does not affect the value of r_area.\n\nSolution (Solution). \n\nr_length &lt;- 2.5\nr_width &lt;- 3.2\nr_area &lt;- r_length * r_width\nr_area\n\n[1] 8\n\n# change the values of r_length and r_width\nr_length &lt;- 7.0\nr_width &lt;- 6.5\n# the value of r_area isn't changed\nr_area\n\n[1] 8"
  },
  {
    "objectID": "episodes/01-intro-to-r.html#exercise-2",
    "href": "episodes/01-intro-to-r.html#exercise-2",
    "title": "Introduction to R",
    "section": "Exercise",
    "text": "Exercise\nType in ?round at the console and then look at the output in the Help pane. What other functions exist that are similar to round? How do you use the digits parameter in the round function?"
  },
  {
    "objectID": "episodes/01-intro-to-r.html#vectors-and-data-types",
    "href": "episodes/01-intro-to-r.html#vectors-and-data-types",
    "title": "Introduction to R",
    "section": "Vectors and data types",
    "text": "Vectors and data types\nA vector is the most common and basic data type in R, and is pretty much the workhorse of R. A vector is composed by a series of values, which can be either numbers or characters. We can assign a series of values to a vector using the c() function. For example we can create a vector of the number of household members for the households we’ve interviewed and assign it to hh_members:\n\nhh_members &lt;- c(3, 7, 10, 6)\nhh_members\n\n[1]  3  7 10  6\n\n\nA vector can also contain characters. For example, we can have a vector of the building material used to construct our interview respondents’ walls (respondent_wall_type):\n\nrespondent_wall_type &lt;- c(\"muddaub\", \"burntbricks\", \"sunbricks\")\nrespondent_wall_type\n\n[1] \"muddaub\"     \"burntbricks\" \"sunbricks\"  \n\n\nThe quotes around “muddaub”, etc. are essential here. Without the quotes R will assume there are objects called muddaub, burntbricks and sunbricks. As these names don’t exist in R’s memory, there will be an error message.\nThere are many functions that allow you to inspect the content of a vector. length() tells you how many elements are in a particular vector:\n\nlength(hh_members)\n\n[1] 4\n\nlength(respondent_wall_type)\n\n[1] 3\n\n\nAn important feature of a vector, is that all of the elements are the same type of data. The function typeof() indicates the type of an object:\n\ntypeof(hh_members)\n\n[1] \"double\"\n\ntypeof(respondent_wall_type)\n\n[1] \"character\"\n\n\nThe function str() provides an overview of the structure of an object and its elements. It is a useful function when working with large and complex objects:\n\nstr(hh_members)\n\n num [1:4] 3 7 10 6\n\nstr(respondent_wall_type)\n\n chr [1:3] \"muddaub\" \"burntbricks\" \"sunbricks\"\n\n\nYou can use the c() function to add other elements to your vector:\n\npossessions &lt;- c(\"bicycle\", \"radio\", \"television\")\npossessions &lt;- c(possessions, \"mobile_phone\") # add to the end of the vector\npossessions &lt;- c(\"car\", possessions) # add to the beginning of the vector\npossessions\n\n[1] \"car\"          \"bicycle\"      \"radio\"        \"television\"   \"mobile_phone\"\n\n\nIn the first line, we take the original vector possessions, add the value \"mobile_phone\" to the end of it, and save the result back into possessions. Then we add the value \"car\" to the beginning, again saving the result back into possessions.\nWe can do this over and over again to grow a vector, or assemble a dataset. As we program, this may be useful to add results that we are collecting or calculating.\nAn atomic vector is the simplest R data type and is a linear vector of a single type. Above, we saw 2 of the 6 main atomic vector types that R uses: \"character\" and \"numeric\" (or \"double\"). These are the basic building blocks that all R objects are built from. The other 4 atomic vector types are:\n\n\"logical\" for TRUE and FALSE (the boolean data type)\n\"integer\" for integer numbers (e.g., 2L, the L indicates to R that it’s an integer)\n\"complex\" to represent complex numbers with real and imaginary parts (e.g., 1 + 4i) and that’s all we’re going to say about them\n\"raw\" for bitstreams that we won’t discuss further\n\nYou can check the type of your vector using the typeof() function and inputting your vector as the argument.\nVectors are one of the many data structures that R uses. Other important ones are lists (list), matrices (matrix), data frames (data.frame), factors (factor) and arrays (array)."
  },
  {
    "objectID": "episodes/01-intro-to-r.html#exercise-3",
    "href": "episodes/01-intro-to-r.html#exercise-3",
    "title": "Introduction to R",
    "section": "Exercise",
    "text": "Exercise\nWe’ve seen that atomic vectors can be of type character, numeric (or double), integer, and logical. But what happens if we try to mix these types in a single vector?\n\nSolution (Solution). R implicitly converts them to all be the same type.\n\nWhat will happen in each of these examples? (hint: use class() to check the data type of your objects):\n\nnum_char &lt;- c(1, 2, 3, \"a\")\nnum_logical &lt;- c(1, 2, 3, TRUE)\nchar_logical &lt;- c(\"a\", \"b\", \"c\", TRUE)\ntricky &lt;- c(1, 2, 3, \"4\")\n\nWhy do you think it happens?\n\nSolution (Solution). Vectors can be of only one data type. R tries to convert (coerce) the content of this vector to find a “common denominator” that doesn’t lose any information.\n\nHow many values in combined_logical are \"TRUE\" (as a character) in the following example:\n\nnum_logical &lt;- c(1, 2, 3, TRUE)\nchar_logical &lt;- c(\"a\", \"b\", \"c\", TRUE)\ncombined_logical &lt;- c(num_logical, char_logical)\n\n\nSolution (Solution). Only one. There is no memory of past data types, and the coercion happens the first time the vector is evaluated. Therefore, the TRUE in num_logical gets converted into a 1 before it gets converted into \"1\" in combined_logical.\n\nYou’ve probably noticed that objects of different types get converted into a single, shared type within a vector. In R, we call converting objects from one class into another class coercion. These conversions happen according to a hierarchy, whereby some types get preferentially coerced into other types. Can you draw a diagram that represents the hierarchy of how these data types are coerced?"
  },
  {
    "objectID": "episodes/01-intro-to-r.html#subsetting-vectors",
    "href": "episodes/01-intro-to-r.html#subsetting-vectors",
    "title": "Introduction to R",
    "section": "Subsetting vectors",
    "text": "Subsetting vectors\nSubsetting (sometimes referred to as extracting or indexing) involves accessing out one or more values based on their numeric placement or “index” within a vector. If we want to subset one or several values from a vector, we must provide one index or several indices in square brackets. For instance:\n\nrespondent_wall_type &lt;- c(\"muddaub\", \"burntbricks\", \"sunbricks\")\nrespondent_wall_type[2]\n\n[1] \"burntbricks\"\n\nrespondent_wall_type[c(3, 2)]\n\n[1] \"sunbricks\"   \"burntbricks\"\n\n\nWe can also repeat the indices to create an object with more elements than the original one:\n\nmore_respondent_wall_type &lt;- respondent_wall_type[c(1, 2, 3, 2, 1, 3)]\nmore_respondent_wall_type\n\n[1] \"muddaub\"     \"burntbricks\" \"sunbricks\"   \"burntbricks\" \"muddaub\"    \n[6] \"sunbricks\"  \n\n\nR indices start at 1. Programming languages like Fortran, MATLAB, Julia, and R start counting at 1, because that’s what human beings typically do. Languages in the C family (including C++, Java, Perl, and Python) count from 0 because that’s simpler for computers to do.\n\nConditional subsetting\nAnother common way of subsetting is by using a logical vector. TRUE will select the element with the same index, while FALSE will not:\n\nhh_members &lt;- c(3, 7, 10, 6)\nhh_members[c(TRUE, FALSE, TRUE, TRUE)]\n\n[1]  3 10  6\n\n\nTypically, these logical vectors are not typed by hand, but are the output of other functions or logical tests. For instance, if you wanted to select only the values above 5:\n\nhh_members &gt; 5    # will return logicals with TRUE for the indices that meet the condition\n\n[1] FALSE  TRUE  TRUE  TRUE\n\n## so we can use this to select only the values above 5\nhh_members[hh_members &gt; 5]\n\n[1]  7 10  6\n\n\nYou can combine multiple tests using & (both conditions are true, AND) or | (at least one of the conditions is true, OR):\n\nhh_members[hh_members &lt; 4 | hh_members &gt; 7]\n\n[1]  3 10\n\nhh_members[hh_members &gt;= 4 & hh_members &lt;= 7]\n\n[1] 7 6\n\n\nHere, &lt; stands for “less than”, &gt; for “greater than”, &gt;= for “greater than or equal to”, and == for “equal to”. The double equal sign == is a test for numerical equality between the left and right hand sides, and should not be confused with the single = sign, which performs variable assignment (similar to &lt;-).\nA common task is to search for certain strings in a vector. One could use the “or” operator | to test for equality to multiple values, but this can quickly become tedious.\n\npossessions &lt;- c(\"car\", \"bicycle\", \"radio\", \"television\", \"mobile_phone\")\npossessions[possessions == \"car\" | possessions == \"bicycle\"] # returns both car and bicycle\n\n[1] \"car\"     \"bicycle\"\n\n\nThe function %in% allows you to test if any of the elements of a search vector (on the left hand side) are found in the target vector (on the right hand side):\n\npossessions %in% c(\"car\", \"bicycle\")\n\n[1]  TRUE  TRUE FALSE FALSE FALSE\n\n\nNote that the output is the same length as the search vector on the left hand side, because %in% checks whether each element of the search vector is found somewhere in the target vector. Thus, you can use %in% to select the elements in the search vector that appear in your target vector:\n\npossessions %in% c(\"car\", \"bicycle\", \"motorcycle\", \"truck\", \"boat\", \"bus\")\n\n[1]  TRUE  TRUE FALSE FALSE FALSE\n\npossessions[possessions %in% c(\"car\", \"bicycle\", \"motorcycle\", \"truck\", \"boat\", \"bus\")]\n\n[1] \"car\"     \"bicycle\""
  },
  {
    "objectID": "episodes/01-intro-to-r.html#missing-data",
    "href": "episodes/01-intro-to-r.html#missing-data",
    "title": "Introduction to R",
    "section": "Missing data",
    "text": "Missing data\nAs R was designed to analyze datasets, it includes the concept of missing data (which is uncommon in other programming languages). Missing data are represented in vectors as NA.\nWhen doing operations on numbers, most functions will return NA if the data you are working with include missing values. This feature makes it harder to overlook the cases where you are dealing with missing data. You can add the argument na.rm=TRUE to calculate the result while ignoring the missing values.\n\nrooms &lt;- c(2, 1, 1, NA, 7)\nmean(rooms)\n\n[1] NA\n\nmax(rooms)\n\n[1] NA\n\nmean(rooms, na.rm = TRUE)\n\n[1] 2.75\n\nmax(rooms, na.rm = TRUE)\n\n[1] 7\n\n\nIf your data include missing values, you may want to become familiar with the functions is.na(), na.omit(), and complete.cases(). See below for examples.\n\n## Extract those elements which are not missing values.\n## The ! character is also called the NOT operator\nrooms[!is.na(rooms)]\n\n[1] 2 1 1 7\n\n## Count the number of missing values.\n## The output of is.na() is a logical vector (TRUE/FALSE equivalent to 1/0) so the sum() function here is effectively counting\nsum(is.na(rooms))\n\n[1] 1\n\n## Returns the object with incomplete cases removed. The returned object is an atomic vector of type `\"numeric\"` (or `\"double\"`).\nna.omit(rooms)\n\n[1] 2 1 1 7\nattr(,\"na.action\")\n[1] 4\nattr(,\"class\")\n[1] \"omit\"\n\n## Extract those elements which are complete cases. The returned object is an atomic vector of type `\"numeric\"` (or `\"double\"`).\nrooms[complete.cases(rooms)]\n\n[1] 2 1 1 7\n\n\nRecall that you can use the typeof() function to find the type of your atomic vector."
  },
  {
    "objectID": "episodes/01-intro-to-r.html#exercise-4",
    "href": "episodes/01-intro-to-r.html#exercise-4",
    "title": "Introduction to R",
    "section": "Exercise",
    "text": "Exercise\n\nUsing this vector of rooms, create a new vector with the NAs removed.\n\nrooms &lt;- c(1, 2, 1, 1, NA, 3, 1, 3, 2, 1, 1, 8, 3, 1, NA, 1)\n\nUse the function median() to calculate the median of the rooms vector.\nUse R to figure out how many households in the set use more than 2 rooms for sleeping.\n\n\nSolution (Solution). \n\nrooms &lt;- c(1, 2, 1, 1, NA, 3, 1, 3, 2, 1, 1, 8, 3, 1, NA, 1)\nrooms_no_na &lt;- rooms[!is.na(rooms)]\n# or\nrooms_no_na &lt;- na.omit(rooms)\n# 2.\nmedian(rooms, na.rm = TRUE)\n\n[1] 1\n\n# 3.\nrooms_above_2 &lt;- rooms_no_na[rooms_no_na &gt; 2]\nlength(rooms_above_2)\n\n[1] 4"
  },
  {
    "objectID": "episodes/07-json.html",
    "href": "episodes/07-json.html",
    "title": "Processing JSON data (Optional)",
    "section": "",
    "text": "This is an optional lessons intended to introduce learners to JSON data, as well as how to read JSON data into R and how to convert the data into a data frame or array.\nNote that his lesson was community-contributed and remains a work in progress. As such, it could benefit from feedback from instructors and/or workshop participants."
  },
  {
    "objectID": "episodes/07-json.html#the-json-data-format",
    "href": "episodes/07-json.html#the-json-data-format",
    "title": "Processing JSON data (Optional)",
    "section": "The JSON data format",
    "text": "The JSON data format\nThe JSON data format was designed as a way of allowing different machines or processes within machines to communicate with each other by sending messages constructed in a well defined format. JSON is now the preferred data format used by APIs (Application Programming Interfaces).\nThe JSON format although somewhat verbose is not only Human readable but it can also be mapped very easily to an R dataframe.\nWe are going to read a file of data formatted as JSON, convert it into a dataframe in R then selectively create a csv file from the extracted data.\nThe JSON file we are going to use is the SAFI.json file. This is the output file from an electronic survey system called ODK. The JSON represents the answers to a series of survey questions. The questions themselves have been replaced with unique Keys, the values are the answers.\nBecause detailed surveys are by nature nested structures making it possible to record different levels of detail or selectively ask a set of specific questions based on the answer given to a previous question, the structure of the answers for the survey can not only be complex and convoluted, it could easily be different from one survey respondent’s set of answers to another.\n\nAdvantages of JSON\n\nVery popular data format for APIs (e.g. results from an Internet search)\nHuman readable\nEach record (or document as they are called) is self contained. The equivalent of the column name and column values are in every record.\nDocuments do not all have to have the same structure within the same file\nDocument structures can be complex and nested\n\n\n\nDisadvantages of JSON\n\nIt is more verbose than the equivalent data in csv format\nCan be more difficult to process and display than csv formatted data"
  },
  {
    "objectID": "episodes/07-json.html#use-the-json-package-to-read-a-json-file",
    "href": "episodes/07-json.html#use-the-json-package-to-read-a-json-file",
    "title": "Processing JSON data (Optional)",
    "section": "Use the JSON package to read a JSON file",
    "text": "Use the JSON package to read a JSON file\n\nlibrary(jsonlite)\n\nAs with reading in a CSV, you have a couple of options for how to access the JSON file.\nYou can read the JSON file directly into R with read_json() or the comparable fromJSON() function, though this does not download the file.\n\njson_data &lt;- read_json(\n  \"https://raw.githubusercontent.com/datacarpentry/r-socialsci/main/episodes/data/SAFI.json\"\n  )\n\nTo download the file you can copy and paste the contents of the file on GitHub, creating a SAFI.json file in your data directory, or you can download the file with R.\n\ndownload.file(\n  \"https://raw.githubusercontent.com/datacarpentry/r-socialsci/main/episodes/data/SAFI.json\",\n   \"data/SAFI.json\", mode = \"wb\")\n\nOnce you have the data downloaded, you can read it into R with read_json():\n\njson_data &lt;- read_json(\"data/SAFI.json\")\n\nWe can see that a new object called json_data has appeared in our Environment. It is described as a Large list (131 elements). In this current form, our data is messy. You can have a glimpse of it with the head() or view() functions. It will look not much more structured than if you were to open the JSON file with a text editor.\nThis is because, by default, the read_json() function’s parameter simplifyVector, which specifies whether or not to simplify vectors is set to FALSE. This means that the default setting does not simplify nested lists into vectors and data frames. However, we can set this to TRUE, and our data will be read directly as a dataframe:\n\njson_data &lt;- read_json(\"data/SAFI.json\", simplifyVector = TRUE)\n\nNow we can see we have this json data in a dataframe format. For consistency with the rest of the lesson, let’s coerce it to be a tibble and use glimpse to take a peek inside (these functions were loaded by library(tidyverse)):\n\njson_data &lt;- json_data %&gt;% as_tibble()\nglimpse(json_data)\n\nRows: 131\nColumns: 74\n$ C06_rooms                      &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 3, 1, 5, 1, 3, 1, …\n$ B19_grand_liv                  &lt;chr&gt; \"no\", \"yes\", \"no\", \"no\", \"yes\", \"no\", \"…\n$ A08_ward                       &lt;chr&gt; \"ward2\", \"ward2\", \"ward2\", \"ward2\", \"wa…\n$ E01_water_use                  &lt;chr&gt; \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"y…\n$ B18_sp_parents_liv             &lt;chr&gt; \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"…\n$ B16_years_liv                  &lt;int&gt; 4, 9, 15, 6, 40, 3, 38, 70, 6, 23, 20, …\n$ E_yes_group_count              &lt;chr&gt; NA, \"3\", NA, NA, NA, NA, \"4\", \"2\", \"3\",…\n$ F_liv                          &lt;list&gt; [&lt;data.frame[1 x 2]&gt;], [&lt;data.frame[3 …\n$ `_note2`                       &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ instanceID                     &lt;chr&gt; \"uuid:ec241f2c-0609-46ed-b5e8-fe575f6ce…\n$ B20_sp_grand_liv               &lt;chr&gt; \"yes\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"…\n$ F10_liv_owned_other            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ `_note1`                       &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ F12_poultry                    &lt;chr&gt; \"yes\", \"yes\", \"yes\", \"yes\", \"yes\", \"no\"…\n$ D_plots_count                  &lt;chr&gt; \"2\", \"3\", \"1\", \"3\", \"2\", \"1\", \"4\", \"2\",…\n$ C02_respondent_wall_type_other &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ C02_respondent_wall_type       &lt;chr&gt; \"muddaub\", \"muddaub\", \"burntbricks\", \"b…\n$ C05_buildings_in_compound      &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, …\n$ `_remitters`                   &lt;list&gt; [&lt;data.frame[0 x 0]&gt;], [&lt;data.frame[0 …\n$ E18_months_no_water            &lt;list&gt; &lt;NULL&gt;, &lt;\"Aug\", \"Sept\"&gt;, &lt;NULL&gt;, &lt;NULL…\n$ F07_use_income                 &lt;chr&gt; NA, \"AlimentaÃ§Ã£o e pagamento de educa…\n$ G01_no_meals                   &lt;int&gt; 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 2, 3, 2, …\n$ E17_no_enough_water            &lt;chr&gt; NA, \"yes\", NA, NA, NA, NA, \"yes\", \"yes\"…\n$ F04_need_money                 &lt;chr&gt; NA, \"no\", NA, NA, NA, NA, \"no\", \"no\", \"…\n$ A05_end                        &lt;chr&gt; \"2017-04-02T17:29:08.000Z\", \"2017-04-02…\n$ C04_window_type                &lt;chr&gt; \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\", \"n…\n$ E21_other_meth                 &lt;chr&gt; NA, \"no\", NA, NA, NA, NA, \"no\", \"no\", \"…\n$ D_no_plots                     &lt;int&gt; 2, 3, 1, 3, 2, 1, 4, 2, 3, 2, 2, 2, 4, …\n$ F05_money_source               &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;…\n$ A07_district                   &lt;chr&gt; \"district1\", \"district1\", \"district1\", …\n$ C03_respondent_floor_type      &lt;chr&gt; \"earth\", \"earth\", \"cement\", \"earth\", \"e…\n$ E_yes_group                    &lt;list&gt; [&lt;data.frame[0 x 0]&gt;], [&lt;data.frame[3 …\n$ A01_interview_date             &lt;chr&gt; \"2016-11-17\", \"2016-11-17\", \"2016-11-17…\n$ B11_remittance_money           &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no…\n$ A04_start                      &lt;chr&gt; \"2017-03-23T09:49:57.000Z\", \"2017-04-02…\n$ D_plots                        &lt;list&gt; [&lt;data.frame[2 x 8]&gt;], [&lt;data.frame[3 …\n$ F_items                        &lt;list&gt; [&lt;data.frame[3 x 3]&gt;], [&lt;data.frame[2 …\n$ F_liv_count                    &lt;chr&gt; \"1\", \"3\", \"1\", \"2\", \"4\", \"1\", \"1\", \"2\",…\n$ F10_liv_owned                  &lt;list&gt; \"poultry\", &lt;\"oxen\", \"cows\", \"goats\"&gt;, …\n$ B_no_membrs                    &lt;int&gt; 3, 7, 10, 7, 7, 3, 6, 12, 8, 12, 6, 7, …\n$ F13_du_look_aftr_cows          &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no…\n$ E26_affect_conflicts           &lt;chr&gt; NA, \"once\", NA, NA, NA, NA, \"never\", \"n…\n$ F14_items_owned                &lt;list&gt; &lt;\"bicycle\", \"television\", \"solar_panel…\n$ F06_crops_contr                &lt;chr&gt; NA, \"more_half\", NA, NA, NA, NA, \"more_…\n$ B17_parents_liv                &lt;chr&gt; \"no\", \"yes\", \"no\", \"no\", \"yes\", \"no\", \"…\n$ G02_months_lack_food           &lt;list&gt; \"Jan\", &lt;\"Jan\", \"Sept\", \"Oct\", \"Nov\", \"…\n$ A11_years_farm                 &lt;dbl&gt; 11, 2, 40, 6, 18, 3, 20, 16, 16, 22, 6,…\n$ F09_du_labour                  &lt;chr&gt; \"no\", \"no\", \"yes\", \"yes\", \"no\", \"yes\", …\n$ E_no_group_count               &lt;chr&gt; \"2\", NA, \"1\", \"3\", \"2\", \"1\", NA, NA, NA…\n$ E22_res_change                 &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;…\n$ E24_resp_assoc                 &lt;chr&gt; NA, \"no\", NA, NA, NA, NA, NA, \"yes\", NA…\n$ A03_quest_no                   &lt;chr&gt; \"01\", \"01\", \"03\", \"04\", \"05\", \"6\", \"7\",…\n$ `_members`                     &lt;list&gt; [&lt;data.frame[3 x 12]&gt;], [&lt;data.frame[7…\n$ A06_province                   &lt;chr&gt; \"province1\", \"province1\", \"province1\", …\n$ `gps:Accuracy`                 &lt;dbl&gt; 14, 19, 13, 5, 10, 12, 11, 9, 11, 14, 1…\n$ E20_exper_other                &lt;chr&gt; NA, \"yes\", NA, NA, NA, NA, \"yes\", \"yes\"…\n$ A09_village                    &lt;chr&gt; \"village2\", \"village2\", \"village2\", \"vi…\n$ C01_respondent_roof_type       &lt;chr&gt; \"grass\", \"grass\", \"mabatisloping\", \"mab…\n$ `gps:Altitude`                 &lt;dbl&gt; 698, 690, 674, 679, 689, 692, 709, 700,…\n$ `gps:Longitude`                &lt;dbl&gt; 33.48346, 33.48342, 33.48345, 33.48342,…\n$ E23_memb_assoc                 &lt;chr&gt; NA, \"yes\", NA, NA, NA, NA, \"no\", \"yes\",…\n$ E19_period_use                 &lt;dbl&gt; NA, 2, NA, NA, NA, NA, 10, 10, 6, 22, N…\n$ E25_fees_water                 &lt;chr&gt; NA, \"no\", NA, NA, NA, NA, \"no\", \"no\", \"…\n$ C07_other_buildings            &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"ye…\n$ observation                    &lt;chr&gt; \"None\", \"Estes primeiros inquÃ©ritos na…\n$ `_note`                        &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ A12_agr_assoc                  &lt;chr&gt; \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"n…\n$ G03_no_food_mitigation         &lt;list&gt; &lt;\"na\", \"rely_less_food\", \"reduce_meals…\n$ F05_money_source_other         &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ `gps:Latitude`                 &lt;dbl&gt; -19.11226, -19.11248, -19.11211, -19.11…\n$ E_no_group                     &lt;list&gt; [&lt;data.frame[2 x 6]&gt;], [&lt;data.frame[0 …\n$ F14_items_owned_other          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ F08_emply_lab                  &lt;chr&gt; \"no\", \"yes\", \"no\", \"no\", \"no\", \"no\", \"n…\n$ `_members_count`               &lt;chr&gt; \"3\", \"7\", \"10\", \"7\", \"7\", \"3\", \"6\", \"12…\n\n\nLooking good, but you might notice that actually we have a variable, F_liv that is a list of dataframes! It is very important to know what you are expecting from your data to be able to look for things like this. For example, if you are getting your JSON from an API, have a look at the API documentation, so you know what to look for.\nOften when we have a very large number of columns, it can become difficult to determine all the variables which may require some special attention, like lists. Fortunately, we can use special verbs like where to quickly select all the list columns.\n\njson_data %&gt;%\n    select(where(is.list)) %&gt;%\n    glimpse()\n\nRows: 131\nColumns: 14\n$ F_liv                  &lt;list&gt; [&lt;data.frame[1 x 2]&gt;], [&lt;data.frame[3 x 2]&gt;], …\n$ `_remitters`           &lt;list&gt; [&lt;data.frame[0 x 0]&gt;], [&lt;data.frame[0 x 0]&gt;], …\n$ E18_months_no_water    &lt;list&gt; &lt;NULL&gt;, &lt;\"Aug\", \"Sept\"&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL…\n$ F05_money_source       &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;…\n$ E_yes_group            &lt;list&gt; [&lt;data.frame[0 x 0]&gt;], [&lt;data.frame[3 x 14]&gt;],…\n$ D_plots                &lt;list&gt; [&lt;data.frame[2 x 8]&gt;], [&lt;data.frame[3 x 8]&gt;], …\n$ F_items                &lt;list&gt; [&lt;data.frame[3 x 3]&gt;], [&lt;data.frame[2 x 3]&gt;], …\n$ F10_liv_owned          &lt;list&gt; \"poultry\", &lt;\"oxen\", \"cows\", \"goats\"&gt;, \"none\", …\n$ F14_items_owned        &lt;list&gt; &lt;\"bicycle\", \"television\", \"solar_panel\", \"tabl…\n$ G02_months_lack_food   &lt;list&gt; \"Jan\", &lt;\"Jan\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"&gt;, &lt;…\n$ E22_res_change         &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;…\n$ `_members`             &lt;list&gt; [&lt;data.frame[3 x 12]&gt;], [&lt;data.frame[7 x 12]&gt;]…\n$ G03_no_food_mitigation &lt;list&gt; &lt;\"na\", \"rely_less_food\", \"reduce_meals\", \"day_…\n$ E_no_group             &lt;list&gt; [&lt;data.frame[2 x 6]&gt;], [&lt;data.frame[0 x 0]&gt;], …\n\n\nSo what can we do about F_liv, the column of dataframes? Well first things first, we can access each one. For example to access the dataframe in the first row, we can use the bracket ([) subsetting. Here we use single bracket, but you could also use double bracket ([[). The [[ form allows only a single element to be selected using integer or character indices, whereas [ allows indexing by vectors.\n\njson_data$F_liv[1]\n\n[[1]]\n  F11_no_owned F_curr_liv\n1            1    poultry\n\n\nWe can also choose to view the nested dataframes at all the rows of our main dataframe where a particular condition is met (for example where the value for the variable C06_rooms is equal to 4):\n\njson_data$F_liv[which(json_data$C06_rooms == 4)]\n\n[[1]]\n  F11_no_owned F_curr_liv\n1            3       oxen\n2            2       cows\n3            5      goats\n\n[[2]]\n  F11_no_owned F_curr_liv\n1            4       oxen\n2            5       cows\n3            3      goats\n\n[[3]]\ndata frame with 0 columns and 0 rows\n\n[[4]]\n  F11_no_owned F_curr_liv\n1            4       oxen\n2            4       cows\n3            4      goats\n4            1      sheep\n\n[[5]]\n  F11_no_owned F_curr_liv\n1            2       cows"
  },
  {
    "objectID": "episodes/07-json.html#write-the-json-file-to-csv",
    "href": "episodes/07-json.html#write-the-json-file-to-csv",
    "title": "Processing JSON data (Optional)",
    "section": "Write the JSON file to csv",
    "text": "Write the JSON file to csv\nIf we try to write our json_data dataframe to a csv as we would usually in a regular dataframe, we won’t get the desired result. Using the write_csv function from the {readr} package won’t give you an error for list columns, but you’ll only see missing (i.e. NA) values in these columns. Let’s try it out to confirm:\n\nwrite_csv(json_data, \"json_data_with_list_columns.csv\")\nread_csv(\"json_data_with_list_columns.csv\")\n\nTo write out as a csv while maintaining the data within the list columns, we will need to “flatten” these columns. One way to do this is to convert these list columns into character types. (However, we don’t want to change the data types for any of the other columns). Here’s one way to do this using tidyverse. This command only applies the as.character command to those columns ‘where’ is.list is TRUE.\n\nflattened_json_data &lt;- json_data %&gt;% \n  mutate(across(where(is.list), as.character))\nflattened_json_data\n\n# A tibble: 131 × 74\n   C06_rooms B19_grand_liv A08_ward E01_water_use B18_sp_parents_liv\n       &lt;int&gt; &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;             \n 1         1 no            ward2    no            yes               \n 2         1 yes           ward2    yes           yes               \n 3         1 no            ward2    no            no                \n 4         1 no            ward2    no            no                \n 5         1 yes           ward2    no            no                \n 6         1 no            ward2    no            no                \n 7         1 yes           ward2    yes           no                \n 8         3 yes           ward1    yes           yes               \n 9         1 yes           ward2    yes           no                \n10         5 no            ward2    yes           no                \n# ℹ 121 more rows\n# ℹ 69 more variables: B16_years_liv &lt;int&gt;, E_yes_group_count &lt;chr&gt;,\n#   F_liv &lt;chr&gt;, `_note2` &lt;lgl&gt;, instanceID &lt;chr&gt;, B20_sp_grand_liv &lt;chr&gt;,\n#   F10_liv_owned_other &lt;lgl&gt;, `_note1` &lt;lgl&gt;, F12_poultry &lt;chr&gt;,\n#   D_plots_count &lt;chr&gt;, C02_respondent_wall_type_other &lt;lgl&gt;,\n#   C02_respondent_wall_type &lt;chr&gt;, C05_buildings_in_compound &lt;int&gt;,\n#   `_remitters` &lt;chr&gt;, E18_months_no_water &lt;chr&gt;, F07_use_income &lt;chr&gt;, …\n\n\nNow you can write this to a csv file:\n\nwrite_csv(flattened_json_data, \"data_output/json_data_with_flattened_list_columns.csv\")\n\nNote: this means that when you read this csv back into R, the column of the nested dataframes will now be read in as a character vector. Converting it back to list to extract elements might be complicated, so it is probably better to keep storing these data in a JSON format if you will have to do this.\nYou can also write out the individual nested dataframes to a csv. For example:\n\nwrite_csv(json_data$F_liv[[1]], \"data_output/F_liv_row1.csv\")\n\n\n\nJSON is a popular data format for transferring data used by a great many Web based APIs\nThe complex structure of a JSON document means that it cannot easily be ‘flattened’ into tabular data\nWe can use R code to extract values of interest and place them in a csv file"
  },
  {
    "objectID": "episodes/00-intro.html",
    "href": "episodes/00-intro.html",
    "title": "Before we Start",
    "section": "",
    "text": "The main goal here is to help the learners be comfortable with the RStudio interface.\nGo very slowly in the “Getting set up” section. Make sure everyone is following along (remind learners to use the stickies). Plan with the helpers at this point to go around the room, and be available to help. It’s important to make sure that learners are in the correct working directory, and that they create a data (all lowercase) subfolder.\nBecause the install process accesses the CRAN repository, you will need an Internet connection to install packages.\nIt is also possible to install packages from other repositories, as well as Github or the local file system, but we won’t be looking at these options in this lesson."
  },
  {
    "objectID": "episodes/00-intro.html#what-is-r-what-is-rstudio",
    "href": "episodes/00-intro.html#what-is-r-what-is-rstudio",
    "title": "Before we Start",
    "section": "What is R? What is RStudio?",
    "text": "What is R? What is RStudio?\nThe term “R” is used to refer to both the programming language and the software that interprets the scripts written using it.\nRStudio is currently a very popular way to not only write your R scripts but also to interact with the R software. To function correctly, RStudio needs R and therefore both need to be installed on your computer.\nTo make it easier to interact with R, we will use RStudio. RStudio is the most popular IDE (Integrated Development Environment) for R. An IDE is a piece of software that provides tools to make programming easier.\nYou can also use the R Presentations feature to present your work in an HTML5 presentation mixing Markdown and R code. You can display these within R Studio or your browser. There are many options for customising your presentation slides, including an option for showing LaTeX equations. This can help you collaborate with others and also has an application in teaching and classroom use."
  },
  {
    "objectID": "episodes/00-intro.html#why-learn-r",
    "href": "episodes/00-intro.html#why-learn-r",
    "title": "Before we Start",
    "section": "Why learn R?",
    "text": "Why learn R?\n\nR does not involve lots of pointing and clicking, and that’s a good thing\nThe learning curve might be steeper than with other software but with R, the results of your analysis do not rely on remembering a succession of pointing and clicking, but instead on a series of written commands, and that’s a good thing! So, if you want to redo your analysis because you collected more data, you don’t have to remember which button you clicked in which order to obtain your results; you just have to run your script again.\nWorking with scripts makes the steps you used in your analysis clear, and the code you write can be inspected by someone else who can give you feedback and spot mistakes.\nWorking with scripts forces you to have a deeper understanding of what you are doing, and facilitates your learning and comprehension of the methods you use.\n\n\nR code is great for reproducibility\nReproducibility is when someone else (including your future self) can obtain the same results from the same dataset when using the same analysis.\nR integrates with other tools to generate manuscripts from your code. If you collect more data, or fix a mistake in your dataset, the figures and the statistical tests in your manuscript are updated automatically.\nAn increasing number of journals and funding agencies expect analyses to be reproducible, so knowing R will give you an edge with these requirements.\nTo further support reproducibility and transparency, there are also packages that help you with dependency management: keeping track of which packages we are loading and how they depend on the package version you are using. This helps you make sure existing workflows work consistently and continue doing what they did before.\nPackages like renv let you “save” and “load” the state of your project library, also keeping track of the package version you use and the source it can be retrieved from.\n\n\nR is interdisciplinary and extensible\nWith 10,000+ packages that can be installed to extend its capabilities, R provides a framework that allows you to combine statistical approaches from many scientific disciplines to best suit the analytical framework you need to analyze your data. For instance, R has packages for image analysis, GIS, time series, population genetics, and a lot more.\n\n\nR works on data of all shapes and sizes\nThe skills you learn with R scale easily with the size of your dataset. Whether your dataset has hundreds or millions of lines, it won’t make much difference to you.\nR is designed for data analysis. It comes with special data structures and data types that make handling of missing data and statistical factors convenient.\nR can connect to spreadsheets, databases, and many other data formats, on your computer or on the web.\n\n\nR produces high-quality graphics\nThe plotting functionalities in R are endless, and allow you to adjust any aspect of your graph to convey most effectively the message from your data.\n\n\nR has a large and welcoming community\nThousands of people use R daily. Many of them are willing to help you through mailing lists and websites such as Stack Overflow, or on the RStudio community. Questions which are backed up with short, reproducible code snippets are more likely to attract knowledgeable responses.\n\n\nNot only is R free, but it is also open-source and cross-platform\nAnyone can inspect the source code to see how R works. Because of this transparency, there is less chance for mistakes, and if you (or someone else) find some, you can report and fix bugs.\nBecause R is open source and is supported by a large community of developers and users, there is a very large selection of third-party add-on packages which are freely available to extend R’s native capabilities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRStudio extends what R can do, and makes it easier to write R code and interact with R. Left photo credit; Right photo credit."
  },
  {
    "objectID": "episodes/00-intro.html#a-tour-of-rstudio",
    "href": "episodes/00-intro.html#a-tour-of-rstudio",
    "title": "Before we Start",
    "section": "A tour of RStudio",
    "text": "A tour of RStudio"
  },
  {
    "objectID": "episodes/00-intro.html#knowing-your-way-around-rstudio",
    "href": "episodes/00-intro.html#knowing-your-way-around-rstudio",
    "title": "Before we Start",
    "section": "Knowing your way around RStudio",
    "text": "Knowing your way around RStudio\nLet’s start by learning about RStudio, which is an Integrated Development Environment (IDE) for working with R.\nThe RStudio IDE open-source product is free under the Affero General Public License (AGPL) v3. The RStudio IDE is also available with a commercial license and priority email support from RStudio, Inc.\nWe will use the RStudio IDE to write code, navigate the files on our computer, inspect the variables we create, and visualize the plots we generate. RStudio can also be used for other things (e.g., version control, developing packages, writing Shiny apps) that we will not cover during the workshop.\nOne of the advantages of using RStudio is that all the information you need to write code is available in a single window. Additionally, RStudio provides many shortcuts, autocompletion, and highlighting for the major file types you use while developing in R. RStudio makes typing easier and less error-prone."
  },
  {
    "objectID": "episodes/00-intro.html#getting-set-up",
    "href": "episodes/00-intro.html#getting-set-up",
    "title": "Before we Start",
    "section": "Getting set up",
    "text": "Getting set up\nIt is good practice to keep a set of related data, analyses, and text self-contained in a single folder called the working directory. All of the scripts within this folder can then use relative paths to files. Relative paths indicate where inside the project a file is located (as opposed to absolute paths, which point to where a file is on a specific computer). Working this way makes it a lot easier to move your project around on your computer and share it with others without having to directly modify file paths in the individual scripts.\nRStudio provides a helpful set of tools to do this through its “Projects” interface, which not only creates a working directory for you but also remembers its location (allowing you to quickly navigate to it). The interface also (optionally) preserves custom settings and open files to make it easier to resume work after a break.\n\nCreate a new project\n\nUnder the File menu, click on New project, choose New directory, then New project\nEnter a name for this new folder (or “directory”) and choose a convenient location for it. This will be your working directory for the rest of the day (e.g., ~/data-carpentry)\nClick on Create project\nCreate a new file where we will type our scripts. Go to File &gt; New File &gt; R script. Click the save icon on your toolbar and save your script as “script.R”.\n\nThe simplest way to open an RStudio project once it has been created is to navigate through your files to where the project was saved and double click on the .Rproj (blue cube) file. This will open RStudio and start your R session in the same directory as the .Rproj file. All your data, plots and scripts will now be relative to the project directory. RStudio projects have the added benefit of allowing you to open multiple projects at the same time each open to its own project directory. This allows you to keep multiple projects open without them interfering with each other.\n\n\nThe RStudio Interface\nLet’s take a quick tour of RStudio.\n\nRStudio is divided into four “panes”. The placement of these panes and their content can be customized (see menu, Tools -&gt; Global Options -&gt; Pane Layout).\nThe Default Layout is:\n\nTop Left - Source: your scripts and documents\nBottom Left - Console: what R would look and be like without RStudio\nTop Right - Environment/History: look here to see what you have done\nBottom Right - Files and more: see the contents of the project/working directory here, like your Script.R file\n\n\n\nOrganizing your working directory\nUsing a consistent folder structure across your projects will help keep things organized and make it easy to find/file things in the future. This can be especially helpful when you have multiple projects. In general, you might create directories (folders) for scripts, data, and documents. Here are some examples of suggested directories:\n\ndata/ Use this folder to store your raw data and intermediate datasets. For the sake of transparency and provenance, you should always keep a copy of your raw data accessible and do as much of your data cleanup and preprocessing programmatically (i.e., with scripts, rather than manually) as possible.\ndata_output/ When you need to modify your raw data, it might be useful to store the modified versions of the datasets in a different folder.\ndocuments/ Used for outlines, drafts, and other text.\nfig_output/ This folder can store the graphics that are generated by your scripts.\nscripts/ A place to keep your R scripts for different analyses or plotting.\n\nYou may want additional directories or subdirectories depending on your project needs, but these should form the backbone of your working directory.\n\n\n\nThe working directory\nThe working directory is an important concept to understand. It is the place where R will look for and save files. When you write code for your project, your scripts should refer to files in relation to the root of your working directory and only to files within this structure.\nUsing RStudio projects makes this easy and ensures that your working directory is set up properly. If you need to check it, you can use getwd(). If for some reason your working directory is not the same as the location of your RStudio project, it is likely that you opened an R script or RMarkdown file not your .Rproj file. You should close out of RStudio and open the .Rproj file by double clicking on the blue cube! If you ever need to modify your working directory in a script, setwd('my/path') changes the working directory. This should be used with caution since it makes analyses hard to share across devices and with other users.\n\n\nDownloading the data and getting set up\nFor this lesson we will use the following folders in our working directory: data/, data_output/ and fig_output/. Let’s write them all in lowercase to be consistent. We can create them using the RStudio interface by clicking on the “New Folder” button in the file pane (bottom right), or directly from R by typing at console:\n\ndir.create(\"data\")\ndir.create(\"data_output\")\ndir.create(\"fig_output\")\n\nYou can either download the data used for this lesson from GitHub or with R. You can copy the data from this GitHub link and paste it into a file called SAFI_clean.csv in the data/ directory you just created. Or you can do this directly from R by copying and pasting this in your terminal (your instructor can place this chunk of code in the Etherpad):\n\ndownload.file(\n  \"https://raw.githubusercontent.com/datacarpentry/r-socialsci/main/episodes/data/SAFI_clean.csv\",\n  \"data/SAFI_clean.csv\", mode = \"wb\"\n  )"
  },
  {
    "objectID": "episodes/00-intro.html#interacting-with-r",
    "href": "episodes/00-intro.html#interacting-with-r",
    "title": "Before we Start",
    "section": "Interacting with R",
    "text": "Interacting with R\nThe basis of programming is that we write down instructions for the computer to follow, and then we tell the computer to follow those instructions. We write, or code, instructions in R because it is a common language that both the computer and we can understand. We call the instructions commands and we tell the computer to follow the instructions by executing (also called running) those commands.\nThere are two main ways of interacting with R: by using the console or by using script files (plain text files that contain your code). The console pane (in RStudio, the bottom left panel) is the place where commands written in the R language can be typed and executed immediately by the computer. It is also where the results will be shown for commands that have been executed. You can type commands directly into the console and press Enter to execute those commands, but they will be forgotten when you close the session.\nBecause we want our code and workflow to be reproducible, it is better to type the commands we want in the script editor and save the script. This way, there is a complete record of what we did, and anyone (including our future selves!) can easily replicate the results on their computer.\nRStudio allows you to execute commands directly from the script editor by using the Ctrl + Enter shortcut (on Mac, Cmd + Return will work). The command on the current line in the script (indicated by the cursor) or all of the commands in selected text will be sent to the console and executed when you press Ctrl + Enter. If there is information in the console you do not need anymore, you can clear it with Ctrl + L. You can find other keyboard shortcuts in this RStudio cheatsheet about the RStudio IDE.\nAt some point in your analysis, you may want to check the content of a variable or the structure of an object without necessarily keeping a record of it in your script. You can type these commands and execute them directly in the console. RStudio provides the Ctrl + 1 and Ctrl + 2 shortcuts allow you to jump between the script and the console panes.\nIf R is ready to accept commands, the R console shows a &gt; prompt. If R receives a command (by typing, copy-pasting, or sent from the script editor using Ctrl + Enter), R will try to execute it and, when ready, will show the results and come back with a new &gt; prompt to wait for new commands.\nIf R is still waiting for you to enter more text, the console will show a + prompt. It means that you haven’t finished entering a complete command. This is likely because you have not ‘closed’ a parenthesis or quotation, i.e. you don’t have the same number of left-parentheses as right-parentheses or the same number of opening and closing quotation marks. When this happens, and you thought you finished typing your command, click inside the console window and press Esc; this will cancel the incomplete command and return you to the &gt; prompt. You can then proofread the command(s) you entered and correct the error."
  },
  {
    "objectID": "episodes/00-intro.html#installing-additional-packages-using-the-packages-tab",
    "href": "episodes/00-intro.html#installing-additional-packages-using-the-packages-tab",
    "title": "Before we Start",
    "section": "Installing additional packages using the packages tab",
    "text": "Installing additional packages using the packages tab\nIn addition to the core R installation, there are in excess of 10,000 additional packages which can be used to extend the functionality of R. Many of these have been written by R users and have been made available in central repositories, like the one hosted at CRAN, for anyone to download and install into their own R environment. You should have already installed the packages ‘ggplot2’ and ’dplyr. If you have not, please do so now using these instructions.\nYou can see if you have a package installed by looking in the packages tab (on the lower-right by default). You can also type the command installed.packages() into the console and examine the output.\n\nAdditional packages can be installed from the ‘packages’ tab. On the packages tab, click the ‘Install’ icon and start typing the name of the package you want in the text box. As you type, packages matching your starting characters will be displayed in a drop-down list so that you can select them.\n\nAt the bottom of the Install Packages window is a check box to ‘Install’ dependencies. This is ticked by default, which is usually what you want. Packages can (and do) make use of functionality built into other packages, so for the functionality contained in the package you are installing to work properly, there may be other packages which have to be installed with them. The ‘Install dependencies’ option makes sure that this happens."
  },
  {
    "objectID": "episodes/00-intro.html#exercise",
    "href": "episodes/00-intro.html#exercise",
    "title": "Before we Start",
    "section": "Exercise",
    "text": "Exercise\nUse both the Console and the Packages tab to confirm that you have the tidyverse installed.\n\nSolution (Solution). Scroll through packages tab down to ‘tidyverse’. You can also type a few characters into the searchbox. The ‘tidyverse’ package is really a package of packages, including ‘ggplot2’ and ‘dplyr’, both of which require other packages to run correctly. All of these packages will be installed automatically. Depending on what packages have previously been installed in your R environment, the install of ‘tidyverse’ could be very quick or could take several minutes. As the install proceeds, messages relating to its progress will be written to the console. You will be able to see all of the packages which are actually being installed."
  },
  {
    "objectID": "episodes/00-intro.html#installing-additional-packages-using-r-code",
    "href": "episodes/00-intro.html#installing-additional-packages-using-r-code",
    "title": "Before we Start",
    "section": "Installing additional packages using R code",
    "text": "Installing additional packages using R code\nIf you were watching the console window when you started the install of ‘tidyverse’, you may have noticed that the line\n\ninstall.packages(\"tidyverse\")\n\nwas written to the console before the start of the installation messages.\nYou could also have installed the tidyverse packages by running this command directly at the R terminal.\nWe will be using another package called here throughout the workshop to manage paths and directories. We will discuss it more detail in a later episode, but we will install it now in the console:\n\ninstall.packages(\"here\")\n\n\n\nUse RStudio to write and run R programs.\nUse install.packages() to install packages (libraries)."
  },
  {
    "objectID": "episodes/data-frame.html",
    "href": "episodes/data-frame.html",
    "title": "data frame",
    "section": "",
    "text": "Data Frames\nData Frames are data displayed in a format as a table.\nData Frames can have different types of data inside it. While the first column can be character, the second and third can be numeric or logical. However, each column should have the same type of data.\nUse the data.frame() function to create a data frame:\nExample # Create a data frame\n\nData_Frame &lt;- data.frame (\n  Training = c(\"Strength\", \"Stamina\", \"Other\"),\n  Pulse = c(100, 150, 120),\n  Duration = c(60, 30, 45)\n)\n# Print the data frame\nData_Frame\n\n  Training Pulse Duration\n1 Strength   100       60\n2  Stamina   150       30\n3    Other   120       45\n\n\n\n\nSummarize the Data\nUse the summary() function to summarize the data from a Data Frame:\nExample\n\nData_Frame &lt;- data.frame (\n  Training = c(\"Strength\", \"Stamina\", \"Other\"),\n  Pulse = c(100, 150, 120),\n  Duration = c(60, 30, 45)\n)\n\nData_Frame\n\n  Training Pulse Duration\n1 Strength   100       60\n2  Stamina   150       30\n3    Other   120       45\n\nsummary(Data_Frame)\n\n   Training             Pulse          Duration   \n Length:3           Min.   :100.0   Min.   :30.0  \n Class :character   1st Qu.:110.0   1st Qu.:37.5  \n Mode  :character   Median :120.0   Median :45.0  \n                    Mean   :123.3   Mean   :45.0  \n                    3rd Qu.:135.0   3rd Qu.:52.5  \n                    Max.   :150.0   Max.   :60.0  \n\n\nYou will learn more about the summary() function in the statistical part of the R tutorial.\nAccess Items We can use single brackets [ ], double brackets [[ ]] or $ to access columns from a data frame:\nExample\n\nData_Frame &lt;- data.frame (\n  Training = c(\"Strength\", \"Stamina\", \"Other\"),\n  Pulse = c(100, 150, 120),\n  Duration = c(60, 30, 45)\n)\n\nData_Frame[1]\n\n  Training\n1 Strength\n2  Stamina\n3    Other\n\nData_Frame[[\"Training\"]]\n\n[1] \"Strength\" \"Stamina\"  \"Other\"   \n\nData_Frame$Training\n\n[1] \"Strength\" \"Stamina\"  \"Other\"   \n\n\nAdd Rows Use the rbind() function to add new rows in a Data Frame:\nExample\n\nData_Frame &lt;- data.frame (\n  Training = c(\"Strength\", \"Stamina\", \"Other\"),\n  Pulse = c(100, 150, 120),\n  Duration = c(60, 30, 45)\n)\n\n# Add a new row\nNew_row_DF &lt;- rbind(Data_Frame, c(\"Strength\", 110, 110))\n\n# Print the new row\nNew_row_DF\n\n  Training Pulse Duration\n1 Strength   100       60\n2  Stamina   150       30\n3    Other   120       45\n4 Strength   110      110\n\n\nAdd Columns Use the cbind() function to add new columns in a Data Frame:\nExample\n\nData_Frame &lt;- data.frame (\n  Training = c(\"Strength\", \"Stamina\", \"Other\"),\n  Pulse = c(100, 150, 120),\n  Duration = c(60, 30, 45)\n)\n\n# Add a new column\nNew_col_DF &lt;- cbind(Data_Frame, Steps = c(1000, 6000, 2000))\n\n# Print the new column\nNew_col_DF\n\n  Training Pulse Duration Steps\n1 Strength   100       60  1000\n2  Stamina   150       30  6000\n3    Other   120       45  2000\n\n\nRemove Rows and Columns Use the c() function to remove rows and columns in a Data Frame:\nExample\n\nData_Frame &lt;- data.frame (\n  Training = c(\"Strength\", \"Stamina\", \"Other\"),\n  Pulse = c(100, 150, 120),\n  Duration = c(60, 30, 45)\n)\n\n# Remove the first row and column\nData_Frame_New &lt;- Data_Frame[-c(1), -c(1)]\n\n# Print the new data frame\nData_Frame_New\n\n  Pulse Duration\n2   150       30\n3   120       45\n\n\nAmount of Rows and Columns Use the dim() function to find the amount of rows and columns in a Data Frame:\nExample\n\nData_Frame &lt;- data.frame (\n  Training = c(\"Strength\", \"Stamina\", \"Other\"),\n  Pulse = c(100, 150, 120),\n  Duration = c(60, 30, 45)\n)\n\ndim(Data_Frame)\n\n[1] 3 3\n\n\nYou can also use the ncol() function to find the number of columns and nrow() to find the number of rows:\nExample\n\nData_Frame &lt;- data.frame (\n  Training = c(\"Strength\", \"Stamina\", \"Other\"),\n  Pulse = c(100, 150, 120),\n  Duration = c(60, 30, 45)\n)\n\nncol(Data_Frame)\n\n[1] 3\n\nnrow(Data_Frame)\n\n[1] 3\n\n\nData Frame Length Use the length() function to find the number of columns in a Data Frame (similar to ncol()):\nExample\n\nData_Frame &lt;- data.frame (\n  Training = c(\"Strength\", \"Stamina\", \"Other\"),\n  Pulse = c(100, 150, 120),\n  Duration = c(60, 30, 45)\n)\n\nlength(Data_Frame)\n\n[1] 3\n\n\nCombining Data Frames Use the rbind() function to combine two or more data frames in R vertically:\nExample\n\nData_Frame1 &lt;- data.frame (\n  Training = c(\"Strength\", \"Stamina\", \"Other\"),\n  Pulse = c(100, 150, 120),\n  Duration = c(60, 30, 45)\n)\n\nData_Frame2 &lt;- data.frame (\n  Training = c(\"Stamina\", \"Stamina\", \"Strength\"),\n  Pulse = c(140, 150, 160),\n  Duration = c(30, 30, 20)\n)\n\nNew_Data_Frame &lt;- rbind(Data_Frame1, Data_Frame2)\nNew_Data_Frame\n\n  Training Pulse Duration\n1 Strength   100       60\n2  Stamina   150       30\n3    Other   120       45\n4  Stamina   140       30\n5  Stamina   150       30\n6 Strength   160       20\n\n\nAnd use the cbind() function to combine two or more data frames in R horizontally:\nExample\n\nData_Frame3 &lt;- data.frame (\n  Training = c(\"Strength\", \"Stamina\", \"Other\"),\n  Pulse = c(100, 150, 120),\n  Duration = c(60, 30, 45)\n)\n\nData_Frame4 &lt;- data.frame (\n  Steps = c(3000, 6000, 2000),\n  Calories = c(300, 400, 300)\n)\n\nNew_Data_Frame1 &lt;- cbind(Data_Frame3, Data_Frame4)\nNew_Data_Frame1\n\n  Training Pulse Duration Steps Calories\n1 Strength   100       60  3000      300\n2  Stamina   150       30  6000      400\n3    Other   120       45  2000      300"
  },
  {
    "objectID": "episodes/04-tidyr.html",
    "href": "episodes/04-tidyr.html",
    "title": "Data Wrangling with tidyr",
    "section": "",
    "text": "Describe the concept of a wide and a long table format and for which purpose those formats are useful.\nDescribe the roles of variable names and their associated values when a table is reshaped.\nReshape a dataframe from long to wide format and back with the pivot_wider and pivot_longer commands from the tidyr package.\nExport a dataframe to a csv file.\ndplyr pairs nicely with tidyr which enables you to swiftly convert between different data formats (long vs. wide) for plotting and analysis. To learn more about tidyr after the workshop, you may want to check out this handy data tidying with tidyr cheatsheet.\nTo make sure everyone will use the same dataset for this lesson, we’ll read again the SAFI dataset that we downloaded earlier.\n## load the tidyverse\nlibrary(tidyverse)\nlibrary(here)\n\ninterviews &lt;- read_csv(here(\"data\", \"SAFI_clean.csv\"), na = \"NULL\")\n\n## inspect the data\ninterviews\n\n## preview the data\n# view(interviews)"
  },
  {
    "objectID": "episodes/04-tidyr.html#reshaping-with-pivot_wider-and-pivot_longer",
    "href": "episodes/04-tidyr.html#reshaping-with-pivot_wider-and-pivot_longer",
    "title": "Data Wrangling with tidyr",
    "section": "Reshaping with pivot_wider() and pivot_longer()",
    "text": "Reshaping with pivot_wider() and pivot_longer()\nThere are essentially three rules that define a “tidy” dataset:\n\nEach variable has its own column\nEach observation has its own row\nEach value must have its own cell\n\nThis graphic visually represents the three rules that define a “tidy” dataset:\n R for Data Science, Wickham H and Grolemund G (https://r4ds.had.co.nz/index.html) © Wickham, Grolemund 2017 This image is licenced under Attribution-NonCommercial-NoDerivs 3.0 United States (CC-BY-NC-ND 3.0 US)\nIn this section we will explore how these rules are linked to the different data formats researchers are often interested in: “wide” and “long”. This tutorial will help you efficiently transform your data shape regardless of original format. First we will explore qualities of the interviews data and how they relate to these different types of data formats.\n\nLong and wide data formats\nIn the interviews data, each row contains the values of variables associated with each record collected (each interview in the villages). It is stated that the key_ID was “added to provide a unique Id for each observation” and the instanceID “does this as well but it is not as convenient to use.”\nOnce we have established that key_ID and instanceID are both unique we can use either variable as an identifier corresponding to the 131 interview records.\n\ninterviews %&gt;% \n  select(key_ID) %&gt;% \n  distinct() %&gt;% \n  count()\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1   131\n\n\n\ninterviews %&gt;% \n  select(instanceID) %&gt;% \n  distinct() %&gt;% \n  count()\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1   131\n\n\nAs seen in the code below, for each interview date in each village no instanceIDs are the same. Thus, this format is what is called a “long” data format, where each observation occupies only one row in the dataframe.\n\ninterviews %&gt;%\n  filter(village == \"Chirodzo\") %&gt;%\n  select(key_ID, village, interview_date, instanceID) %&gt;%\n  sample_n(size = 10)\n\n# A tibble: 10 × 4\n   key_ID village  interview_date      instanceID                               \n    &lt;dbl&gt; &lt;chr&gt;    &lt;dttm&gt;              &lt;chr&gt;                                    \n 1     36 Chirodzo 2016-11-17 00:00:00 uuid:c90eade0-1148-4a12-8c0e-6387a36f45b1\n 2     50 Chirodzo 2016-11-16 00:00:00 uuid:4267c33c-53a7-46d9-8bd6-b96f58a4f92c\n 3     46 Chirodzo 2016-11-17 00:00:00 uuid:35f297e0-aa5d-4149-9b7b-4965004cfc37\n 4    127 Chirodzo 2016-11-16 00:00:00 uuid:f6d04b41-b539-4e00-868a-0f62b427587d\n 5     69 Chirodzo 2016-11-16 00:00:00 uuid:f86933a5-12b8-4427-b821-43c5b039401d\n 6     66 Chirodzo 2016-11-16 00:00:00 uuid:a457eab8-971b-4417-a971-2e55b8702816\n 7     52 Chirodzo 2016-11-16 00:00:00 uuid:6db55cb4-a853-4000-9555-757b7fae2bcf\n 8     10 Chirodzo 2016-12-16 00:00:00 uuid:8f4e49bc-da81-4356-ae34-e0d794a23721\n 9     37 Chirodzo 2016-11-17 00:00:00 uuid:408c6c93-d723-45ef-8dee-1b1bd3fe20cd\n10    192 Chirodzo 2017-06-03 00:00:00 uuid:f94409a6-e461-4e4c-a6fb-0072d3d58b00\n\n\nWe notice that the layout or format of the interviews data is in a format that adheres to rules 1-3, where\n\neach column is a variable\neach row is an observation\neach value has its own cell\n\nThis is called a “long” data format. But, we notice that each column represents a different variable. In the “longest” data format there would only be three columns, one for the id variable, one for the observed variable, and one for the observed value (of that variable). This data format is quite unsightly and difficult to work with, so you will rarely see it in use.\nAlternatively, in a “wide” data format we see modifications to rule 1, where each column no longer represents a single variable. Instead, columns can represent different levels/values of a variable. For instance, in some data you encounter the researchers may have chosen for every survey date to be a different column.\nThese may sound like dramatically different data layouts, but there are some tools that make transitions between these layouts much simpler than you might think! The gif below shows how these two formats relate to each other, and gives you an idea of how we can use R to shift from one format to the other.\n Long and wide dataframe layouts mainly affect readability. You may find that visually you may prefer the “wide” format, since you can see more of the data on the screen. However, all of the R functions we have used thus far expect for your data to be in a “long” data format. This is because the long format is more machine readable and is closer to the formatting of databases.\n\n\nQuestions which warrant different data formats\nIn interviews, each row contains the values of variables associated with each record (the unit), values such as the village of the respondent, the number of household members, or the type of wall their house had. This format allows for us to make comparisons across individual surveys, but what if we wanted to look at differences in households grouped by different types of items owned?\nTo facilitate this comparison we would need to create a new table where each row (the unit) was comprised of values of variables associated with items owned (i.e., items_owned). In practical terms this means the values of the items in items_owned (e.g. bicycle, radio, table, etc.) would become the names of column variables and the cells would contain values of TRUE or FALSE, for whether that household had that item.\nOnce we we’ve created this new table, we can explore the relationship within and between villages. The key point here is that we are still following a tidy data structure, but we have reshaped the data according to the observations of interest.\nAlternatively, if the interview dates were spread across multiple columns, and we were interested in visualizing, within each village, how irrigation conflicts have changed over time. This would require for the interview date to be included in a single column rather than spread across multiple columns. Thus, we would need to transform the column names into values of a variable.\nWe can do both of these transformations with two tidyr functions, pivot_wider() and pivot_longer()."
  },
  {
    "objectID": "episodes/04-tidyr.html#pivoting-wider",
    "href": "episodes/04-tidyr.html#pivoting-wider",
    "title": "Data Wrangling with tidyr",
    "section": "Pivoting wider",
    "text": "Pivoting wider\npivot_wider() takes three principal arguments:\n\nthe data\nthe names_from column variable whose values will become new column names.\nthe values_from column variable whose values will fill the new column variables.\n\nFurther arguments include values_fill which, if set, fills in missing values with the value provided.\nLet’s use pivot_wider() to transform interviews to create new columns for each item owned by a household. There are a couple of new concepts in this transformation, so let’s walk through it line by line. First we create a new object (interviews_items_owned) based on the interviews data frame.\n\ninterviews_items_owned &lt;- interviews %&gt;%\n\nThen we will actually need to make our data frame longer, because we have multiple items in a single cell. We will use a new function, separate_longer_delim(), from the tidyr package to separate the values of items_owned based on the presence of semi-colons (;). The values of this variable were multiple items separated by semi-colons, so this action creates a row for each item listed in a household’s possession. Thus, we end up with a long format version of the dataset, with multiple rows for each respondent. For example, if a respondent has a television and a solar panel, that respondent will now have two rows, one with “television” and the other with “solar panel” in the items_owned column.\n\nseparate_longer_delim(items_owned, delim = \";\") %&gt;%\n\nAfter this transformation, you may notice that the items_owned column contains NA values. This is because some of the respondents did not own any of the items in the interviewer’s list. We can use the replace_na() function to change these NA values to something more meaningful. The replace_na() function expects for you to give it a list() of columns that you would like to replace the NA values in, and the value that you would like to replace the NAs. This ends up looking like this:\n\nreplace_na(list(items_owned = \"no_listed_items\")) %&gt;%\n\nNext, we create a new variable named items_owned_logical, which has one value (TRUE) for every row. This makes sense, since each item in every row was owned by that household. We are constructing this variable so that when we spread the items_owned across multiple columns, we can fill the values of those columns with logical values describing whether the household did (TRUE) or did not (FALSE) own that particular item.\n\nmutate(items_owned_logical = TRUE) %&gt;%\n\n\nAt this point, we can also count the number of items owned by each household, which is equivalent to the number of rows per key_ID. We can do this with a group_by() and mutate() pipeline that works similar to group_by() and summarize() discussed in the previous episode but instead of creating a summary table, we will add another column called number_items. We use the n() function to count the number of rows within each group. However, there is one difficulty we need to take into account, namely those households that did not list any items. These households now have \"no_listed_items\" under items_owned. We do not want to count this as an item but instead show zero items. We can accomplish this using dplyr’s if_else() function that evaluates a condition and returns one value if true and another if false. Here, if the items_owned column is \"no_listed_items\", then a 0 is returned, otherwise, the number of rows per group is returned using n().\n\ngroup_by(key_ID) %&gt;% \n  mutate(number_items = if_else(items_owned == \"no_listed_items\", 0, n())) %&gt;% \n\nLastly, we use pivot_wider() to switch from long format to wide format. This creates a new column for each of the unique values in the items_owned column, and fills those columns with the values of items_owned_logical. We also declare that for items that are missing, we want to fill those cells with the value of FALSE instead of NA.\n\npivot_wider(names_from = items_owned,\n            values_from = items_owned_logical,\n            values_fill = list(items_owned_logical = FALSE))\n\n\nCombining the above steps, the chunk looks like this. Note that two new columns are created within the same mutate() call.\n\ninterviews_items_owned &lt;- interviews %&gt;%\n  separate_longer_delim(items_owned, delim = \";\") %&gt;%\n  replace_na(list(items_owned = \"no_listed_items\")) %&gt;%\n  group_by(key_ID) %&gt;%\n  mutate(items_owned_logical = TRUE,\n         number_items = if_else(items_owned == \"no_listed_items\", 0, n())) %&gt;%\n  pivot_wider(names_from = items_owned,\n              values_from = items_owned_logical,\n              values_fill = list(items_owned_logical = FALSE))\n\nView the interviews_items_owned data frame. It should have r nrow(interviews) rows (the same number of rows you had originally), but extra columns for each item. How many columns were added? Notice that there is no longer a column titled items_owned. This is because there is a default parameter in pivot_wider() that drops the original column. The values that were in that column have now become columns named television, solar_panel, table, etc. You can use dim(interviews) and dim(interviews_wide) to see how the number of columns has changed between the two datasets.\nThis format of the data allows us to do interesting things, like make a table showing the number of respondents in each village who owned a particular item:\n\ninterviews_items_owned %&gt;%\n  filter(bicycle) %&gt;%\n  group_by(village) %&gt;%\n  count(bicycle)\n\n# A tibble: 3 × 3\n# Groups:   village [3]\n  village  bicycle     n\n  &lt;chr&gt;    &lt;lgl&gt;   &lt;int&gt;\n1 Chirodzo TRUE       17\n2 God      TRUE       23\n3 Ruaca    TRUE       20\n\n\nOr below we calculate the average number of items from the list owned by respondents in each village using the number_items column we created to count the items listed by each household.\n\ninterviews_items_owned %&gt;%\n    group_by(village) %&gt;%\n    summarize(mean_items = mean(number_items))\n\n# A tibble: 3 × 2\n  village  mean_items\n  &lt;chr&gt;         &lt;dbl&gt;\n1 Chirodzo       4.54\n2 God            3.98\n3 Ruaca          5.57"
  },
  {
    "objectID": "episodes/04-tidyr.html#exercise",
    "href": "episodes/04-tidyr.html#exercise",
    "title": "Data Wrangling with tidyr",
    "section": "Exercise",
    "text": "Exercise\nWe created interviews_items_owned by reshaping the data: first longer and then wider. Replicate this process with the months_lack_food column in the interviews dataframe. Create a new dataframe with columns for each of the months filled with logical vectors (TRUE or FALSE) and a summary column called number_months_lack_food that calculates the number of months each household reported a lack of food.\nNote that if the household did not lack food in the previous 12 months, the value input was “none”.\n\nSolution (Solution). \n\nmonths_lack_food &lt;- interviews %&gt;%\n  separate_longer_delim(months_lack_food, delim = \";\") %&gt;%\n  group_by(key_ID) %&gt;%\n  mutate(months_lack_food_logical = TRUE,\n         number_months_lack_food = if_else(months_lack_food == \"none\", 0, n())) %&gt;%\n  pivot_wider(names_from = months_lack_food,\n              values_from = months_lack_food_logical,\n              values_fill = list(months_lack_food_logical = FALSE))"
  },
  {
    "objectID": "episodes/04-tidyr.html#pivoting-longer",
    "href": "episodes/04-tidyr.html#pivoting-longer",
    "title": "Data Wrangling with tidyr",
    "section": "Pivoting longer",
    "text": "Pivoting longer\nThe opposing situation could occur if we had been provided with data in the form of interviews_wide, where the items owned are column names, but we wish to treat them as values of an items_owned variable instead.\nIn this situation we are gathering these columns turning them into a pair of new variables. One variable includes the column names as values, and the other variable contains the values in each cell previously associated with the column names. We will do this in two steps to make this process a bit clearer.\npivot_longer() takes four principal arguments:\n\nthe data\ncols are the names of the columns we use to fill the a new values variable (or to drop).\nthe names_to column variable we wish to create from the cols provided.\nthe values_to column variable we wish to create and fill with values associated with the cols provided.\n\n\ninterviews_long &lt;- interviews_items_owned %&gt;%\n  pivot_longer(cols = bicycle:car,\n               names_to = \"items_owned\",\n               values_to = \"items_owned_logical\")\n\nView both interviews_long and interviews_items_owned and compare their structure."
  },
  {
    "objectID": "episodes/04-tidyr.html#exercise-1",
    "href": "episodes/04-tidyr.html#exercise-1",
    "title": "Data Wrangling with tidyr",
    "section": "Exercise",
    "text": "Exercise\nWe created some summary tables on interviews_items_owned using count and summarise. We can create the same tables on interviews_long, but this will require a different process.\nMake a table showing the number of respondents in each village who owned a particular item, and include all items. The difference between this format and the wide format is that you can now count all the items using the items_owned variable.\n\nSolution (Solution). \n\ninterviews_long %&gt;%\n  filter(items_owned_logical) %&gt;% \n  group_by(village) %&gt;% \n  count(items_owned)\n\n# A tibble: 47 × 3\n# Groups:   village [3]\n   village  items_owned         n\n   &lt;chr&gt;    &lt;chr&gt;           &lt;int&gt;\n 1 Chirodzo bicycle            17\n 2 Chirodzo computer            2\n 3 Chirodzo cow_cart            6\n 4 Chirodzo cow_plough         20\n 5 Chirodzo electricity         1\n 6 Chirodzo fridge              1\n 7 Chirodzo lorry               1\n 8 Chirodzo mobile_phone       25\n 9 Chirodzo motorcyle          13\n10 Chirodzo no_listed_items     3\n# ℹ 37 more rows"
  },
  {
    "objectID": "episodes/04-tidyr.html#applying-what-we-learned-to-clean-our-data",
    "href": "episodes/04-tidyr.html#applying-what-we-learned-to-clean-our-data",
    "title": "Data Wrangling with tidyr",
    "section": "Applying what we learned to clean our data",
    "text": "Applying what we learned to clean our data\nNow we have simultaneously learned about pivot_longer() and pivot_wider(), and fixed a problem in the way our data is structured. In this dataset, we have another column that stores multiple values in a single cell. Some of the cells in the months_lack_food column contain multiple months which, as before, are separated by semi-colons (;).\nTo create a data frame where each of the columns contain only one value per cell, we can repeat the steps we applied to items_owned and apply them to months_lack_food. Since we will be using this data frame for the next episode, we will call it interviews_plotting.\n\n## Plotting data ##\ninterviews_plotting &lt;- interviews %&gt;%\n  ## pivot wider by items_owned\n  separate_longer_delim(items_owned, delim = \";\") %&gt;%\n  replace_na(list(items_owned = \"no_listed_items\")) %&gt;%\n  ## Use of grouped mutate to find number of rows\n  group_by(key_ID) %&gt;% \n  mutate(items_owned_logical = TRUE,\n         number_items = if_else(items_owned == \"no_listed_items\", 0, n())) %&gt;% \n  pivot_wider(names_from = items_owned,\n              values_from = items_owned_logical,\n              values_fill = list(items_owned_logical = FALSE)) %&gt;% \n  ## pivot wider by months_lack_food\n  separate_longer_delim(months_lack_food, delim = \";\") %&gt;%\n  mutate(months_lack_food_logical = TRUE,\n         number_months_lack_food = if_else(months_lack_food == \"none\", 0, n())) %&gt;%\n  pivot_wider(names_from = months_lack_food,\n              values_from = months_lack_food_logical,\n              values_fill = list(months_lack_food_logical = FALSE))"
  },
  {
    "objectID": "episodes/04-tidyr.html#exporting-data",
    "href": "episodes/04-tidyr.html#exporting-data",
    "title": "Data Wrangling with tidyr",
    "section": "Exporting data",
    "text": "Exporting data\nNow that you have learned how to use dplyr and tidyr to wrangle your raw data, you may want to export these new datasets to share them with your collaborators or for archival purposes.\nSimilar to the read_csv() function used for reading CSV files into R, there is a write_csv() function that generates CSV files from data frames.\nBefore using write_csv(), we are going to create a new folder, data_output, in our working directory that will store this generated dataset. We don’t want to write generated datasets in the same directory as our raw data. It’s good practice to keep them separate. The data folder should only contain the raw, unaltered data, and should be left alone to make sure we don’t delete or modify it. In contrast, our script will generate the contents of the data_output directory, so even if the files it contains are deleted, we can always re-generate them.\nIn preparation for our next lesson on plotting, we created a version of the dataset where each of the columns includes only one data value. Now we can save this data frame to our data_output directory.\n\nwrite_csv(interviews_plotting, file = \"data_output/interviews_plotting.csv\")\n\n\n\nUse the tidyr package to change the layout of data frames.\nUse pivot_wider() to go from long to wide format.\nUse pivot_longer() to go from wide to long format."
  },
  {
    "objectID": "episodes/05-ggplot2.html",
    "href": "episodes/05-ggplot2.html",
    "title": "Data Visualisation with ggplot2",
    "section": "",
    "text": "This episode is a broad overview of ggplot2 and focuses on (1) getting familiar with the layering system of ggplot2, (2) using the argument group in the aes() function, (3) basic customization of the plots.\nThe episode depends on data created in the Data Wrangling with tidyr episode. If you did not get to or through all of the tidyr episode, you can have the learners access the data by either downloading it or quickly creating it using the tidyr code below. You will probably want to copy the code into the Etherpad.\nIf you did skip the tidyr episode, you might want to go over the exporting data section in that episode.\nWe start by loading the required package. ggplot2 is also included in the tidyverse package.\nlibrary(tidyverse)\nIf not still in the workspace, load the data we saved in the previous lesson.\ninterviews_plotting &lt;- read_csv(\"data_output/interviews_plotting.csv\")\n\nRows: 131 Columns: 45\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (5): village, respondent_wall_type, memb_assoc, affect_conflicts, inst...\ndbl   (8): key_ID, no_membrs, years_liv, rooms, liv_count, no_meals, number_...\nlgl  (31): bicycle, television, solar_panel, table, cow_cart, radio, cow_plo...\ndttm  (1): interview_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nIf you were unable to complete the previous lesson or did not save the data, then you can create it now. Either download it using read_csv() (Option 1) or create it with the dplyr and tidyr code (Option 2).\nAfter creating your plot, you can save it to a file in your favourite format. The Export tab in the Plot pane in RStudio will save your plots at low resolution, which will not be accepted by many journals and will not scale well for posters.\nInstead, use the ggsave() function, which allows you to easily change the dimension and resolution of your plot by adjusting the appropriate arguments (width, height and dpi).\nMake sure you have the fig_output/ folder in your working directory.\nmy_plot &lt;- percent_items %&gt;%\n    ggplot(aes(x = village, y = percent)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    facet_wrap(~ items) +\n    labs(title = \"Percent of respondents in each village \\n who owned each item\",\n         x = \"Village\",\n         y = \"Percent of Respondents\") +\n    theme_bw() +\n    theme(axis.text.x = element_text(color = \"grey20\", size = 12, angle = 45,\n                                     hjust = 0.5, vjust = 0.5),\n          axis.text.y = element_text(color = \"grey20\", size = 12),\n          text = element_text(size = 16),\n          plot.title = element_text(hjust = 0.5))\n\nggsave(\"fig_output/name_of_file.png\", my_plot, width = 15, height = 10)\nNote: The parameters width and height also determine the font size in the saved plot."
  },
  {
    "objectID": "episodes/05-ggplot2.html#visualization-options-in-r",
    "href": "episodes/05-ggplot2.html#visualization-options-in-r",
    "title": "Data Visualisation with ggplot2",
    "section": "Visualization Options in R",
    "text": "Visualization Options in R\nBefore we start with ggplot2, it’s helpful to know that there are several ways to create visualizations in R. While ggplot2 is great for building complex and highly customizable plots, there are simpler and quicker alternatives that you might encounter or use depending on the context. Let’s briefly explore a few of them:\n\nR Base Plots\nBase R plots are the simplest form of visualization and are great for quick, exploratory analysis. You can create plots with very little code, but customizing them can be cumbersome compared to ggplot2.\nExample of a simple scatterplot in base R using the no_membrs and liv_count variables:\n\nplot(interviews_plotting$no_membrs, interviews_plotting$liv_count,\n     main = \"Base R Scatterplot\",\n     xlab = \"Number of Household Members\",\n     ylab = \"Number of Livestock Owned\")\n\n\n\n\n\n\n\n\n\n\nLattice\nLattice is another plotting system in R, which allows for creating multi-panel plots easily. It’s different from ggplot2 because you define the entire plot in a single function call, and modifications after plotting are limited.\nExample of a lattice plot using no_membrs and liv_count split by village:\n\nlibrary(lattice)\n\n\nxyplot(liv_count ~ no_membrs | village, data = interviews_plotting,\n       main = \"Lattice Plot: Livestock Count by Household Members\",\n       xlab = \"Number of Household Members\",\n       ylab = \"Number of Livestock Owned\")"
  },
  {
    "objectID": "episodes/05-ggplot2.html#plotting-with-ggplot2",
    "href": "episodes/05-ggplot2.html#plotting-with-ggplot2",
    "title": "Data Visualisation with ggplot2",
    "section": "Plotting with ggplot2",
    "text": "Plotting with ggplot2\nggplot2 is a plotting package that makes it simple to create complex plots from data stored in a data frame. It provides a programmatic interface for specifying what variables to plot, how they are displayed, and general visual properties. Therefore, we only need minimal changes if the underlying data change or if we decide to change from a bar plot to a scatterplot. This helps in creating publication quality plots with minimal amounts of adjustments and tweaking.\nggplot2 functions work best with data in the ‘long’ format, i.e., a column for every dimension, and a row for every observation. Well-structured data will save you lots of time when making figures with ggplot2\nggplot graphics are built step by step by adding new elements. Adding layers in this fashion allows for extensive flexibility and customization of plots.\nEach chart built with ggplot2 must include the following\n\nData\nAesthetic mapping (aes)\n\nDescribes how variables are mapped onto graphical attributes\nVisual attribute of data including x-y axes, color, fill, shape, and alpha\n\nGeometric objects (geom)\n\nDetermines how values are rendered graphically, as bars (geom_bar), scatterplot (geom_point), line (geom_line), etc.\n\n\nThus, the template for graphic in ggplot2 is:\n&lt;DATA&gt; %&gt;%\n    ggplot(aes(&lt;MAPPINGS&gt;)) +\n    &lt;GEOM_FUNCTION&gt;()\nRemember from the last lesson that the pipe operator %&gt;% places the result of the previous line(s) into the first argument of the function. ggplot is a function that expects a data frame to be the first argument. This allows for us to change from specifying the data = argument within the ggplot function and instead pipe the data into the function.\n\nuse the ggplot() function and bind the plot to a specific data frame.\n\n\ninterviews_plotting %&gt;%\n    ggplot()\n\n\ndefine a mapping (using the aesthetic (aes) function), by selecting the variables to be plotted and specifying how to present them in the graph, e.g. as x/y positions or characteristics such as size, shape, color, etc.\n\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = no_membrs, y = number_items))\n\n\nadd ‘geoms’ – graphical representations of the data in the plot (points, lines, bars). ggplot2 offers many different geoms; we will use some common ones today, including:\n\ngeom_point() for scatter plots, dot plots, etc.\ngeom_boxplot() for, well, boxplots!\ngeom_line() for trend lines, time series, etc.\n\n\nTo add a geom to the plot use the + operator. Because we have two continuous variables, let’s use geom_point() first:\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = no_membrs, y = number_items)) +\n    geom_point()\n\n\n\n\n\n\n\n\nThe + in the ggplot2 package is particularly useful because it allows you to modify existing ggplot objects. This means you can easily set up plot templates and conveniently explore different types of plots, so the above plot can also be generated with code like this, similar to the “intermediate steps” approach in the previous lesson:\n\n# Assign plot to a variable\ninterviews_plot &lt;- interviews_plotting %&gt;%\n    ggplot(aes(x = no_membrs, y = number_items))\n\n# Draw the plot as a dot plot\ninterviews_plot +\n    geom_point()\n\n\n\n\n\n\n\nNoneNotes\n\n\n\n\nAnything you put in the ggplot() function can be seen by any geom layers that you add (i.e., these are universal plot settings). This includes the x- and y-axis mapping you set up in aes().\nYou can also specify mappings for a given geom independently of the mapping defined globally in the ggplot() function.\nThe + sign used to add new layers must be placed at the end of the line containing the previous layer. If, instead, the + sign is added at the beginning of the line containing the new layer, ggplot2 will not add the new layer and will return an error message.\n\n\n\n\n## This is the correct syntax for adding layers\ninterviews_plot +\n    geom_point()\n\n## This will not add the new layer and will return an error message\ninterviews_plot\n+ geom_point()"
  },
  {
    "objectID": "episodes/05-ggplot2.html#building-your-plots-iteratively",
    "href": "episodes/05-ggplot2.html#building-your-plots-iteratively",
    "title": "Data Visualisation with ggplot2",
    "section": "Building your plots iteratively",
    "text": "Building your plots iteratively\nBuilding plots with ggplot2 is typically an iterative process. We start by defining the dataset we’ll use, lay out the axes, and choose a geom:\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = no_membrs, y = number_items)) +\n    geom_point()\n\n\n\n\n\n\n\n\nThen, we start modifying this plot to extract more information from it. For instance, when inspecting the plot we notice that points only appear at the intersection of whole numbers of no_membrs and number_items. Also, from a rough estimate, it looks like there are far fewer dots on the plot than there rows in our dataframe. This should lead us to believe that there may be multiple observations plotted on top of each other (e.g. three observations where no_membrs is 3 and number_items is 1).\nThere are two main ways to alleviate overplotting issues:\n\nchanging the transparency of the points\njittering the location of the points\n\nLet’s first explore option 1, changing the transparency of the points. What we mean when we say “transparency” we mean the opacity of point, or your ability to see through the point. We can control the transparency of the points with the alpha argument to geom_point. Values of alpha range from 0 to 1, with lower values corresponding to more transparent colors (an alpha of 1 is the default value). Specifically, an alpha of 0.1, would make a point one-tenth as opaque as a normal point. Stated differently ten points stacked on top of each other would correspond to a normal point.\nHere, we change the alpha to 0.5, in an attempt to help fix the overplotting. While the overplotting isn’t solved, adding transparency begins to address this problem, as the points where there are overlapping observations are darker (as opposed to lighter gray):\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = no_membrs, y = number_items)) +\n    geom_point(alpha = 0.5)\n\n\n\n\n\n\n\n\nThat only helped a little bit with the overplotting problem, so let’s try option two. We can jitter the points on the plot, so that we can see each point in the locations where there are overlapping points. Jittering introduces a little bit of randomness into the position of our points. You can think of this process as taking the overplotted graph and giving it a tiny shake. The points will move a little bit side-to-side and up-and-down, but their position from the original plot won’t dramatically change. Note that this solution is suitable for plotting integer figures, while for numeric figures with decimals, geom_jitter() becomes inappropriate because it obscures the true value of the observation.\nWe can jitter our points using the geom_jitter() function instead of the geom_point() function, as seen below:\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = no_membrs, y = number_items)) +\n    geom_jitter()\n\n\n\n\n\n\n\n\nThe geom_jitter() function allows for us to specify the amount of random motion in the jitter, using the width and height arguments. When we don’t specify values for width and height, geom_jitter() defaults to 40% of the resolution of the data (the smallest change that can be measured). Hence, if we would like less spread in our jitter than was default, we should pick values between 0.1 and 0.4. Experiment with the values to see how your plot changes.\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = no_membrs, y = number_items)) +\n    geom_jitter(alpha = 0.5,\n                width = 0.2,\n                height = 0.2)\n\n\n\n\n\n\n\n\nFor our final change, we can also add colours for all the points by specifying a color argument inside the geom_jitter() function:\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = no_membrs, y = number_items)) +\n    geom_jitter(alpha = 0.5,\n                color = \"blue\",\n                width = 0.2,\n                height = 0.2)\n\n\n\n\n\n\n\n\nTo colour each village in the plot differently, you could use a vector as an input to the argument color. However, because we are now mapping features of the data to a colour, instead of setting one colour for all points, the colour of the points now needs to be set inside a call to the aes function. When we map a variable in our data to the colour of the points, ggplot2 will provide a different colour corresponding to the different values of the variable. We will continue to specify the value of alpha, width, and height outside of the aes function because we are using the same value for every point. ggplot2 understands both the Commonwealth English and American English spellings for colour, i.e., you can use either color or colour. Here is an example where we color points by the village of the observation:\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = no_membrs, y = number_items)) +\n    geom_jitter(aes(color = village), alpha = 0.5, width = 0.2, height = 0.2)\n\n\n\n\n\n\n\n\nThere appears to be a positive trend between number of household members and number of items owned (from the list provided). Additionally, this trend does not appear to be different by village.\n\n\n\n\n\n\nNoneNotes\n\n\n\nAs you will learn, there are multiple ways to plot the a relationship between variables. Another way to plot data with overlapping points is to use the geom_count plotting function. The geom_count() function makes the size of each point representative of the number of data items of that type and the legend gives point sizes associated to particular numbers of items.\n\ninterviews_plotting %&gt;%\n   ggplot(aes(x = no_membrs, y = number_items, color = village)) +\n   geom_count()"
  },
  {
    "objectID": "episodes/05-ggplot2.html#exercise",
    "href": "episodes/05-ggplot2.html#exercise",
    "title": "Data Visualisation with ggplot2",
    "section": "Exercise",
    "text": "Exercise\nUse what you just learned to create a scatter plot of rooms by village with the respondent_wall_type showing in different colours. Does this seem like a good way to display the relationship between these variables? What other kinds of plots might you use to show this type of data?\n\nSolution (Solution). \n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = village, y = rooms)) +\n    geom_jitter(aes(color = respondent_wall_type),\n        alpha = 0.5,\n            width = 0.2,\n            height = 0.2)\n\n\n\n\n\n\n\n\nThis is not a great way to show this type of data because it is difficult to distinguish between villages. What other plot types could help you visualize this relationship better?"
  },
  {
    "objectID": "episodes/05-ggplot2.html#boxplot",
    "href": "episodes/05-ggplot2.html#boxplot",
    "title": "Data Visualisation with ggplot2",
    "section": "Boxplot",
    "text": "Boxplot\nWe can use boxplots to visualize the distribution of rooms for each wall type:\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = respondent_wall_type, y = rooms)) +\n    geom_boxplot()\n\n\n\n\n\n\n\n\nBy adding points to a boxplot, we can have a better idea of the number of measurements and of their distribution:\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = respondent_wall_type, y = rooms)) +\n    geom_boxplot(alpha = 0) +\n    geom_jitter(alpha = 0.5,\n            color = \"tomato\",\n            width = 0.2,\n            height = 0.2)\n\n\n\n\n\n\n\n\nWe can see that muddaub houses and sunbrick houses tend to be smaller than burntbrick houses.\nNotice how the boxplot layer is behind the jitter layer? What do you need to change in the code to put the boxplot layer in front of the jitter layer?"
  },
  {
    "objectID": "episodes/05-ggplot2.html#exercise-1",
    "href": "episodes/05-ggplot2.html#exercise-1",
    "title": "Data Visualisation with ggplot2",
    "section": "Exercise",
    "text": "Exercise\nBoxplots are useful summaries, but hide the shape of the distribution. For example, if the distribution is bimodal, we would not see it in a boxplot. An alternative to the boxplot is the violin plot, where the shape (of the density of points) is drawn.\n\nReplace the box plot with a violin plot; see geom_violin().\n\n\nSolution (Solution). \n\ninterviews_plotting %&gt;%\n  ggplot(aes(x = respondent_wall_type, y = rooms)) +\n  geom_violin(alpha = 0) +\n  geom_jitter(alpha = 0.5, color = \"tomato\")\n\nWarning: Groups with fewer than two datapoints have been dropped.\nℹ Set `drop = FALSE` to consider such groups for position adjustment purposes.\n\n\n\n\n\n\n\n\n\n\nSo far, we’ve looked at the distribution of room number within wall type. Try making a new plot to explore the distribution of another variable within wall type.\n\nCreate a boxplot for liv_count for each wall type. Overlay the boxplot layer on a jitter layer to show actual measurements.\n\n\nSolution (Solution). \n\ninterviews_plotting %&gt;%\n   ggplot(aes(x = respondent_wall_type, y = liv_count)) +\n   geom_boxplot(alpha = 0) +\n   geom_jitter(alpha = 0.5, width = 0.2, height = 0.2)\n\n\n\n\n\n\n\n\n\n\nAdd colour to the data points on your boxplot according to whether the respondent is a member of an irrigation association (memb_assoc).\n\n\nSolution (Solution). \n\ninterviews_plotting %&gt;%\n  ggplot(aes(x = respondent_wall_type, y = liv_count)) +\n  geom_boxplot(alpha = 0) +\n  geom_jitter(aes(color = memb_assoc), alpha = 0.5, width = 0.2, height = 0.2)"
  },
  {
    "objectID": "episodes/05-ggplot2.html#barplots",
    "href": "episodes/05-ggplot2.html#barplots",
    "title": "Data Visualisation with ggplot2",
    "section": "Barplots",
    "text": "Barplots\nBarplots are also useful for visualizing categorical data. By default, geom_bar accepts a variable for x, and plots the number of instances each value of x (in this case, wall type) appears in the dataset.\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = respondent_wall_type)) +\n    geom_bar()\n\n\n\n\n\n\n\n\nWe can use the fill aesthetic for the geom_bar() geom to colour bars by the portion of each count that is from each village.\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = respondent_wall_type)) +\n    geom_bar(aes(fill = village))\n\n\n\n\n\n\n\n\nThis creates a stacked bar chart. These are generally more difficult to read than side-by-side bars. We can separate the portions of the stacked bar that correspond to each village and put them side-by-side by using the position argument for geom_bar() and setting it to “dodge”.\n\ninterviews_plotting %&gt;%\n    ggplot(aes(x = respondent_wall_type)) +\n    geom_bar(aes(fill = village), position = \"dodge\")\n\n\n\n\n\n\n\n\nThis is a nicer graphic, but we’re more likely to be interested in the proportion of each housing type in each village than in the actual count of number of houses of each type (because we might have sampled different numbers of households in each village). To compare proportions, we will first create a new data frame (percent_wall_type) with a new column named “percent” representing the percent of each house type in each village. We will remove houses with cement walls, as there was only one in the dataset.\n\npercent_wall_type &lt;- interviews_plotting %&gt;%\n    filter(respondent_wall_type != \"cement\") %&gt;%\n    count(village, respondent_wall_type) %&gt;%\n    group_by(village) %&gt;%\n    mutate(percent = (n / sum(n)) * 100) %&gt;%\n    ungroup()\n\nNow we can use this new data frame to create our plot showing the percentage of each house type in each village.\n\npercent_wall_type %&gt;%\n    ggplot(aes(x = village, y = percent, fill = respondent_wall_type)) +\n    geom_bar(stat = \"identity\", position = \"dodge\")"
  },
  {
    "objectID": "episodes/05-ggplot2.html#exercise-2",
    "href": "episodes/05-ggplot2.html#exercise-2",
    "title": "Data Visualisation with ggplot2",
    "section": "Exercise",
    "text": "Exercise\nCreate a bar plot showing the proportion of respondents in each village who are or are not part of an irrigation association (memb_assoc). Include only respondents who answered that question in the calculations and plot. Which village had the lowest proportion of respondents in an irrigation association?\n\nSolution (Solution). \n\npercent_memb_assoc &lt;- interviews_plotting %&gt;%\n  filter(!is.na(memb_assoc)) %&gt;%\n  count(village, memb_assoc) %&gt;%\n  group_by(village) %&gt;%\n  mutate(percent = (n / sum(n)) * 100) %&gt;%\n  ungroup()\n\npercent_memb_assoc %&gt;%\n   ggplot(aes(x = village, y = percent, fill = memb_assoc)) +\n    geom_bar(stat = \"identity\", position = \"dodge\")\n\n\n\n\n\n\n\n\nRuaca had the lowest proportion of members in an irrigation association."
  },
  {
    "objectID": "episodes/05-ggplot2.html#adding-labels-and-titles",
    "href": "episodes/05-ggplot2.html#adding-labels-and-titles",
    "title": "Data Visualisation with ggplot2",
    "section": "Adding Labels and Titles",
    "text": "Adding Labels and Titles\nBy default, the axes labels on a plot are determined by the name of the variable being plotted. However, ggplot2 offers lots of customization options, like specifying the axes labels, and adding a title to the plot with relatively few lines of code. We will add more informative x-and y-axis labels to our plot, a more explanatory label to the legend, and a plot title.\nThe labs function takes the following arguments:\n\ntitle – to produce a plot title\nsubtitle – to produce a plot subtitle (smaller text placed beneath the title)\ncaption – a caption for the plot\n... – any pair of name and value for aesthetics used in the plot (e.g., x, y, fill, color, size)\n\n\npercent_wall_type %&gt;%\n    ggplot(aes(x = village, y = percent, fill = respondent_wall_type)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    labs(title = \"Proportion of wall type by village\",\n         fill = \"Type of Wall in Home\",\n         x = \"Village\",\n         y = \"Percent\")"
  },
  {
    "objectID": "episodes/05-ggplot2.html#faceting",
    "href": "episodes/05-ggplot2.html#faceting",
    "title": "Data Visualisation with ggplot2",
    "section": "Faceting",
    "text": "Faceting\nRather than creating a single plot with side-by-side bars for each village, we may want to create multiple plot, where each plot shows the data for a single village. This would be especially useful if we had a large number of villages that we had sampled, as a large number of side-by-side bars will become more difficult to read.\nggplot2 has a special technique called faceting that allows the user to split one plot into multiple plots based on a factor included in the dataset. We will use it to split our barplot of housing type proportion by village so that each village has its own panel in a multi-panel plot:\n\npercent_wall_type %&gt;%\n    ggplot(aes(x = respondent_wall_type, y = percent)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    labs(title=\"Proportion of wall type by village\",\n         x=\"Wall Type\",\n         y=\"Percent\") +\n    facet_wrap(~ village)\n\n\n\n\n\n\n\n\nClick the “Zoom” button in your RStudio plots pane to view a larger version of this plot.\nUsually plots with white background look more readable when printed. We can set the background to white using the function theme_bw(). Additionally, you can remove the grid:\n\npercent_wall_type %&gt;%\n    ggplot(aes(x = respondent_wall_type, y = percent)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    labs(title=\"Proportion of wall type by village\",\n         x=\"Wall Type\",\n         y=\"Percent\") +\n    facet_wrap(~ village) +\n    theme_bw() +\n    theme(panel.grid = element_blank())\n\n\n\n\n\n\n\n\nWhat if we wanted to see the proportion of respondents in each village who owned a particular item? We can calculate the percent of people in each village who own each item and then create a faceted series of bar plots where each plot is a particular item. First we need to calculate the percentage of people in each village who own each item:\n\npercent_items &lt;- interviews_plotting %&gt;%\n    group_by(village) %&gt;%\n    summarize(across(bicycle:no_listed_items, ~ sum(.x) / n() * 100)) %&gt;%\n    pivot_longer(bicycle:no_listed_items, names_to = \"items\", values_to = \"percent\")\n\nTo calculate this percentage data frame, we needed to use the across() function within a summarize() operation. Unlike the previous example with a single wall type variable, where each response was exactly one of the types specified, people can (and do) own more than one item. So there are multiple columns of data (one for each item), and the percentage calculation needs to be repeated for each column.\nCombining summarize() with across() allows us to specify first, the columns to be summarized (bicycle:no_listed_items) and then the calculation. Because our calculation is a bit more complex than is available in a built-in function, we define a new formula:\n\n~ indicates that we are defining a formula,\nsum(.x) gives the number of people owning that item by counting the number of TRUE values (.x is shorthand for the column being operated on),\nand n() gives the current group size.\n\nAfter the summarize() operation, we have a table of percentages with each item in its own column, so a pivot_longer() is required to transform the table into an easier format for plotting. Using this data frame, we can now create a multi-paneled bar plot.\n\npercent_items %&gt;%\n    ggplot(aes(x = village, y = percent)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    facet_wrap(~ items) +\n    theme_bw() +\n    theme(panel.grid = element_blank())"
  },
  {
    "objectID": "episodes/05-ggplot2.html#ggplot2-themes",
    "href": "episodes/05-ggplot2.html#ggplot2-themes",
    "title": "Data Visualisation with ggplot2",
    "section": "ggplot2 themes",
    "text": "ggplot2 themes\nIn addition to theme_bw(), which changes the plot background to white, ggplot2 comes with several other themes which can be useful to quickly change the look of your visualization. The complete list of themes is available at https://ggplot2.tidyverse.org/reference/ggtheme.html. theme_minimal() and theme_light() are popular, and theme_void() can be useful as a starting point to create a new hand-crafted theme.\nThe ggthemes package provides a wide variety of options (including an Excel 2003 theme). The ggplot2 extensions website provides a list of packages that extend the capabilities of ggplot2, including additional themes."
  },
  {
    "objectID": "episodes/05-ggplot2.html#exercise-3",
    "href": "episodes/05-ggplot2.html#exercise-3",
    "title": "Data Visualisation with ggplot2",
    "section": "Exercise",
    "text": "Exercise\nExperiment with at least two different themes. Build the previous plot using each of those themes. Which do you like best?"
  },
  {
    "objectID": "episodes/05-ggplot2.html#customization",
    "href": "episodes/05-ggplot2.html#customization",
    "title": "Data Visualisation with ggplot2",
    "section": "Customization",
    "text": "Customization\nTake a look at the ggplot2 cheat sheet, and think of ways you could improve the plot.\nNow, let’s change names of axes to something more informative than ‘village’ and ‘percent’ and add a title to the figure:\n\npercent_items %&gt;%\n    ggplot(aes(x = village, y = percent)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    facet_wrap(~ items) +\n    labs(title = \"Percent of respondents in each village who owned each item\",\n         x = \"Village\",\n         y = \"Percent of Respondents\") +\n    theme_bw()\n\n\n\n\n\n\n\n\nThe axes have more informative names, but their readability can be improved by increasing the font size:\n\npercent_items %&gt;%\n    ggplot(aes(x = village, y = percent)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    facet_wrap(~ items) +\n    labs(title = \"Percent of respondents in each village who owned each item\",\n         x = \"Village\",\n         y = \"Percent of Respondents\") +\n    theme_bw() +\n    theme(text = element_text(size = 16))\n\n\n\n\n\n\n\n\nNote that it is also possible to change the fonts of your plots. If you are on Windows, you may have to install the extrafont package, and follow the instructions included in the README for this package.\nAfter our manipulations, you may notice that the values on the x-axis are still not properly readable. Let’s change the orientation of the labels and adjust them vertically and horizontally so they don’t overlap. You can use a 90-degree angle, or experiment to find the appropriate angle for diagonally oriented labels. With a larger font, the title also runs off. We can add “\\n” in the string for the title to insert a new line:\n\npercent_items %&gt;%\n    ggplot(aes(x = village, y = percent)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    facet_wrap(~ items) +\n    labs(title = \"Percent of respondents in each village \\n who owned each item\",\n         x = \"Village\",\n         y = \"Percent of Respondents\") +\n    theme_bw() +\n    theme(axis.text.x = element_text(colour = \"grey20\", size = 12, angle = 45,\n                                     hjust = 0.5, vjust = 0.5),\n          axis.text.y = element_text(colour = \"grey20\", size = 12),\n          text = element_text(size = 16))\n\n\n\n\n\n\n\n\nIf you like the changes you created better than the default theme, you can save them as an object to be able to easily apply them to other plots you may create. We can also add plot.title = element_text(hjust = 0.5) to centre the title:\n\ngrey_theme &lt;- theme(axis.text.x = element_text(colour = \"grey20\", size = 12,\n                                               angle = 45, hjust = 0.5,\n                                               vjust = 0.5),\n                    axis.text.y = element_text(colour = \"grey20\", size = 12),\n                    text = element_text(size = 16),\n                    plot.title = element_text(hjust = 0.5))\n\n\npercent_items %&gt;%\n    ggplot(aes(x = village, y = percent)) +\n    geom_bar(stat = \"identity\", position = \"dodge\") +\n    facet_wrap(~ items) +\n    labs(title = \"Percent of respondents in each village \\n who owned each item\",\n         x = \"Village\",\n         y = \"Percent of Respondents\") +\n    grey_theme"
  },
  {
    "objectID": "episodes/05-ggplot2.html#exercise-4",
    "href": "episodes/05-ggplot2.html#exercise-4",
    "title": "Data Visualisation with ggplot2",
    "section": "Exercise",
    "text": "Exercise\nWith all of this information in hand, please take another five minutes to either improve one of the plots generated in this exercise or create a beautiful graph of your own. Use the RStudio ggplot2 cheat sheet for inspiration. Here are some ideas:\n\nSee if you can make the bars white with black outline.\nTry using a different colour palette (see http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/)."
  },
  {
    "objectID": "episodes/06-rmarkdown.html",
    "href": "episodes/06-rmarkdown.html",
    "title": "Getting started with R Markdown (Optional)",
    "section": "",
    "text": "This is an optional lesson intended to introduce learners to R Markdown.\nWhile it is listed after the core lessons, some instructors may prefer to teach it early in the workshop, depending on the audience.\nWe can also create a caption with the chunk option fig.cap.\n…or, ideally, something more informative.\ninterviews_plotting %&gt;%\n  ggplot(aes(x = respondent_wall_type)) +\n  geom_bar(aes(fill = village), position = \"dodge\") + \n  labs(x = \"Type of Wall in Home\", y = \"Count\", fill = \"Village Name\") +\n  scale_fill_viridis_d() # add colour deficient friendly palette\n\n\n\n\nI made this plot while attending an awesome Data Carpentries workshop where I learned a ton of cool stuff!"
  },
  {
    "objectID": "episodes/06-rmarkdown.html#r-markdown",
    "href": "episodes/06-rmarkdown.html#r-markdown",
    "title": "Getting started with R Markdown (Optional)",
    "section": "R Markdown",
    "text": "R Markdown\nR Markdown is a flexible type of document that allows you to seamlessly combine executable R code, and its output, with text in a single document. These documents can be readily converted to multiple static and dynamic output formats, including PDF (.pdf), Word (.docx), and HTML (.html).\nThe benefit of a well-prepared R Markdown document is full reproducibility. This also means that, if you notice a data transcription error, or you are able to add more data to your analysis, you will be able to recompile the report without making any changes in the actual document.\nThe rmarkdown package comes pre-installed with RStudio, so no action is necessary.\n\n\n\n\n\n\n\n\n\n\n\nImage credit: Allison Horst"
  },
  {
    "objectID": "episodes/06-rmarkdown.html#creating-an-r-markdown-file",
    "href": "episodes/06-rmarkdown.html#creating-an-r-markdown-file",
    "title": "Getting started with R Markdown (Optional)",
    "section": "Creating an R Markdown file",
    "text": "Creating an R Markdown file\nTo create a new R Markdown document in RStudio, click File -&gt; New File -&gt; R Markdown:\n\nThen click on ‘Create Empty Document’. Normally you could enter the title of your document, your name (Author), and select the type of output, but we will be learning how to start from a blank document."
  },
  {
    "objectID": "episodes/06-rmarkdown.html#basic-components-of-r-markdown",
    "href": "episodes/06-rmarkdown.html#basic-components-of-r-markdown",
    "title": "Getting started with R Markdown (Optional)",
    "section": "Basic components of R Markdown",
    "text": "Basic components of R Markdown\nTo control the output, a YAML (YAML Ain’t Markup Language) header is needed:\n---\ntitle: \"My Awesome Report\"\nauthor: \"Emmet Brickowski\"\ndate: \"\"\noutput: html_document\n---\nThe header is defined by the three hyphens at the beginning (---) and the three hyphens at the end (---).\nIn the YAML, the only required field is the output:, which specifies the type of output you want. This can be an html_document, a pdf_document, or a word_document. We will start with an HTML doument and discuss the other options later.\nThe rest of the fields can be deleted, if you don’t need them. After the header, to begin the body of the document, you start typing after the end of the YAML header (i.e. after the second ---)."
  },
  {
    "objectID": "episodes/06-rmarkdown.html#markdown-syntax",
    "href": "episodes/06-rmarkdown.html#markdown-syntax",
    "title": "Getting started with R Markdown (Optional)",
    "section": "Markdown syntax",
    "text": "Markdown syntax\nMarkdown is a popular markup language that allows you to add formatting elements to text, such as bold, italics, and code. The formatting will not be immediately visible in a markdown (.md) document, like you would see in a Word document. Rather, you add Markdown syntax to the text, which can then be converted to various other files that can translate the Markdown syntax. Markdown is useful because it is lightweight, flexible, and platform independent.\nSome platforms provide a real time preview of the formatting, like RStudio’s visual markdown editor (available from version 1.4).\nFirst, let’s create a heading! A # in front of text indicates to Markdown that this text is a heading. Adding more #s make the heading smaller, i.e. one # is a first level heading, two ##s is a second level heading, etc. upto the 6th level heading.\n# Title\n## Section\n### Sub-section\n#### Sub-sub section\n##### Sub-sub-sub section\n###### Sub-sub-sub-sub section\n(only use a level if the one above is also in use)\nSince we have already defined our title in the YAML header, we will use a section heading to create an Introduction section.\n## Introduction\nYou can make things bold by surrounding the word with double asterisks, **bold**, or double underscores, __bold__; and italicize using single asterisks, *italics*, or single underscores, _italics_.\nYou can also combine bold and italics to write something really important with triple-asterisks, ***really***, or underscores, ___really___; and, if you’re feeling bold (pun intended), you can also use a combination of asterisks and underscores, **_really_**, **_really_**.\nTo create code-type font, surround the word with backticks, `code-type`.\nNow that we’ve learned a couple of things, it might be useful to implement them:\n## Introduction\n\nThis report uses the **tidyverse** package along with the *SAFI* dataset, \nwhich has columns that include:\nThen we can create a list for the variables using -, +, or * keys.\n## Introduction\n\nThis report uses the **tidyverse** package along with the *SAFI* dataset, \nwhich has columns that include:\n\n- village\n- interview_date\n- no_members\n- years_liv\n- respondent_wall_type\n- rooms\nYou can also create an ordered list using numbers:\n1. village\n2. interview_date\n3. no_members\n4. years_liv\n5. respondent_wall_type\n6. rooms\nAnd nested items by tab-indenting:\n- village\n  + Name of village\n- interview_date\n  + Date of interview\n- no_members\n  + How many family members lived in a house\n- years_liv\n  + How many years respondent has lived in village or neighbouring village\n- respondent_wall_type\n  + Type of wall of house\n- rooms\n  + Number of rooms in house\nFor more Markdown syntax see the following reference guide.\nNow we can render the document into HTML by clicking the Knit button in the top of the Source pane (top left), or use the keyboard shortcut Ctrl+Shift+K on Windows and Linux, and Cmd+Shift+K on Mac. If you haven’t saved the document yet, you will be prompted to do so when you Knit for the first time."
  },
  {
    "objectID": "episodes/06-rmarkdown.html#writing-an-r-markdown-report",
    "href": "episodes/06-rmarkdown.html#writing-an-r-markdown-report",
    "title": "Getting started with R Markdown (Optional)",
    "section": "Writing an R Markdown report",
    "text": "Writing an R Markdown report\nNow we will add some R code from our previous data wrangling and visualisation, which means we need to make sure tidyverse is loaded. It is not enough to load tidyverse from the console, we will need to load it within our R Markdown document. The same applies to our data. To load these, we will need to create a ‘code chunk’ at the top of our document (below the YAML header).\nA code chunk can be inserted by clicking Code &gt; Insert Chunk, or by using the keyboard shortcuts Ctrl+Alt+I on Windows and Linux, and Cmd+Option+I on Mac.\nThe syntax of a code chunk is:\n```{r chunk-name}\n\"Here is where you place the R code that you want to run.\"\n```\nAn R Markdown document knows that this text is not part of the report from the ``` that begins and ends the chunk. It also knows that the code inside of the chunk is R code from the r inside of the curly braces ({}). After the r you can add a name for the code chunk . Naming a chunk is optional, but recommended. Each chunk name must be unique, and only contain alphanumeric characters and -.\nTo load tidyverse and our SAFI_clean.csv file, we will insert a chunk and call it ‘setup’. Since we don’t want this code or the output to show in our knitted HTML document, we add an include = FALSE option after the code chunk name ({r setup, include = FALSE}).\n```{r setup, include = FALSE}\nlibrary(tidyverse)\nlibrary(here)\ninterviews &lt;- read_csv(here(\"data/SAFI_clean.csv\"), na = \"NULL\")\n```\n\n\n\n\n\n\nNoneImportant Note!\n\n\n\nThe file paths you give in a .Rmd document, e.g. to load a .csv file, are relative to the .Rmd document, not the project root.\nAs suggested in the Starting with Data episode, we highly recommend the use of the here() function to keep the file paths consistent within your project."
  },
  {
    "objectID": "episodes/06-rmarkdown.html#insert-table",
    "href": "episodes/06-rmarkdown.html#insert-table",
    "title": "Getting started with R Markdown (Optional)",
    "section": "Insert table",
    "text": "Insert table\nNext, we will re-create a table from the Data Wrangling episode which shows the average household size grouped by village and memb_assoc. We can do this by creating a new code chunk and calling it ‘interview-tbl’. Or, you can come up with something more creative (just remember to stick to the naming rules).\nIt isn’t necessary to Knit your document every time you want to see the output. Instead you can run the code chunk with the green triangle in the top right corner of the the chunk, or with the keyboard shortcuts: Ctrl+Alt+C on Windows and Linux, or Cmd+Option+C on Mac.\nTo make sure the table is formatted nicely in our output document, we will need to use the kable() function from the knitr package. The kable() function takes the output of your R code and knits it into a nice looking HTML table. You can also specify different aspects of the table, e.g. the column names, a caption, etc.\nRun the code chunk to make sure you get the desired output.\n\ninterviews %&gt;%\n    filter(!is.na(memb_assoc)) %&gt;%\n    group_by(village, memb_assoc) %&gt;%\n    summarize(mean_no_membrs = mean(no_membrs)) %&gt;%\n  knitr::kable(caption = \"We can also add a caption.\", \n               col.names = c(\"Village\", \"Member Association\", \n                             \"Mean Number of Members\"))\n\n\nWe can also add a caption.\n\n\nVillage\nMember Association\nMean Number of Members\n\n\n\n\nChirodzo\nno\n8.062500\n\n\nChirodzo\nyes\n7.818182\n\n\nGod\nno\n7.133333\n\n\nGod\nyes\n8.000000\n\n\nRuaca\nno\n7.178571\n\n\nRuaca\nyes\n9.500000\n\n\n\n\n\nMany different R packages can be used to generate tables. Some of the more commonly used options are listed in the table below.\n\n\n\nName\nCreator(s)\nDescription\n\n\n\n\ncondformat\nOller Moreno (2022)\nApply and visualize conditional formatting to data frames in R. It renders a data frame with cells formatted according to criteria defined by rules, using a tidy evaluation syntax.\n\n\nDT\nXie et al. (2023)\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny). The ‘DataTables’ library has been included in this R package.\n\n\nformattable\nRen and Russell (2021)\nProvides functions to create formattable vectors and data frames. ‘Formattable’ vectors are printed with text formatting, and formattable data frames are printed with multiple types of formatting in HTML to improve the readability of data presented in tabular form rendered on web pages.\n\n\nflextable\nGohel and Skintzos (2023)\nUse a grammar for creating and customizing pretty tables. The following formats are supported: ‘HTML’, ‘PDF’, ‘RTF’, ‘Microsoft Word’, ‘Microsoft PowerPoint’ and R ‘Grid Graphics’. ‘R Markdown’, ‘Quarto’, and the package ‘officer’ can be used to produce the result files.\n\n\ngt\nIannone et al. (2022)\nBuild display tables from tabular data with an easy-to-use set of functions. With its progressive approach, we can construct display tables with cohesive table parts. Table values can be formatted using any of the included formatting functions.\n\n\nhuxtable\nHugh-Jones (2022)\nCreates styled tables for data presentation. Export to HTML, LaTeX, RTF, ‘Word’, ‘Excel’, and ‘PowerPoint’. Simple, modern interface to manipulate borders, size, position, captions, colours, text styles and number formatting.\n\n\npander\nDaróczi and Tsegelskyi (2022)\nContains some functions catching all messages, ‘stdout’ and other useful information while evaluating R code and other helpers to return user specified text elements (e.g., header, paragraph, table, image, lists etc.) in ‘pandoc’ markdown or several types of R objects similarly automatically transformed to markdown format.\n\n\npixiedust\nNutter and Kretch (2021)\n‘pixiedust’ provides tidy data frames with a programming interface intended to be similar to ’ggplot2’s system of layers with fine-tuned control over each cell of the table.\n\n\nreactable\nLin et al. (2023)\nInteractive data tables for R, based on the ‘React Table’ JavaScript library. Provides an HTML widget that can be used in ‘R Markdown’ or ‘Quarto’ documents, ‘Shiny’ applications, or viewed from an R console.\n\n\nrhandsontable\nOwen et al. (2021)\nAn R interface to the ‘Handsontable’ JavaScript library, which is a minimalist Excel-like data grid editor.\n\n\nstargazer\nHlavac (2022)\nProduces LaTeX code, HTML/CSS code and ASCII text for well-formatted tables that hold regression analysis results from several models side-by-side, as well as summary statistics.\n\n\ntables\nMurdoch (2022)\nComputes and displays complex tables of summary statistics. Output may be in LaTeX, HTML, plain text, or an R matrix for further processing.\n\n\ntangram\nGarbett et al. (2023)\nProvides an extensible formula system to quickly and easily create production quality tables. The processing steps are a formula parser, statistical content generation from data defined by a formula, and rendering into a table.\n\n\nxtable\nDahl et al. (2019)\nCoerce data to LaTeX and HTML tables.\n\n\nztable\nMoon (2021)\nMakes zebra-striped tables (tables with alternating row colors) in LaTeX and HTML formats easily from a data.frame, matrix, lm, aov, anova, glm, coxph, nls, fitdistr, mytable and cbind.mytable objects."
  },
  {
    "objectID": "episodes/06-rmarkdown.html#customising-chunk-output",
    "href": "episodes/06-rmarkdown.html#customising-chunk-output",
    "title": "Getting started with R Markdown (Optional)",
    "section": "Customising chunk output",
    "text": "Customising chunk output\nWe mentioned using include = FALSE in a code chunk to prevent the code and output from printing in the knitted document. There are additional options available to customise how the code-chunks are presented in the output document. The options are entered in the code chunk after chunk-name and separated by commas, e.g. {r chunk-name, eval = FALSE, echo = TRUE}.\n\n\n\n\n\n\n\n\nOption\nOptions\nOutput\n\n\n\n\neval\nTRUE or FALSE\nWhether or not the code within the code chunk should be run.\n\n\necho\nTRUE or FALSE\nChoose if you want to show your code chunk in the output document. echo = TRUE will show the code chunk.\n\n\ninclude\nTRUE or FALSE\nChoose if the output of a code chunk should be included in the document. FALSE means that your code will run, but will not show up in the document.\n\n\nwarning\nTRUE or FALSE\nWhether or not you want your output document to display potential warning messages produced by your code.\n\n\nmessage\nTRUE or FALSE\nWhether or not you want your output document to display potential messages produced by your code.\n\n\nfig.align\ndefault, left, right, center\nWhere the figure from your R code chunk should be output on the page\n\n\n\n\n\n\n\n\n\nNoneTip\n\n\n\n\nThe default settings for the above chunk options are all TRUE.\nThe default settings can be modified per chunk, or with knitr::opts_chunk$set(),\nEntering knitr::opts_chunk$set(echo = FALSE) will change the default of value of echo to FALSE for every code chunk in the document."
  },
  {
    "objectID": "episodes/06-rmarkdown.html#exercise",
    "href": "episodes/06-rmarkdown.html#exercise",
    "title": "Getting started with R Markdown (Optional)",
    "section": "Exercise",
    "text": "Exercise\nPlay around with the different options in the chunk with the code for the table, and re-Knit to see what each option does to the output.\nWhat happens if you use eval = FALSE and echo = FALSE? What is the difference between this and include = FALSE?\n\nSolution (Solution to Exercise). Create a chunk with {r eval = FALSE, echo = FALSE}, then create another chunk with {r include = FALSE} to compare. eval = FALSE and echo = FALSE will neither run the code in the chunk, nor show the code in the knitted document. The code chunk essentially doesn’t exist in the knitted document as it was never run. Whereas include = FALSE will run the code and store the output for later use."
  },
  {
    "objectID": "episodes/06-rmarkdown.html#in-line-r-code",
    "href": "episodes/06-rmarkdown.html#in-line-r-code",
    "title": "Getting started with R Markdown (Optional)",
    "section": "In-line R code",
    "text": "In-line R code\nNow we will use some in-line R code to present some descriptive statistics. To use in-line R-code, we use the same backticks that we used in the Markdown section, with an r to specify that we are generating R-code. The difference between in-line code and a code chunk is the number of backticks. In-line R code uses one backtick (`r`), whereas code chunks use three backticks (```r```).\nFor example, today’s date is `r Sys.Date()`, will be rendered as: today’s date is 2025-11-03.\nThe code will display today’s date in the output document (well, technically the date the document was last knitted).\nThe best way to use in-line R code, is to minimise the amount of code you need to produce the in-line output by preparing the output in code chunks. Let’s say we’re interested in presenting the average household size in a village.\n\n# create a summary data frame with the mean household size by village\nmean_household &lt;- interviews %&gt;%\n    group_by(village) %&gt;%\n    summarize(mean_no_membrs = mean(no_membrs))\n\n# and select the village we want to use\nmean_chirodzo &lt;- mean_household %&gt;%\n  filter(village == \"Chirodzo\")\n\nNow we can make an informative statement on the means of each village, and include the mean values as in-line R-code. For example:\nThe average household size in the village of Chirodzo is `r round(mean_chirodzo$mean_no_membrs, 2)`\nbecomes…\nThe average household size in the village of Chirodzo is 7.08.\nBecause we are using in-line R code instead of the actual values, we have created a dynamic document that will automatically update if we make changes to the dataset and/or code chunks."
  },
  {
    "objectID": "episodes/06-rmarkdown.html#plots",
    "href": "episodes/06-rmarkdown.html#plots",
    "title": "Getting started with R Markdown (Optional)",
    "section": "Plots",
    "text": "Plots\nFinally, we will also include a plot, so our document is a little more colourful and a little less boring. We will use the interview_plotting data from the previous episode.\nIf you were unable to complete the previous lesson or did not save the data, then you can create it in a new code chunk.\n\n## Not run, but can be used to load in data from previous lesson!\ninterviews_plotting &lt;- interviews %&gt;%\n  ## pivot wider by items_owned\n  separate_rows(items_owned, sep = \";\") %&gt;%\n  ## if there were no items listed, changing NA to no_listed_items\n  replace_na(list(items_owned = \"no_listed_items\")) %&gt;%\n  mutate(items_owned_logical = TRUE) %&gt;%\n  pivot_wider(names_from = items_owned, \n              values_from = items_owned_logical, \n              values_fill = list(items_owned_logical = FALSE)) %&gt;%\n  ## pivot wider by months_lack_food\n  separate_rows(months_lack_food, sep = \";\") %&gt;%\n  mutate(months_lack_food_logical = TRUE) %&gt;%\n  pivot_wider(names_from = months_lack_food, \n              values_from = months_lack_food_logical, \n              values_fill = list(months_lack_food_logical = FALSE)) %&gt;%\n  ## add some summary columns\n  mutate(number_months_lack_food = rowSums(select(., Jan:May))) %&gt;%\n  mutate(number_items = rowSums(select(., bicycle:car)))"
  },
  {
    "objectID": "episodes/06-rmarkdown.html#exercise-1",
    "href": "episodes/06-rmarkdown.html#exercise-1",
    "title": "Getting started with R Markdown (Optional)",
    "section": "Exercise",
    "text": "Exercise\nCreate a new code chunk for the plot, and copy the code from any of the plots we created in the previous episode to produce a plot in the chunk. I recommend one of the colourful plots.\nIf you are feeling adventurous, you can also create a new plot with the interviews_plotting data frame.\n\nSolution (Solution to Exercise). \n\ninterviews_plotting %&gt;%\n  ggplot(aes(x = respondent_wall_type)) +\n  geom_bar(aes(fill = village))"
  },
  {
    "objectID": "episodes/06-rmarkdown.html#other-output-options",
    "href": "episodes/06-rmarkdown.html#other-output-options",
    "title": "Getting started with R Markdown (Optional)",
    "section": "Other output options",
    "text": "Other output options\nYou can convert R Markdown to a PDF or a Word document (among others). Click the little triangle next to the Knit button to get a drop-down menu. Or you could put pdf_document or word_document in the initial header of the file.\n---\ntitle: \"My Awesome Report\"\nauthor: \"Emmet Brickowski\"\ndate: \"\"\noutput: word_document\n---\n\n\n\n\n\n\nNoneNote: Creating PDF documents\n\n\n\nCreating .pdf documents may require installation of some extra software. The R package tinytex provides some tools to help make this process easier for R users. With tinytex installed, run tinytex::install_tinytex() to install the required software (you’ll only need to do this once) and then when you Knit to pdf tinytex will automatically detect and install any additional LaTeX packages that are needed to produce the pdf document. Visit the tinytex website for more information.\n\n\n\n\n\n\n\n\nNoneNote: Inserting citations into an R Markdown file\n\n\n\nIt is possible to insert citations into an R Markdown file using the editor toolbar. The editor toolbar includes commonly seen formatting buttons generally seen in text editors (e.g., bold and italic buttons). The toolbar is accessible by using the settings dropdown menu (next to the ‘Knit’ dropdown menu) to select ‘Use Visual Editor’, also accessible through the shortcut ‘Crtl+Shift+F4’. From here, clicking ‘Insert’ allows ‘Citation’ to be selected (shortcut: ‘Crtl+Shift+F8’). For example, searching ‘10.1007/978-3-319-24277-4’ in ‘From DOI’ and inserting will provide the citation for ggplot2 [@wickham2016]. This will also save the citation(s) in ‘references.bib’ in the current working directory. Visit the R Studio website for more information. Tip: obtaining citation information from relevant packages can be done by using citation(\"package\")."
  },
  {
    "objectID": "episodes/06-rmarkdown.html#resources",
    "href": "episodes/06-rmarkdown.html#resources",
    "title": "Getting started with R Markdown (Optional)",
    "section": "Resources",
    "text": "Resources\n\nKnitr in a knutshell tutorial\nDynamic Documents with R and knitr (book)\nR Markdown documentation\nR Markdown cheat sheet\nGetting started with R Markdown\nMarkdown tutorial\nR Markdown: The Definitive Guide (book by Rstudio team)\nReproducible Reporting\nThe Ecosystem of R Markdown\nIntroducing Bookdown\n\n\n\nR Markdown is a useful language for creating reproducible documents combining text and executable R-code.\nSpecify chunk options to control formatting of the output document"
  },
  {
    "objectID": "episodes/data-types.html",
    "href": "episodes/data-types.html",
    "title": "data in R",
    "section": "",
    "text": "In any programming language there are some basic types of data; numeric, character, integer, and logical.\n\n\nA numeric type of data consists the whole number and also number with decimal. In other words we can say a numeric types data consists a numeric with decimal. for example\n\nc(2,3,2.3,5.7,8.9,0,78,80)-&gt;num\nnum\n\n[1]  2.0  3.0  2.3  5.7  8.9  0.0 78.0 80.0\n\nclass(num)\n\n[1] \"numeric\"\n\n\n\n\n\nAn integer type of data consists only the whole number. Or we can say an integer type of data having number without decimal\n\n\n\nA character type of data represented a alphabetic string values. A special type of character string is “factor” which is likely in an order.\n\nc(\"a\",\"hello\",\"B\",\"world\")-&gt;chr\nchr\n\n[1] \"a\"     \"hello\" \"B\"     \"world\"\n\nclass(chr)\n\n[1] \"character\"\n\n\n\n\n\nA logical type of data consists the value either True or False.\n\nc(TRUE,FALSE)-&gt;logi\nlogi\n\n[1]  TRUE FALSE\n\nclass(logi)\n\n[1] \"logical\"\n\n\nNote: You can also specify the class of any vector or variable using\nas.numeric() for numeric type of data as.character for character type of data as.factor\nas.logical"
  },
  {
    "objectID": "episodes/data-types.html#numeric-data-type",
    "href": "episodes/data-types.html#numeric-data-type",
    "title": "data in R",
    "section": "",
    "text": "A numeric type of data consists the whole number and also number with decimal. In other words we can say a numeric types data consists a numeric with decimal. for example\n\nc(2,3,2.3,5.7,8.9,0,78,80)-&gt;num\nnum\n\n[1]  2.0  3.0  2.3  5.7  8.9  0.0 78.0 80.0\n\nclass(num)\n\n[1] \"numeric\""
  },
  {
    "objectID": "episodes/data-types.html#integer-data-type",
    "href": "episodes/data-types.html#integer-data-type",
    "title": "data in R",
    "section": "",
    "text": "An integer type of data consists only the whole number. Or we can say an integer type of data having number without decimal"
  },
  {
    "objectID": "episodes/data-types.html#character-data-type",
    "href": "episodes/data-types.html#character-data-type",
    "title": "data in R",
    "section": "",
    "text": "A character type of data represented a alphabetic string values. A special type of character string is “factor” which is likely in an order.\n\nc(\"a\",\"hello\",\"B\",\"world\")-&gt;chr\nchr\n\n[1] \"a\"     \"hello\" \"B\"     \"world\"\n\nclass(chr)\n\n[1] \"character\""
  },
  {
    "objectID": "episodes/data-types.html#logical-data-type",
    "href": "episodes/data-types.html#logical-data-type",
    "title": "data in R",
    "section": "",
    "text": "A logical type of data consists the value either True or False.\n\nc(TRUE,FALSE)-&gt;logi\nlogi\n\n[1]  TRUE FALSE\n\nclass(logi)\n\n[1] \"logical\"\n\n\nNote: You can also specify the class of any vector or variable using\nas.numeric() for numeric type of data as.character for character type of data as.factor\nas.logical"
  },
  {
    "objectID": "episodes/data-types.html#vector",
    "href": "episodes/data-types.html#vector",
    "title": "data in R",
    "section": "Vector",
    "text": "Vector\nA vector is an ordered collection of basic data types of a given length. The only key thing here is all the elements of a vector must be of the identical data type e.g homogeneous data structures. Vectors are one-dimensional data structures.\nVector is one of the basic data structures in R. It is homogeneous, which means that it only contains elements of the same data type. Data types can be numeric, integer, character, complex, or logical.\nVectors are created by using the c() function. Coercion takes place in a vector, from bottom to top, if the elements passed are of different data types, from logical to integer to double to character.\nThe class() function is used to check the class of the vector.\n\n# Vectors(ordered collection of same data type)\nX = c(1, 3, 5, 7, 8)\nX\n\n[1] 1 3 5 7 8\n\nVec1 &lt;- c(44, 25, 64, 96, 30)\nVec1\n\n[1] 44 25 64 96 30\n\nVec2 &lt;- c(1, FALSE, 9.8, \"hello world\")\nVec2\n\n[1] \"1\"           \"FALSE\"       \"9.8\"         \"hello world\"\n\nclass(X)\n\n[1] \"numeric\"\n\nclass(Vec1)\n\n[1] \"numeric\"\n\nclass(Vec2)\n\n[1] \"character\"\n\n\nElements of a vector can be accessed by using their respective indexes. [ ] brackets are used to specify indexes of the elements to be accessed. For example:\n\nx &lt;- c(\"Jan\",\"Feb\",\"March\",\"Apr\",\"May\",\"June\",\"July\")\nx\n\n[1] \"Jan\"   \"Feb\"   \"March\" \"Apr\"   \"May\"   \"June\"  \"July\" \n\ny &lt;- x[c(3,2,7)]\ny\n\n[1] \"March\" \"Feb\"   \"July\" \n\n\n\nVector Arithmetic\nYou can perform addition, subtraction, multiplication, and division on the vectors having the same number of elements in the following ways:\n\nv1 &lt;- c(4,6,7,31,45)\nv1\n\n[1]  4  6  7 31 45\n\nv2 &lt;- c(54,1,10,86,14,57)\nv2\n\n[1] 54  1 10 86 14 57\n\naddv &lt;- v1+v2\n\nWarning in v1 + v2: longer object length is not a multiple of shorter object\nlength\n\naddv\n\n[1]  58   7  17 117  59  61\n\nsubv &lt;- v1-v2\n\nWarning in v1 - v2: longer object length is not a multiple of shorter object\nlength\n\nsubv\n\n[1] -50   5  -3 -55  31 -53\n\nmultiv &lt;- v1*v2\n\nWarning in v1 * v2: longer object length is not a multiple of shorter object\nlength\n\nmultiv\n\n[1]  216    6   70 2666  630  228\n\ndiviv &lt;- v1/v2\n\nWarning in v1/v2: longer object length is not a multiple of shorter object\nlength\n\ndiviv\n\n[1] 0.07407407 6.00000000 0.70000000 0.36046512 3.21428571 0.07017544\n\n\n\n\nSorting a Vector\nYou can sort the elements of a vector by using the sort() function in the following way:\n\nv &lt;- c(4,78,-45,6,89,678)\nsortv &lt;- sort(v)\nsortv\n\n[1] -45   4   6  78  89 678\n\n#Sort the elements in the reverse order\nrevsortv &lt;- sort(v, decreasing = TRUE)\nrevsortv\n\n[1] 678  89  78   6   4 -45\n\n#Sorting character vectors\nv &lt;- c(\"Jan\",\"Feb\",\"March\",\"April\")\nsortv &lt;- sort(v)\nsortv \n\n[1] \"April\" \"Feb\"   \"Jan\"   \"March\"\n\n#Sorting character vectors in reverse order\nrevsortv &lt;- sort(v, decreasing = TRUE)\nrevsortv\n\n[1] \"March\" \"Jan\"   \"Feb\"   \"April\""
  },
  {
    "objectID": "episodes/data-types.html#lists",
    "href": "episodes/data-types.html#lists",
    "title": "data in R",
    "section": "Lists",
    "text": "Lists\nA list is a generic object consisting of an ordered collection of objects. Lists are heterogeneous data structures. These are also one-dimensional data structures. A list can be a list of vectors, list of matrices, a list of characters and a list of functions and so on.\nA list is a non-homogeneous data structure, which implies that it can contain elements of different data types. It accepts numbers, characters, lists, and even matrices and functions inside it. It is created by using the list() function.\n\n# The first attributes is a numeric vector containing the IDs which is created using the 'c' command here\nId = c(1, 2, 3, 4)\n \n# The second attribute is the name which is created using this line of code here which is the character vector\nName = c(\"Debi\", \"Sandeep\", \"Subham\", \"Shiba\")\n \n# The third attribute is the number of which is a single numeric variable.\nnumber = 4\n \n# We can combine all these three different data types into a list which can be done using a list command\nList = list(Id, Name, number)\nList\n\n[[1]]\n[1] 1 2 3 4\n\n[[2]]\n[1] \"Debi\"    \"Sandeep\" \"Subham\"  \"Shiba\"  \n\n[[3]]\n[1] 4\n\nlist1&lt;- list(\"Sam\", \"Green\", c(8,2,67), TRUE, 51.99, 11.78,FALSE)\nlist1\n\n[[1]]\n[1] \"Sam\"\n\n[[2]]\n[1] \"Green\"\n\n[[3]]\n[1]  8  2 67\n\n[[4]]\n[1] TRUE\n\n[[5]]\n[1] 51.99\n\n[[6]]\n[1] 11.78\n\n[[7]]\n[1] FALSE"
  },
  {
    "objectID": "episodes/data-types.html#accessing-the-elements-of-a-list",
    "href": "episodes/data-types.html#accessing-the-elements-of-a-list",
    "title": "data in R",
    "section": "Accessing the Elements of a List",
    "text": "Accessing the Elements of a List\nThe elements of a list can be accessed by using the indices of those elements.\nFor example:\n\nlist2 &lt;- list(matrix(c(3,9,5,1,-2,8), nrow = 2), c(\"Jan\",\"Feb\",\"Mar\"), list(3,4,5))\nlist2[1]\n\n[[1]]\n     [,1] [,2] [,3]\n[1,]    3    5   -2\n[2,]    9    1    8\n\nlist2[2]\n\n[[1]]\n[1] \"Jan\" \"Feb\" \"Mar\"\n\nlist2[3]\n\n[[1]]\n[[1]][[1]]\n[1] 3\n\n[[1]][[2]]\n[1] 4\n\n[[1]][[3]]\n[1] 5"
  },
  {
    "objectID": "episodes/data-types.html#dataframes",
    "href": "episodes/data-types.html#dataframes",
    "title": "data in R",
    "section": "Dataframes",
    "text": "Dataframes\nDataframes are generic data objects of R which are used to store the tabular data. Data frame is a two-dimensional structure, in which each column contains values of one variable and each row contains one set of values from each column.\nA data frame has the following characteristics:\nA data-frame must have column names and every row should have a unique name. Each column must have the identical number of items. Each item in a single column must be of the same data type. Different columns may have different data types. The column names of a data frame should not be empty. The row names of a data frame should be unique. The data stored in a data frame can be a numeric, factor, or character type. To create a data frame we use the data.frame() function.\n\n##A vector which is a character vector\nName = c(\"Amiya\", \"Raj\", \"Asish\")\n \n# A vector which is a character vector\nLanguage = c(\"R\", \"Python\", \"Java\")\n \n# A vector which is a numeric vector\nAge = c(22, 25, 45)\n \n# To create dataframe use data.frame command and then pass each of the vectors we have created as arguments to the function data.frame()\ndf = data.frame(Name, Language, Age)\ndf\n\n   Name Language Age\n1 Amiya        R  22\n2   Raj   Python  25\n3 Asish     Java  45"
  },
  {
    "objectID": "episodes/data-types.html#matrices",
    "href": "episodes/data-types.html#matrices",
    "title": "data in R",
    "section": "Matrices",
    "text": "Matrices\nA matrix is a rectangular arrangement of numbers in rows and columns. In a matrix, as we know rows are the ones that run horizontally and columns are the ones that run vertically. Matrices are two-dimensional, homogeneous data structures. Now, let’s see how to create a matrix in R. To create a matrix in R you need to use the function called matrix. The arguments to this matrix() are the set of elements in the vector. You have to pass how many numbers of rows and how many numbers of columns you want to have in your matrix and this is the important point you have to remember that by default, matrices are in column-wise order.\nThe basic syntax to create a matrix is given below:\nmatrix(data, nrow, ncol, byrow, dimnames) where, data = the input element of a matrix given as a vector. nrow = the number of rows to be created. ncol = the number of columns to be created. byrow = the row-wise arrangement of the elements instead of column-wise dimnames = the names of columns or rows to be created.\n\nA = matrix(\n     # Taking sequence of elements\n    c(1, 2, 3, 4, 5, 6, 7, 8, 9),\n     \n    # No of rows and columns\n    nrow = 3, ncol = 3, \n \n    # By default matrices are in column-wise order So this parameter decide how to arrange the matrix         \n    byrow = TRUE                            \n)\nA\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\nM1 &lt;- matrix(c(1:9), nrow = 3, ncol =3, byrow= TRUE)\nM1\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\nM2 &lt;-  matrix(c(1:9), nrow = 3, ncol =3, byrow= FALSE)\nM2\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nBy using row and column names, a matrix can be created as follows:\n\nrownames = c(\"row1\", \"row2\", \"row3\")\ncolnames = c(\"col1\", \"col2\", \"col3\")\nM3 &lt;- matrix(c(1:9), nrow = 3, byrow = TRUE, dimnames = list(rownames, colnames))\nM3\n\n     col1 col2 col3\nrow1    1    2    3\nrow2    4    5    6\nrow3    7    8    9\n\n\n\nAccessing the Elements of a Matrix\nTo access the elements of a matrix, row and column indices are used in the following ways: For accessing the elements of the matrix M3 created above, use the following syntax:\n\nM3[1,1] # first argument represent row number and second argument represent column number\n\n[1] 1\n\nM3[3,3]\n\n[1] 9\n\nM3[2,3]\n\n[1] 6"
  },
  {
    "objectID": "episodes/data-types.html#arrays",
    "href": "episodes/data-types.html#arrays",
    "title": "data in R",
    "section": "Arrays",
    "text": "Arrays\nArrays are the R data objects which store the data in more than two dimensions. Arrays are n-dimensional data structures. For example, if we create an array of dimensions (2, 3, 3) then it creates 3 rectangular matrices each with 2 rows and 3 columns. They are homogeneous data structures.\nNow, let’s see how to create arrays in R. To create an array in R you need to use the function called array(). The arguments to this array() are the set of elements in vectors and you have to pass a vector containing the dimensions of the array.\n\nA = array(\n    # Taking sequence of elements\n    c(1, 2, 3, 4, 5, 6, 7, 8),\n \n    # Creating two rectangular matrices each with two rows and two columns\n    dim = c(2, 2, 2)                       \n)\nA\n\n, , 1\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n, , 2\n\n     [,1] [,2]\n[1,]    5    7\n[2,]    6    8"
  },
  {
    "objectID": "episodes/data-types.html#factors",
    "href": "episodes/data-types.html#factors",
    "title": "data in R",
    "section": "Factors",
    "text": "Factors\nFactors are the data objects which are used to categorize the data and store it as levels. They are useful for storing categorical data. They can store both strings and integers. They are useful to categorize unique values in columns like TRUE or FALSE, or MALE or FEMALE, etc.. They are useful in data analysis for statistical modeling.\nFactors can be created using the as.factor() function and they take vectors as inputs. For example:\n\nfac = factor(c(\"Male\", \"Female\", \"Male\",\n               \"Male\", \"Female\", \"Male\", \"Female\"))\nfac \n\n[1] Male   Female Male   Male   Female Male   Female\nLevels: Female Male\n\ndata &lt;- c(\"Male\",\"Female\",\"Male\",\"Child\",\"Child\",\"Male\",\"Female\",\"Female\")\ndata\n\n[1] \"Male\"   \"Female\" \"Male\"   \"Child\"  \"Child\"  \"Male\"   \"Female\" \"Female\"\n\nfactordata &lt;- as.factor(data)\nfactordata\n\n[1] Male   Female Male   Child  Child  Male   Female Female\nLevels: Child Female Male\n\n\nNow, let’s see how to create factors in R. To create a factor in R you need to use the function called factor(). The argument to this factor() is the vector."
  },
  {
    "objectID": "episodes/reshaping-data.html",
    "href": "episodes/reshaping-data.html",
    "title": "Efficient reshaping using data.tables",
    "section": "",
    "text": "The melt and dcast functions for data.tables are for reshaping wide-to-long and long-to-wide, respectively\nThe extended functionalities are in line with data.table’s philosophy of performing operations efficiently and in a straightforward manner.\n\nDefault functionality\n\n\nmelting data.tables (wide to long) Suppose we have a data.table (artificial data) as shown below:\n\ns1 &lt;- “family_id age_mother dob_child1 dob_child2 dob_child3 1 30 1998-11-26 2000-01-29 NA 2 27 1996-06-22 NA NA 3 26 2002-07-11 2004-04-05 2007-09-02 4 32 2004-10-10 2009-08-27 2012-07-21 5 29 2000-12-05 2005-02-28 NA” DT &lt;- fread(s1) DT # family_id age_mother dob_child1 dob_child2 dob_child3 # 1: 1 30 1998-11-26 2000-01-29  # 2: 2 27 1996-06-22   # 3: 3 26 2002-07-11 2004-04-05 2007-09-02 # 4: 4 32 2004-10-10 2009-08-27 2012-07-21 # 5: 5 29 2000-12-05 2005-02-28  ## dob stands for date of birth.\nstr(DT) # Classes ‘data.table’ and ‘data.frame’: 5 obs. of 5 variables: # $ family_id : int 1 2 3 4 5 # $ age_mother: int 30 27 26 32 29 # $ dob_child1: IDate, format: “1998-11-26” “1996-06-22” “2002-07-11” … # $ dob_child2: IDate, format: “2000-01-29” NA “2004-04-05” … # $ dob_child3: IDate, format: NA NA “2007-09-02” … # - attr(*, “.internal.selfref”)= - Convert DT to long form where each dob is a separate observation. We could accomplish this using melt() by specifying id.vars and measure.vars arguments as follows:\nDT.m1 = melt(DT, id.vars = c(“family_id”, “age_mother”), measure.vars = c(“dob_child1”, “dob_child2”, “dob_child3”)) DT.m1 # family_id age_mother variable value # 1: 1 30 dob_child1 1998-11-26 # 2: 2 27 dob_child1 1996-06-22 # 3: 3 26 dob_child1 2002-07-11 # 4: 4 32 dob_child1 2004-10-10 # 5: 5 29 dob_child1 2000-12-05 # 6: 1 30 dob_child2 2000-01-29 # 7: 2 27 dob_child2  # 8: 3 26 dob_child2 2004-04-05 # 9: 4 32 dob_child2 2009-08-27 # 10: 5 29 dob_child2 2005-02-28 # 11: 1 30 dob_child3  # 12: 2 27 dob_child3  # 13: 3 26 dob_child3 2007-09-02 # 14: 4 32 dob_child3 2012-07-21 # 15: 5 29 dob_child3  str(DT.m1) # Classes ‘data.table’ and ‘data.frame’: 15 obs. of 4 variables: # $ family_id : int 1 2 3 4 5 1 2 3 4 5 … # $ age_mother: int 30 27 26 32 29 30 27 26 32 29 … # $ variable : Factor w/ 3 levels “dob_child1”,“dob_child2”,..: 1 1 1 1 1 2 2 2 2 2 … # $ value : IDate, format: “1998-11-26” “1996-06-22” “2002-07-11” … # - attr(*, “.internal.selfref”)= measure.vars specify the set of columns we would like to collapse (or combine) together.\nWe can also specify column indices instead of names.\nBy default, variable column is of type factor. Set variable.factor argument to FALSE if you’d like to return a character vector instead.\nBy default, the molten columns are automatically named variable and value.\nmelt preserves column attributes in result.\n\nName the variable and value columns to child and dob respectively DT.m1 = melt(DT, measure.vars = c(“dob_child1”, “dob_child2”, “dob_child3”), variable.name = “child”, value.name = “dob”) DT.m1 # family_id age_mother child dob # 1: 1 30 dob_child1 1998-11-26 # 2: 2 27 dob_child1 1996-06-22 # 3: 3 26 dob_child1 2002-07-11 # 4: 4 32 dob_child1 2004-10-10 # 5: 5 29 dob_child1 2000-12-05 # 6: 1 30 dob_child2 2000-01-29 # 7: 2 27 dob_child2  # 8: 3 26 dob_child2 2004-04-05 # 9: 4 32 dob_child2 2009-08-27 # 10: 5 29 dob_child2 2005-02-28 # 11: 1 30 dob_child3  # 12: 2 27 dob_child3  # 13: 3 26 dob_child3 2007-09-02 # 14: 4 32 dob_child3 2012-07-21 # 15: 5 29 dob_child3  By default, when one of id.vars or measure.vars is missing, the rest of the columns are automatically assigned to the missing argument.\n\nWhen neither id.vars nor measure.vars are specified, as mentioned under ?melt, all non-numeric, integer, logical columns will be assigned to id.vars.\nIn addition, a warning message is issued highlighting the columns that are automatically considered to be id.vars.\n\ndcasting data.tables (long to wide) In the previous section, we saw how to get from wide form to long form. Let’s see the reverse operation in this section.\n\n\nHow can we get back to the original data table DT from DT.m? That is, we’d like to collect all child observations corresponding to each family_id, age_mother together under the same row. We can accomplish it using dcast as follows:\n\ndcast(DT.m1, family_id + age_mother ~ child, value.var = “dob”) # family_id age_mother dob_child1 dob_child2 dob_child3 # 1: 1 30 1998-11-26 2000-01-29  # 2: 2 27 1996-06-22   # 3: 3 26 2002-07-11 2004-04-05 2007-09-02 # 4: 4 32 2004-10-10 2009-08-27 2012-07-21 # 5: 5 29 2000-12-05 2005-02-28  dcast uses formula interface. The variables on the LHS of formula represents the id vars and RHS the measure vars.\nvalue.var denotes the column to be filled in with while casting to wide format.\ndcast also tries to preserve attributes in result wherever possible.\n\nStarting from DT.m, how can we get the number of children in each family? You can also pass a function to aggregate by in dcast with the argument fun.aggregate. This is particularly essential when the formula provided does not identify single observation for each cell.\n\ndcast(DT.m1, family_id ~ ., fun.agg = function(x) sum(!is.na(x)), value.var = “dob”) # family_id . # 1: 1 2 # 2: 2 1 # 3: 3 3 # 4: 4 3 # 5: 5 2 Check ?dcast for other useful arguments and additional examples.\n\nLimitations in current melt/dcast approaches So far we’ve seen features of melt and dcast that are implemented efficiently for data.tables, using internal data.table machinery (fast radix ordering, binary search etc..).\n\nHowever, there are situations we might run into where the desired operation is not expressed in a straightforward manner. For example, consider the data.table shown below:\ns2 &lt;- “family_id age_mother dob_child1 dob_child2 dob_child3 gender_child1 gender_child2 gender_child3 1 30 1998-11-26 2000-01-29 NA 1 2 NA 2 27 1996-06-22 NA NA 2 NA NA 3 26 2002-07-11 2004-04-05 2007-09-02 2 2 1 4 32 2004-10-10 2009-08-27 2012-07-21 1 1 1 5 29 2000-12-05 2005-02-28 NA 2 1 NA” DT &lt;- fread(s2) DT # family_id age_mother dob_child1 dob_child2 dob_child3 gender_child1 gender_child2 gender_child3 # 1: 1 30 1998-11-26 2000-01-29  1 2 NA # 2: 2 27 1996-06-22   2 NA NA # 3: 3 26 2002-07-11 2004-04-05 2007-09-02 2 2 1 # 4: 4 32 2004-10-10 2009-08-27 2012-07-21 1 1 1 # 5: 5 29 2000-12-05 2005-02-28  2 1 NA ## 1 = female, 2 = male And you’d like to combine (melt) all the dob columns together, and gender columns together. Using the current functionality, we can do something like this:\nDT.m1 = melt(DT, id = c(“family_id”, “age_mother”)) DT.m1[, c(“variable”, “child”) := tstrsplit(variable, “_“, fixed = TRUE)] DT.c1 = dcast(DT.m1, family_id + age_mother + child ~ variable, value.var = “value”) DT.c1 # family_id age_mother child dob gender # 1: 1 30 child1 1998-11-26 1970-01-02 # 2: 1 30 child2 2000-01-29 1970-01-03 # 3: 1 30 child3   # 4: 2 27 child1 1996-06-22 1970-01-03 # 5: 2 27 child2   # 6: 2 27 child3   # 7: 3 26 child1 2002-07-11 1970-01-03 # 8: 3 26 child2 2004-04-05 1970-01-03 # 9: 3 26 child3 2007-09-02 1970-01-02 # 10: 4 32 child1 2004-10-10 1970-01-02 # 11: 4 32 child2 2009-08-27 1970-01-02 # 12: 4 32 child3 2012-07-21 1970-01-02 # 13: 5 29 child1 2000-12-05 1970-01-03 # 14: 5 29 child2 2005-02-28 1970-01-02 # 15: 5 29 child3  \nstr(DT.c1) ## gender column is character type now! # Classes ‘data.table’ and ‘data.frame’: 15 obs. of 5 variables: # $ family_id : int 1 1 1 2 2 2 3 3 3 4 … # $ age_mother: int 30 30 30 27 27 27 26 26 26 32 … # $ child : chr “child1” “child2” “child3” “child1” … # $ dob : IDate, format: “1998-11-26” “2000-01-29” NA … # $ gender : IDate, format: “1970-01-02” “1970-01-03” NA … # - attr(, “.internal.selfref”)= # - attr(, “sorted”)= chr [1:3] “family_id” “age_mother” “child” Issues What we wanted to do was to combine all the dob and gender type columns together respectively. Instead we are combining everything together, and then splitting them again. I think it’s easy to see that it’s quite roundabout (and inefficient).\nAs an analogy, imagine you’ve a closet with four shelves of clothes and you’d like to put together the clothes from shelves 1 and 2 together (in 1), and 3 and 4 together (in 3). What we are doing is more or less to combine all the clothes together, and then split them back on to shelves 1 and 3!\nThe columns to melt may be of different types, as in this case (character and integer types). By melting them all together, the columns will be coerced in result, as explained by the warning message above and shown from output of str(DT.c1), where gender has been converted to character type.\nWe are generating an additional column by splitting the variable column into two columns, whose purpose is quite cryptic. We do it because we need it for casting in the next step.\nFinally, we cast the data set. But the issue is it’s a much more computationally involved operation than melt. Specifically, it requires computing the order of the variables in formula, and that’s costly.\nIn fact, stats::reshape is capable of performing this operation in a very straightforward manner. It is an extremely useful and often underrated function. You should definitely give it a try!\n\nEnhanced (new) functionality\n\n\nEnhanced melt Since we’d like for data.tables to perform this operation straightforward and efficient using the same interface, we went ahead and implemented an additional functionality, where we can melt to multiple columns simultaneously.\n\n\nmelt multiple columns simultaneously The idea is quite simple. We pass a list of columns to measure.vars, where each element of the list contains the columns that should be combined together.\n\ncolA = paste(“dob_child”, 1:3, sep = ““) colB = paste(”gender_child”, 1:3, sep = ““) DT.m2 = melt(DT, measure = list(colA, colB), value.name = c(”dob”, “gender”)) DT.m2 # family_id age_mother variable dob gender # 1: 1 30 1 1998-11-26 1 # 2: 2 27 1 1996-06-22 2 # 3: 3 26 1 2002-07-11 2 # 4: 4 32 1 2004-10-10 1 # 5: 5 29 1 2000-12-05 2 # 6: 1 30 2 2000-01-29 2 # 7: 2 27 2  NA # 8: 3 26 2 2004-04-05 2 # 9: 4 32 2 2009-08-27 1 # 10: 5 29 2 2005-02-28 1 # 11: 1 30 3  NA # 12: 2 27 3  NA # 13: 3 26 3 2007-09-02 1 # 14: 4 32 3 2012-07-21 1 # 15: 5 29 3  NA\nstr(DT.m2) ## col type is preserved # Classes ‘data.table’ and ‘data.frame’: 15 obs. of 5 variables: # $ family_id : int 1 2 3 4 5 1 2 3 4 5 … # $ age_mother: int 30 27 26 32 29 30 27 26 32 29 … # $ variable : Factor w/ 3 levels “1”,“2”,“3”: 1 1 1 1 1 2 2 2 2 2 … # $ dob : IDate, format: “1998-11-26” “1996-06-22” “2002-07-11” … # $ gender : int 1 2 2 1 2 2 NA 2 1 1 … # - attr(*, “.internal.selfref”)= - Using patterns() Usually in these problems, the columns we’d like to melt can be distinguished by a common pattern. We can use the function patterns(), implemented for convenience, to provide regular expressions for the columns to be combined together. The above operation can be rewritten as:\nDT.m2 = melt(DT, measure = patterns(“^dob”, “^gender”), value.name = c(“dob”, “gender”)) DT.m2 # family_id age_mother variable dob gender # 1: 1 30 1 1998-11-26 1 # 2: 2 27 1 1996-06-22 2 # 3: 3 26 1 2002-07-11 2 # 4: 4 32 1 2004-10-10 1 # 5: 5 29 1 2000-12-05 2 # 6: 1 30 2 2000-01-29 2 # 7: 2 27 2  NA # 8: 3 26 2 2004-04-05 2 # 9: 4 32 2 2009-08-27 1 # 10: 5 29 2 2005-02-28 1 # 11: 1 30 3  NA # 12: 2 27 3  NA # 13: 3 26 3 2007-09-02 1 # 14: 4 32 3 2012-07-21 1 # 15: 5 29 3  NA That’s it!\nWe can remove the variable column if necessary.\nThe functionality is implemented entirely in C, and is therefore both fast and memory efficient in addition to being straightforward.\n\nEnhanced dcast Okay great! We can now melt into multiple columns simultaneously. Now given the data set DT.m2 as shown above, how can we get back to the same format as the original data we started with?\n\nIf we use the current functionality of dcast, then we’d have to cast twice and bind the results together. But that’s once again verbose, not straightforward and is also inefficient.\n\nCasting multiple value.vars simultaneously We can now provide multiple value.var columns to dcast for data.tables directly so that the operations are taken care of internally and efficiently.\n\n\n\nDT.c2 = dcast(DT.m2, family_id + age_mother ~ variable, value.var = c(“dob”, “gender”)) DT.c2 # family_id age_mother dob_1 dob_2 dob_3 gender_1 gender_2 gender_3 # 1: 1 30 1998-11-26 2000-01-29  1 2 NA # 2: 2 27 1996-06-22   2 NA NA # 3: 3 26 2002-07-11 2004-04-05 2007-09-02 2 2 1 # 4: 4 32 2004-10-10 2009-08-27 2012-07-21 1 1 1 # 5: 5 29 2000-12-05 2005-02-28  2 1 NA Attributes are preserved in result wherever possible.\nEverything is taken care of internally, and efficiently. In addition to being fast, it is also very memory efficient.\nMultiple functions to fun.aggregate: You can also provide multiple functions to fun.aggregate to dcast for data.tables. Check the examples in ?dcast which illustrates this functionality."
  },
  {
    "objectID": "episodes/reshaping-data.html#new-cast-functionality---multiple-value.vars",
    "href": "episodes/reshaping-data.html#new-cast-functionality---multiple-value.vars",
    "title": "Efficient reshaping using data.tables",
    "section": "",
    "text": "DT.c2 = dcast(DT.m2, family_id + age_mother ~ variable, value.var = c(“dob”, “gender”)) DT.c2 # family_id age_mother dob_1 dob_2 dob_3 gender_1 gender_2 gender_3 # 1: 1 30 1998-11-26 2000-01-29  1 2 NA # 2: 2 27 1996-06-22   2 NA NA # 3: 3 26 2002-07-11 2004-04-05 2007-09-02 2 2 1 # 4: 4 32 2004-10-10 2009-08-27 2012-07-21 1 1 1 # 5: 5 29 2000-12-05 2005-02-28  2 1 NA Attributes are preserved in result wherever possible.\nEverything is taken care of internally, and efficiently. In addition to being fast, it is also very memory efficient.\nMultiple functions to fun.aggregate: You can also provide multiple functions to fun.aggregate to dcast for data.tables. Check the examples in ?dcast which illustrates this functionality."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "r",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "00-intro.html",
    "href": "00-intro.html",
    "title": "1  Before we Start",
    "section": "",
    "text": "1.1 What is R? What is RStudio?\nThe term “R” is used to refer to both the programming language and the software that interprets the scripts written using it.\nRStudio is currently a very popular way to not only write your R scripts but also to interact with the R software. To function correctly, RStudio needs R and therefore both need to be installed on your computer.\nTo make it easier to interact with R, we will use RStudio. RStudio is the most popular IDE (Integrated Development Environment) for R. An IDE is a piece of software that provides tools to make programming easier.\nYou can also use the R Presentations feature to present your work in an HTML5 presentation mixing Markdown and R code. You can display these within R Studio or your browser. There are many options for customising your presentation slides, including an option for showing LaTeX equations. This can help you collaborate with others and also has an application in teaching and classroom use.\nBecause the install process accesses the CRAN repository, you will need an Internet connection to install packages.\nIt is also possible to install packages from other repositories, as well as Github or the local file system, but we won’t be looking at these options in this lesson.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Before we Start</span>"
    ]
  },
  {
    "objectID": "00-intro.html#why-learn-r",
    "href": "00-intro.html#why-learn-r",
    "title": "1  Before we Start",
    "section": "1.2 Why learn R?",
    "text": "1.2 Why learn R?\n\n1.2.1 R does not involve lots of pointing and clicking, and that’s a good thing\nThe learning curve might be steeper than with other software but with R, the results of your analysis do not rely on remembering a succession of pointing and clicking, but instead on a series of written commands, and that’s a good thing! So, if you want to redo your analysis because you collected more data, you don’t have to remember which button you clicked in which order to obtain your results; you just have to run your script again.\nWorking with scripts makes the steps you used in your analysis clear, and the code you write can be inspected by someone else who can give you feedback and spot mistakes.\nWorking with scripts forces you to have a deeper understanding of what you are doing, and facilitates your learning and comprehension of the methods you use.\n\n\n1.2.2 R code is great for reproducibility\nReproducibility is when someone else (including your future self) can obtain the same results from the same dataset when using the same analysis.\nR integrates with other tools to generate manuscripts from your code. If you collect more data, or fix a mistake in your dataset, the figures and the statistical tests in your manuscript are updated automatically.\nAn increasing number of journals and funding agencies expect analyses to be reproducible, so knowing R will give you an edge with these requirements.\nTo further support reproducibility and transparency, there are also packages that help you with dependency management: keeping track of which packages we are loading and how they depend on the package version you are using. This helps you make sure existing workflows work consistently and continue doing what they did before.\nPackages like renv let you “save” and “load” the state of your project library, also keeping track of the package version you use and the source it can be retrieved from.\n\n\n1.2.3 R is interdisciplinary and extensible\nWith 10,000+ packages that can be installed to extend its capabilities, R provides a framework that allows you to combine statistical approaches from many scientific disciplines to best suit the analytical framework you need to analyze your data. For instance, R has packages for image analysis, GIS, time series, population genetics, and a lot more.\n\n\n1.2.4 R works on data of all shapes and sizes\nThe skills you learn with R scale easily with the size of your dataset. Whether your dataset has hundreds or millions of lines, it won’t make much difference to you.\nR is designed for data analysis. It comes with special data structures and data types that make handling of missing data and statistical factors convenient.\nR can connect to spreadsheets, databases, and many other data formats, on your computer or on the web.\n\n\n1.2.5 R produces high-quality graphics\nThe plotting functionalities in R are endless, and allow you to adjust any aspect of your graph to convey most effectively the message from your data.\n\n\n1.2.6 R has a large and welcoming community\nThousands of people use R daily. Many of them are willing to help you through mailing lists and websites such as Stack Overflow, or on the RStudio community. Questions which are backed up with short, reproducible code snippets are more likely to attract knowledgeable responses.\n\n\n1.2.7 Not only is R free, but it is also open-source and cross-platform\nAnyone can inspect the source code to see how R works. Because of this transparency, there is less chance for mistakes, and if you (or someone else) find some, you can report and fix bugs.\nBecause R is open source and is supported by a large community of developers and users, there is a very large selection of third-party add-on packages which are freely available to extend R’s native capabilities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRStudio extends what R can do, and makes it easier to write R code and interact with R. Left photo credit; Right photo credit.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Before we Start</span>"
    ]
  },
  {
    "objectID": "00-intro.html#a-tour-of-rstudio",
    "href": "00-intro.html#a-tour-of-rstudio",
    "title": "1  Before we Start",
    "section": "1.3 A tour of RStudio",
    "text": "1.3 A tour of RStudio",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Before we Start</span>"
    ]
  },
  {
    "objectID": "00-intro.html#knowing-your-way-around-rstudio",
    "href": "00-intro.html#knowing-your-way-around-rstudio",
    "title": "1  Before we Start",
    "section": "1.4 Knowing your way around RStudio",
    "text": "1.4 Knowing your way around RStudio\nLet’s start by learning about RStudio, which is an Integrated Development Environment (IDE) for working with R.\nThe RStudio IDE open-source product is free under the Affero General Public License (AGPL) v3. The RStudio IDE is also available with a commercial license and priority email support from RStudio, Inc.\nWe will use the RStudio IDE to write code, navigate the files on our computer, inspect the variables we create, and visualize the plots we generate. RStudio can also be used for other things (e.g., version control, developing packages, writing Shiny apps) that we will not cover during the workshop.\nOne of the advantages of using RStudio is that all the information you need to write code is available in a single window. Additionally, RStudio provides many shortcuts, autocompletion, and highlighting for the major file types you use while developing in R. RStudio makes typing easier and less error-prone.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Before we Start</span>"
    ]
  },
  {
    "objectID": "00-intro.html#getting-set-up",
    "href": "00-intro.html#getting-set-up",
    "title": "1  Before we Start",
    "section": "1.5 Getting set up",
    "text": "1.5 Getting set up\nIt is good practice to keep a set of related data, analyses, and text self-contained in a single folder called the working directory. All of the scripts within this folder can then use relative paths to files. Relative paths indicate where inside the project a file is located (as opposed to absolute paths, which point to where a file is on a specific computer). Working this way makes it a lot easier to move your project around on your computer and share it with others without having to directly modify file paths in the individual scripts.\nRStudio provides a helpful set of tools to do this through its “Projects” interface, which not only creates a working directory for you but also remembers its location (allowing you to quickly navigate to it). The interface also (optionally) preserves custom settings and open files to make it easier to resume work after a break.\n\n1.5.1 Create a new project\n\nUnder the File menu, click on New project, choose New directory, then New project\nEnter a name for this new folder (or “directory”) and choose a convenient location for it. This will be your working directory for the rest of the day (e.g., ~/data-carpentry)\nClick on Create project\nCreate a new file where we will type our scripts. Go to File &gt; New File &gt; R script. Click the save icon on your toolbar and save your script as “script.R”.\n\nThe simplest way to open an RStudio project once it has been created is to navigate through your files to where the project was saved and double click on the .Rproj (blue cube) file. This will open RStudio and start your R session in the same directory as the .Rproj file. All your data, plots and scripts will now be relative to the project directory. RStudio projects have the added benefit of allowing you to open multiple projects at the same time each open to its own project directory. This allows you to keep multiple projects open without them interfering with each other.\n\n\n1.5.2 The RStudio Interface\nLet’s take a quick tour of RStudio.\n\nRStudio is divided into four “panes”. The placement of these panes and their content can be customized (see menu, Tools -&gt; Global Options -&gt; Pane Layout).\nThe Default Layout is:\n\nTop Left - Source: your scripts and documents\nBottom Left - Console: what R would look and be like without RStudio\nTop Right - Environment/History: look here to see what you have done\nBottom Right - Files and more: see the contents of the project/working directory here, like your Script.R file\n\n\n\n1.5.3 Organizing your working directory\nUsing a consistent folder structure across your projects will help keep things organized and make it easy to find/file things in the future. This can be especially helpful when you have multiple projects. In general, you might create directories (folders) for scripts, data, and documents. Here are some examples of suggested directories:\n\ndata/ Use this folder to store your raw data and intermediate datasets. For the sake of transparency and provenance, you should always keep a copy of your raw data accessible and do as much of your data cleanup and preprocessing programmatically (i.e., with scripts, rather than manually) as possible.\ndata_output/ When you need to modify your raw data, it might be useful to store the modified versions of the datasets in a different folder.\ndocuments/ Used for outlines, drafts, and other text.\nfig_output/ This folder can store the graphics that are generated by your scripts.\nscripts/ A place to keep your R scripts for different analyses or plotting.\n\nYou may want additional directories or subdirectories depending on your project needs, but these should form the backbone of your working directory.\n\n\n\n1.5.4 The working directory\nThe working directory is an important concept to understand. It is the place where R will look for and save files. When you write code for your project, your scripts should refer to files in relation to the root of your working directory and only to files within this structure.\nUsing RStudio projects makes this easy and ensures that your working directory is set up properly. If you need to check it, you can use getwd(). If for some reason your working directory is not the same as the location of your RStudio project, it is likely that you opened an R script or RMarkdown file not your .Rproj file. You should close out of RStudio and open the .Rproj file by double clicking on the blue cube! If you ever need to modify your working directory in a script, setwd('my/path') changes the working directory. This should be used with caution since it makes analyses hard to share across devices and with other users.\n\n\n1.5.5 Downloading the data and getting set up\nFor this lesson we will use the following folders in our working directory: data/, data_output/ and fig_output/. Let’s write them all in lowercase to be consistent. We can create them using the RStudio interface by clicking on the “New Folder” button in the file pane (bottom right), or directly from R by typing at console:\n\ndir.create(\"data\")\ndir.create(\"data_output\")\ndir.create(\"fig_output\")\n\nYou can either download the data used for this lesson from GitHub or with R. You can copy the data from this GitHub link and paste it into a file called SAFI_clean.csv in the data/ directory you just created. Or you can do this directly from R by copying and pasting this in your terminal (your instructor can place this chunk of code in the Etherpad):\n\ndownload.file(\n  \"https://raw.githubusercontent.com/datacarpentry/r-socialsci/main/episodes/data/SAFI_clean.csv\",\n  \"data/SAFI_clean.csv\", mode = \"wb\"\n  )",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Before we Start</span>"
    ]
  },
  {
    "objectID": "00-intro.html#interacting-with-r",
    "href": "00-intro.html#interacting-with-r",
    "title": "1  Before we Start",
    "section": "1.6 Interacting with R",
    "text": "1.6 Interacting with R\nThe basis of programming is that we write down instructions for the computer to follow, and then we tell the computer to follow those instructions. We write, or code, instructions in R because it is a common language that both the computer and we can understand. We call the instructions commands and we tell the computer to follow the instructions by executing (also called running) those commands.\nThere are two main ways of interacting with R: by using the console or by using script files (plain text files that contain your code). The console pane (in RStudio, the bottom left panel) is the place where commands written in the R language can be typed and executed immediately by the computer. It is also where the results will be shown for commands that have been executed. You can type commands directly into the console and press Enter to execute those commands, but they will be forgotten when you close the session.\nBecause we want our code and workflow to be reproducible, it is better to type the commands we want in the script editor and save the script. This way, there is a complete record of what we did, and anyone (including our future selves!) can easily replicate the results on their computer.\nRStudio allows you to execute commands directly from the script editor by using the Ctrl + Enter shortcut (on Mac, Cmd + Return will work). The command on the current line in the script (indicated by the cursor) or all of the commands in selected text will be sent to the console and executed when you press Ctrl + Enter. If there is information in the console you do not need anymore, you can clear it with Ctrl + L. You can find other keyboard shortcuts in this RStudio cheatsheet about the RStudio IDE.\nAt some point in your analysis, you may want to check the content of a variable or the structure of an object without necessarily keeping a record of it in your script. You can type these commands and execute them directly in the console. RStudio provides the Ctrl + 1 and Ctrl + 2 shortcuts allow you to jump between the script and the console panes.\nIf R is ready to accept commands, the R console shows a &gt; prompt. If R receives a command (by typing, copy-pasting, or sent from the script editor using Ctrl + Enter), R will try to execute it and, when ready, will show the results and come back with a new &gt; prompt to wait for new commands.\nIf R is still waiting for you to enter more text, the console will show a + prompt. It means that you haven’t finished entering a complete command. This is likely because you have not ‘closed’ a parenthesis or quotation, i.e. you don’t have the same number of left-parentheses as right-parentheses or the same number of opening and closing quotation marks. When this happens, and you thought you finished typing your command, click inside the console window and press Esc; this will cancel the incomplete command and return you to the &gt; prompt. You can then proofread the command(s) you entered and correct the error.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Before we Start</span>"
    ]
  },
  {
    "objectID": "00-intro.html#installing-additional-packages-using-the-packages-tab",
    "href": "00-intro.html#installing-additional-packages-using-the-packages-tab",
    "title": "1  Before we Start",
    "section": "1.7 Installing additional packages using the packages tab",
    "text": "1.7 Installing additional packages using the packages tab\nIn addition to the core R installation, there are in excess of 10,000 additional packages which can be used to extend the functionality of R. Many of these have been written by R users and have been made available in central repositories, like the one hosted at CRAN, for anyone to download and install into their own R environment. You should have already installed the packages ‘ggplot2’ and ’dplyr. If you have not, please do so now using these instructions.\nYou can see if you have a package installed by looking in the packages tab (on the lower-right by default). You can also type the command installed.packages() into the console and examine the output.\n\nAdditional packages can be installed from the ‘packages’ tab. On the packages tab, click the ‘Install’ icon and start typing the name of the package you want in the text box. As you type, packages matching your starting characters will be displayed in a drop-down list so that you can select them.\n\nAt the bottom of the Install Packages window is a check box to ‘Install’ dependencies. This is ticked by default, which is usually what you want. Packages can (and do) make use of functionality built into other packages, so for the functionality contained in the package you are installing to work properly, there may be other packages which have to be installed with them. The ‘Install dependencies’ option makes sure that this happens.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Before we Start</span>"
    ]
  },
  {
    "objectID": "00-intro.html#exercise",
    "href": "00-intro.html#exercise",
    "title": "1  Before we Start",
    "section": "1.8 Exercise",
    "text": "1.8 Exercise\nUse both the Console and the Packages tab to confirm that you have the tidyverse installed.\n\nSolution (Solution). Scroll through packages tab down to ‘tidyverse’. You can also type a few characters into the searchbox. The ‘tidyverse’ package is really a package of packages, including ‘ggplot2’ and ‘dplyr’, both of which require other packages to run correctly. All of these packages will be installed automatically. Depending on what packages have previously been installed in your R environment, the install of ‘tidyverse’ could be very quick or could take several minutes. As the install proceeds, messages relating to its progress will be written to the console. You will be able to see all of the packages which are actually being installed.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Before we Start</span>"
    ]
  },
  {
    "objectID": "00-intro.html#installing-additional-packages-using-r-code",
    "href": "00-intro.html#installing-additional-packages-using-r-code",
    "title": "1  Before we Start",
    "section": "1.9 Installing additional packages using R code",
    "text": "1.9 Installing additional packages using R code\nIf you were watching the console window when you started the install of ‘tidyverse’, you may have noticed that the line\n\ninstall.packages(\"tidyverse\")\n\nwas written to the console before the start of the installation messages.\nYou could also have installed the tidyverse packages by running this command directly at the R terminal.\nWe will be using another package called here throughout the workshop to manage paths and directories. We will discuss it more detail in a later episode, but we will install it now in the console:\n\ninstall.packages(\"here\")\n\n\n\nUse RStudio to write and run R programs.\nUse install.packages() to install packages (libraries).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Before we Start</span>"
    ]
  },
  {
    "objectID": "01-intro-to-r.html",
    "href": "01-intro-to-r.html",
    "title": "2  Introduction to R",
    "section": "",
    "text": "2.1 Creating objects in R\nYou can get output from R simply by typing math in the console:\n3 + 5\n\n[1] 8\n\n12 / 7\n\n[1] 1.714286\nEverything that exists in R is an objects: from simple numerical values, to strings, to more complex objects like vectors, matrices, and lists. Even expressions and functions are objects in R.\nHowever, to do useful and interesting things, we need to name objects. To do so, we need to give a name followed by the assignment operator &lt;-, and the object we want to be named:\narea_hectares &lt;- 1.0\n&lt;- is the assignment operator. It assigns values (objects) on the right to names (also called symbols) on the left. So, after executing x &lt;- 3, the value of x is 3. The arrow can be read as 3 goes into x. For historical reasons, you can also use = for assignments, but not in every context. Because of the slight differences in syntax, it is good practice to always use &lt;- for assignments. More generally we prefer the &lt;- syntax over = because it makes it clear what direction the assignment is operating (left assignment), and it increases the read-ability of the code.\nIn RStudio, typing Alt + - (push Alt at the same time as the - key) will write &lt;- in a single keystroke in a PC, while typing Option + - (push Option at the same time as the - key) does the same in a Mac.\nObjects can be given any name such as x, current_temperature, or subject_id. You want your object names to be explicit and not too long. They cannot start with a number (2x is not valid, but x2 is). R is case sensitive (e.g., age is different from Age). There are some names that cannot be used because they are the names of fundamental objects in R (e.g., if, else, for, see here for a complete list). In general, even if it’s allowed, it’s best to not use them (e.g., c, T, mean, data, df, weights). If in doubt, check the help to see if the name is already in use. It’s also best to avoid dots (.) within an object name as in my.dataset. There are many objects in R with dots in their names for historical reasons, but because dots have a special meaning in R (for methods) and other programming languages, it’s best to avoid them. The recommended writing style is called snake_case, which implies using only lowercaseletters and numbers and separating each word with underscores (e.g., animals_weight, average_income). It is also recommended to use nouns for object names, and verbs for function names. It’s important to be consistent in the styling of your code (where you put spaces, how you name objects, etc.). Using a consistent coding style makes your code clearer to read for your future self and your collaborators. In R, three popular style guides are Google’s, Jean Fan’s and the tidyverse’s. The tidyverse’s is very comprehensive and may seem overwhelming at first. You can install the lintr package to automatically check for issues in the styling of your code.\nWhen assigning an value to a name, R does not print anything. You can force R to print the value by using parentheses or by typing the object name:\narea_hectares &lt;- 1.0    # doesn't print anything\n(area_hectares &lt;- 1.0)  # putting parenthesis around the call prints the value of `area_hectares`\n\n[1] 1\n\narea_hectares         # and so does typing the name of the object\n\n[1] 1\nNow that R has area_hectares in memory, we can do arithmetic with it. For instance, we may want to convert this area into acres (area in acres is 2.47 times the area in hectares):\n2.47 * area_hectares\n\n[1] 2.47\nWe can also change an the value assigned to an name by assigning it a new one:\narea_hectares &lt;- 2.5\n2.47 * area_hectares\n\n[1] 6.175\nThis means that assigning a value to one name does not change the values of other names. For example, let’s name the plot’s area in acres area_acres:\narea_acres &lt;- 2.47 * area_hectares\nand then change (reassign) area_hectares to 50.\narea_hectares &lt;- 50\nNow that we have learned how to write scripts, and the basics of R’s data structures, we are ready to start working with the SAFI dataset we have been using in the other lessons, and learn about data frames.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-intro-to-r.html#creating-objects-in-r",
    "href": "01-intro-to-r.html#creating-objects-in-r",
    "title": "2  Introduction to R",
    "section": "",
    "text": "NoneObjects vs. variables\n\n\n\nThe naming of objects in R is somehow related to variables in many other programming languages. In many programming languages, a variable has three aspects: a name, a memory location, and the current value stored in this location. R abstracts from modifiable memory locations. In R we only have objects which cn be named. Depending on the context, name (of an object) and variable can have drastically different meanings. However, in this lesson, the two words are used synonymously. For more information see: https://cran.r-project.org/doc/manuals/r-release/R-lang.html#Objects",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-intro-to-r.html#exercise",
    "href": "01-intro-to-r.html#exercise",
    "title": "2  Introduction to R",
    "section": "2.2 Exercise",
    "text": "2.2 Exercise\nWhat do you think is the current value of area_acres? 123.5 or 6.175?\n\nSolution (Solution). The value of area_acres is still 6.175 because you have not re-run the line area_acres &lt;- 2.47 * area_hectares since changing the value of area_hectares.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-intro-to-r.html#comments",
    "href": "01-intro-to-r.html#comments",
    "title": "2  Introduction to R",
    "section": "2.3 Comments",
    "text": "2.3 Comments\nAll programming languages allow the programmer to include comments in their code. Including comments to your code has many advantages: it helps you explain your reasoning and it forces you to be tidy. A commented code is also a great tool not only to your collaborators, but to your future self. Comments are the key to a reproducible analysis.\nTo do this in R we use the # character. Anything to the right of the # sign and up to the end of the line is treated as a comment and is ignored by R. You can start lines with comments or include them after any code on the line.\n\narea_hectares &lt;- 1.0            # land area in hectares\narea_acres &lt;- area_hectares * 2.47  # convert to acres\narea_acres              # print land area in acres.\n\n[1] 2.47\n\n\nRStudio makes it easy to comment or uncomment a paragraph: after selecting the lines you want to comment, press at the same time on your keyboard Ctrl + Shift + C. If you only want to comment out one line, you can put the cursor at any location of that line (i.e. no need to select the whole line), then press Ctrl + Shift + C.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-intro-to-r.html#exercise-1",
    "href": "01-intro-to-r.html#exercise-1",
    "title": "2  Introduction to R",
    "section": "2.4 Exercise",
    "text": "2.4 Exercise\nCreate two variables r_length and r_width and assign them values. It should be noted that, because length is a built-in R function, R Studio might add “()” after you type length and if you leave the parentheses you will get unexpected results. This is why you might see other programmers abbreviate common words. Create a third variable r_area and give it a value based on the current values of r_length and r_width. Show that changing the values of either r_length and r_width does not affect the value of r_area.\n\nSolution (Solution). \n\nr_length &lt;- 2.5\nr_width &lt;- 3.2\nr_area &lt;- r_length * r_width\nr_area\n\n[1] 8\n\n# change the values of r_length and r_width\nr_length &lt;- 7.0\nr_width &lt;- 6.5\n# the value of r_area isn't changed\nr_area\n\n[1] 8",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-intro-to-r.html#exercise-2",
    "href": "01-intro-to-r.html#exercise-2",
    "title": "2  Introduction to R",
    "section": "2.5 Exercise",
    "text": "2.5 Exercise\nType in ?round at the console and then look at the output in the Help pane. What other functions exist that are similar to round? How do you use the digits parameter in the round function?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-intro-to-r.html#vectors-and-data-types",
    "href": "01-intro-to-r.html#vectors-and-data-types",
    "title": "2  Introduction to R",
    "section": "2.6 Vectors and data types",
    "text": "2.6 Vectors and data types\nA vector is the most common and basic data type in R, and is pretty much the workhorse of R. A vector is composed by a series of values, which can be either numbers or characters. We can assign a series of values to a vector using the c() function. For example we can create a vector of the number of household members for the households we’ve interviewed and assign it to hh_members:\n\nhh_members &lt;- c(3, 7, 10, 6)\nhh_members\n\n[1]  3  7 10  6\n\n\nA vector can also contain characters. For example, we can have a vector of the building material used to construct our interview respondents’ walls (respondent_wall_type):\n\nrespondent_wall_type &lt;- c(\"muddaub\", \"burntbricks\", \"sunbricks\")\nrespondent_wall_type\n\n[1] \"muddaub\"     \"burntbricks\" \"sunbricks\"  \n\n\nThe quotes around “muddaub”, etc. are essential here. Without the quotes R will assume there are objects called muddaub, burntbricks and sunbricks. As these names don’t exist in R’s memory, there will be an error message.\nThere are many functions that allow you to inspect the content of a vector. length() tells you how many elements are in a particular vector:\n\nlength(hh_members)\n\n[1] 4\n\nlength(respondent_wall_type)\n\n[1] 3\n\n\nAn important feature of a vector, is that all of the elements are the same type of data. The function typeof() indicates the type of an object:\n\ntypeof(hh_members)\n\n[1] \"double\"\n\ntypeof(respondent_wall_type)\n\n[1] \"character\"\n\n\nThe function str() provides an overview of the structure of an object and its elements. It is a useful function when working with large and complex objects:\n\nstr(hh_members)\n\n num [1:4] 3 7 10 6\n\nstr(respondent_wall_type)\n\n chr [1:3] \"muddaub\" \"burntbricks\" \"sunbricks\"\n\n\nYou can use the c() function to add other elements to your vector:\n\npossessions &lt;- c(\"bicycle\", \"radio\", \"television\")\npossessions &lt;- c(possessions, \"mobile_phone\") # add to the end of the vector\npossessions &lt;- c(\"car\", possessions) # add to the beginning of the vector\npossessions\n\n[1] \"car\"          \"bicycle\"      \"radio\"        \"television\"   \"mobile_phone\"\n\n\nIn the first line, we take the original vector possessions, add the value \"mobile_phone\" to the end of it, and save the result back into possessions. Then we add the value \"car\" to the beginning, again saving the result back into possessions.\nWe can do this over and over again to grow a vector, or assemble a dataset. As we program, this may be useful to add results that we are collecting or calculating.\nAn atomic vector is the simplest R data type and is a linear vector of a single type. Above, we saw 2 of the 6 main atomic vector types that R uses: \"character\" and \"numeric\" (or \"double\"). These are the basic building blocks that all R objects are built from. The other 4 atomic vector types are:\n\n\"logical\" for TRUE and FALSE (the boolean data type)\n\"integer\" for integer numbers (e.g., 2L, the L indicates to R that it’s an integer)\n\"complex\" to represent complex numbers with real and imaginary parts (e.g., 1 + 4i) and that’s all we’re going to say about them\n\"raw\" for bitstreams that we won’t discuss further\n\nYou can check the type of your vector using the typeof() function and inputting your vector as the argument.\nVectors are one of the many data structures that R uses. Other important ones are lists (list), matrices (matrix), data frames (data.frame), factors (factor) and arrays (array).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-intro-to-r.html#exercise-3",
    "href": "01-intro-to-r.html#exercise-3",
    "title": "2  Introduction to R",
    "section": "2.7 Exercise",
    "text": "2.7 Exercise\nWe’ve seen that atomic vectors can be of type character, numeric (or double), integer, and logical. But what happens if we try to mix these types in a single vector?\n\nSolution (Solution). R implicitly converts them to all be the same type.\n\nWhat will happen in each of these examples? (hint: use class() to check the data type of your objects):\n\nnum_char &lt;- c(1, 2, 3, \"a\")\nnum_logical &lt;- c(1, 2, 3, TRUE)\nchar_logical &lt;- c(\"a\", \"b\", \"c\", TRUE)\ntricky &lt;- c(1, 2, 3, \"4\")\n\nWhy do you think it happens?\n\nSolution (Solution). Vectors can be of only one data type. R tries to convert (coerce) the content of this vector to find a “common denominator” that doesn’t lose any information.\n\nHow many values in combined_logical are \"TRUE\" (as a character) in the following example:\n\nnum_logical &lt;- c(1, 2, 3, TRUE)\nchar_logical &lt;- c(\"a\", \"b\", \"c\", TRUE)\ncombined_logical &lt;- c(num_logical, char_logical)\n\n\nSolution (Solution). Only one. There is no memory of past data types, and the coercion happens the first time the vector is evaluated. Therefore, the TRUE in num_logical gets converted into a 1 before it gets converted into \"1\" in combined_logical.\n\nYou’ve probably noticed that objects of different types get converted into a single, shared type within a vector. In R, we call converting objects from one class into another class coercion. These conversions happen according to a hierarchy, whereby some types get preferentially coerced into other types. Can you draw a diagram that represents the hierarchy of how these data types are coerced?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-intro-to-r.html#subsetting-vectors",
    "href": "01-intro-to-r.html#subsetting-vectors",
    "title": "2  Introduction to R",
    "section": "2.8 Subsetting vectors",
    "text": "2.8 Subsetting vectors\nSubsetting (sometimes referred to as extracting or indexing) involves accessing out one or more values based on their numeric placement or “index” within a vector. If we want to subset one or several values from a vector, we must provide one index or several indices in square brackets. For instance:\n\nrespondent_wall_type &lt;- c(\"muddaub\", \"burntbricks\", \"sunbricks\")\nrespondent_wall_type[2]\n\n[1] \"burntbricks\"\n\nrespondent_wall_type[c(3, 2)]\n\n[1] \"sunbricks\"   \"burntbricks\"\n\n\nWe can also repeat the indices to create an object with more elements than the original one:\n\nmore_respondent_wall_type &lt;- respondent_wall_type[c(1, 2, 3, 2, 1, 3)]\nmore_respondent_wall_type\n\n[1] \"muddaub\"     \"burntbricks\" \"sunbricks\"   \"burntbricks\" \"muddaub\"    \n[6] \"sunbricks\"  \n\n\nR indices start at 1. Programming languages like Fortran, MATLAB, Julia, and R start counting at 1, because that’s what human beings typically do. Languages in the C family (including C++, Java, Perl, and Python) count from 0 because that’s simpler for computers to do.\n\n2.8.1 Conditional subsetting\nAnother common way of subsetting is by using a logical vector. TRUE will select the element with the same index, while FALSE will not:\n\nhh_members &lt;- c(3, 7, 10, 6)\nhh_members[c(TRUE, FALSE, TRUE, TRUE)]\n\n[1]  3 10  6\n\n\nTypically, these logical vectors are not typed by hand, but are the output of other functions or logical tests. For instance, if you wanted to select only the values above 5:\n\nhh_members &gt; 5    # will return logicals with TRUE for the indices that meet the condition\n\n[1] FALSE  TRUE  TRUE  TRUE\n\n## so we can use this to select only the values above 5\nhh_members[hh_members &gt; 5]\n\n[1]  7 10  6\n\n\nYou can combine multiple tests using & (both conditions are true, AND) or | (at least one of the conditions is true, OR):\n\nhh_members[hh_members &lt; 4 | hh_members &gt; 7]\n\n[1]  3 10\n\nhh_members[hh_members &gt;= 4 & hh_members &lt;= 7]\n\n[1] 7 6\n\n\nHere, &lt; stands for “less than”, &gt; for “greater than”, &gt;= for “greater than or equal to”, and == for “equal to”. The double equal sign == is a test for numerical equality between the left and right hand sides, and should not be confused with the single = sign, which performs variable assignment (similar to &lt;-).\nA common task is to search for certain strings in a vector. One could use the “or” operator | to test for equality to multiple values, but this can quickly become tedious.\n\npossessions &lt;- c(\"car\", \"bicycle\", \"radio\", \"television\", \"mobile_phone\")\npossessions[possessions == \"car\" | possessions == \"bicycle\"] # returns both car and bicycle\n\n[1] \"car\"     \"bicycle\"\n\n\nThe function %in% allows you to test if any of the elements of a search vector (on the left hand side) are found in the target vector (on the right hand side):\n\npossessions %in% c(\"car\", \"bicycle\")\n\n[1]  TRUE  TRUE FALSE FALSE FALSE\n\n\nNote that the output is the same length as the search vector on the left hand side, because %in% checks whether each element of the search vector is found somewhere in the target vector. Thus, you can use %in% to select the elements in the search vector that appear in your target vector:\n\npossessions %in% c(\"car\", \"bicycle\", \"motorcycle\", \"truck\", \"boat\", \"bus\")\n\n[1]  TRUE  TRUE FALSE FALSE FALSE\n\npossessions[possessions %in% c(\"car\", \"bicycle\", \"motorcycle\", \"truck\", \"boat\", \"bus\")]\n\n[1] \"car\"     \"bicycle\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-intro-to-r.html#missing-data",
    "href": "01-intro-to-r.html#missing-data",
    "title": "2  Introduction to R",
    "section": "2.9 Missing data",
    "text": "2.9 Missing data\nAs R was designed to analyze datasets, it includes the concept of missing data (which is uncommon in other programming languages). Missing data are represented in vectors as NA.\nWhen doing operations on numbers, most functions will return NA if the data you are working with include missing values. This feature makes it harder to overlook the cases where you are dealing with missing data. You can add the argument na.rm=TRUE to calculate the result while ignoring the missing values.\n\nrooms &lt;- c(2, 1, 1, NA, 7)\nmean(rooms)\n\n[1] NA\n\nmax(rooms)\n\n[1] NA\n\nmean(rooms, na.rm = TRUE)\n\n[1] 2.75\n\nmax(rooms, na.rm = TRUE)\n\n[1] 7\n\n\nIf your data include missing values, you may want to become familiar with the functions is.na(), na.omit(), and complete.cases(). See below for examples.\n\n## Extract those elements which are not missing values.\n## The ! character is also called the NOT operator\nrooms[!is.na(rooms)]\n\n[1] 2 1 1 7\n\n## Count the number of missing values.\n## The output of is.na() is a logical vector (TRUE/FALSE equivalent to 1/0) so the sum() function here is effectively counting\nsum(is.na(rooms))\n\n[1] 1\n\n## Returns the object with incomplete cases removed. The returned object is an atomic vector of type `\"numeric\"` (or `\"double\"`).\nna.omit(rooms)\n\n[1] 2 1 1 7\nattr(,\"na.action\")\n[1] 4\nattr(,\"class\")\n[1] \"omit\"\n\n## Extract those elements which are complete cases. The returned object is an atomic vector of type `\"numeric\"` (or `\"double\"`).\nrooms[complete.cases(rooms)]\n\n[1] 2 1 1 7\n\n\nRecall that you can use the typeof() function to find the type of your atomic vector.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-intro-to-r.html#exercise-4",
    "href": "01-intro-to-r.html#exercise-4",
    "title": "2  Introduction to R",
    "section": "2.10 Exercise",
    "text": "2.10 Exercise\n\nUsing this vector of rooms, create a new vector with the NAs removed.\n\nrooms &lt;- c(1, 2, 1, 1, NA, 3, 1, 3, 2, 1, 1, 8, 3, 1, NA, 1)\n\nUse the function median() to calculate the median of the rooms vector.\nUse R to figure out how many households in the set use more than 2 rooms for sleeping.\n\n\nSolution (Solution). \n\nrooms &lt;- c(1, 2, 1, 1, NA, 3, 1, 3, 2, 1, 1, 8, 3, 1, NA, 1)\nrooms_no_na &lt;- rooms[!is.na(rooms)]\n# or\nrooms_no_na &lt;- na.omit(rooms)\n# 2.\nmedian(rooms, na.rm = TRUE)\n\n[1] 1\n\n# 3.\nrooms_above_2 &lt;- rooms_no_na[rooms_no_na &gt; 2]\nlength(rooms_above_2)\n\n[1] 4",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Summary</span>"
    ]
  }
]